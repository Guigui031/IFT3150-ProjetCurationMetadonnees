key	project	title	abstract	keywords	authors	venue	doi	references	pages	bibtex	screened_decision	final_decision	mode	inclusion_criteria	exclusion_criteria	reviewer_count	source	year	meta_title	link	publisher	metadata_missing
0	TestNN	A framework for testing robust autonomy of UAS during design and certification	As the number of Uninhabited Airborne Systems (UAS) proliferates in civil applications, industry is increasingly putting pressure on regulation authorities to provide a path for certification and allow UAS integration into regulated airspace. The success of this integration depends on developments in improved UAS reliability and safety, regulations for certification, and technologies for operational performance and safety assessment. This paper focusses on the last topic and describes a framework for quantifying robust autonomy of UAS, which quantifies the system's ability to either continue operating in the presence of faults or safely shut down. Two figures of merit are used to evaluate vehicle performance relative to mission requirements and the consequences of autonomous decision making in motion control and guidance systems. These figures of merit are interpreted within a probabilistic framework, which extends previous work in the literature. The valuation of the figures of merit can be done using stochastic simulation scenarios during both vehicle development and certification stages with different degrees of integration of hardware-in-the-loop simulation technology. The objective of the proposed framework is to aid in decision making about the suitability of a vehicle with respect to safety and reliability relative to mission requirements. © 2011 by The University of Newcastle.	Decision making; Stochastic models; Vehicle performance; Autonomous decision; Control and guidance systems; Hardware in-the-loop simulation; Mission requirements; Operational performance; Probabilistic framework; Reliability and safeties; Stochastic simulations; Integration	Perez, Tristan; Donaire, Alejandro; de Lamberterie, Pierre; Williams, Brendan	AIAA Infotech at Aerospace Conference and Exhibit 2011				"@CONFERENCE{Perez2011,
    author = ""Perez, Tristan and Donaire, Alejandro and de Lamberterie, Pierre and Williams, Brendan"",
    title = ""A framework for testing robust autonomy of UAS during design and certification"",
    year = ""2011"",
    journal = ""AIAA Infotech at Aerospace Conference and Exhibit 2011"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880791365\&partnerID=40\&md5=67e1d8db066df28bfcdfeab4463af69d"",
    affiliations = ""School of Engineering, University of Newcastle, Callaghan, NSW-2308, Australia; Centre for Complex Dynamic Systems and Control, University of Newcastle, School of Engineering, Callaghan, NSW-2308, Australia; Brisbane Technology Centre, Boeing Research and Technology, QLD-4001, GPO Box 767, Australia"",
    abstract = ""As the number of Uninhabited Airborne Systems (UAS) proliferates in civil applications, industry is increasingly putting pressure on regulation authorities to provide a path for certification and allow UAS integration into regulated airspace. The success of this integration depends on developments in improved UAS reliability and safety, regulations for certification, and technologies for operational performance and safety assessment. This paper focusses on the last topic and describes a framework for quantifying robust autonomy of UAS, which quantifies the system's ability to either continue operating in the presence of faults or safely shut down. Two figures of merit are used to evaluate vehicle performance relative to mission requirements and the consequences of autonomous decision making in motion control and guidance systems. These figures of merit are interpreted within a probabilistic framework, which extends previous work in the literature. The valuation of the figures of merit can be done using stochastic simulation scenarios during both vehicle development and certification stages with different degrees of integration of hardware-in-the-loop simulation technology. The objective of the proposed framework is to aid in decision making about the suitability of a vehicle with respect to safety and reliability relative to mission requirements. © 2011 by The University of Newcastle."",
    keywords = ""Decision making; Stochastic models; Vehicle performance; Autonomous decision; Control and guidance systems; Hardware in-the-loop simulation; Mission requirements; Operational performance; Probabilistic framework; Reliability and safeties; Stochastic simulations; Integration"",
    isbn = ""978-160086944-0"",
    language = ""English"",
    abbrev_source_title = ""AIAA Infotech at Aerospace Conf. and Exhib. 2011"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: AIAA Infotech at Aerospace Conference and Exhibit 2011; Conference date: 29 March 2011 through 31 March 2011; Conference code: 97876""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2011	 A framework for testing robust autonomy of UAS during design and certification	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880791365&partnerID=40&md5=67e1d8db066df28bfcdfeab4463af69d		nan; References; Pages; DOI; Publisher
1	TestNN	A PROBABILISTIC APPROACH TO COLLISION RISK ESTIMATION FOR PASSENGER VEHICLES	"<div class=""abstract author"" id=""ceab10""><h2 class=""section-title u-h4 u-margin-l-top u-margin-xs-bottom"">Abstract</h2><div id=""ceabs10""><p id=""spara10"">Active safety and collision avoidance (CA) is a growing field within the automotive industry. The aim of CA systems is to prevent or mitigate collisions by active interventions i.e. warning, braking and steering. For many reasons, such as driver acceptance of the system and legal requirement that the system itself must not cause hazards, the decision making is a crucial part of the system. This paper presents a method for risk estimation on which to base the decision making. We will show how one can form criterions for decision making in terms of probability of collision. This criterion handles the noisy sensor data and process noise (driver behavior) in a natural way, using existing tracking theory. The method is illustrated by simulation results as well as test result from a prototype vehicle. Simulations and tests are examples of a system which performs autonomous braking actuation at imminent collision.</p></div></div>"	Collision Avoidance; Collision Mitigation; Tracking; Decision Making; Collision Probability	Jansson, J. and F. Gustafsson	IFAC Proceedings Volumes	https://doi.org/10.3182/20020721-6-ES-1901.01505		Volume 35, Issue 1,2002, Pages 		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ScienceDirect	2002	 A probabilistic approach to collision risk estimation for passenger vehicles		Science Direct	nan; Authors; References; Year; Bibtex; Link
2	TestNN	A rational agent controlling an autonomous vehicle: Implementation and formal verification	The development and deployment of Autonomous Vehicles (AVs) on our roads is not only realistic in the near future but can also bring significant benefits. In particular, it can potentially solve several problems relating to vehicles and traffic, for instance: (i) possible reduction of traffic congestion, with the consequence of improved fuel economy and reduced driver inactivity; (ii) possible reduction in the number of accidents, assuming that an AV can minimise the human errors that often cause traffic accidents; and (iii) increased ease of parking, especially when one considers the potential for shared AVs. In order to deploy an AV there are significant steps that must be completed in terms of hardware and software. As expected, software components play a key role in the complex AV system and so, at least for safety, we should assess the correctness of these components. In this paper, we are concerned with the high-level software component(s) responsible for the decisions in an AV. We intend to model an AV capable of navigation; obstacle avoidance; obstacle selection (when a crash is unavoidable) and vehicle recovery, etc, using a rational agent. To achieve this, we have established the following stages. First, the agent plans and actions have been implemented within the GWENDOLEN agent programming language. Second, we have built a simulated automotive environment in the Java language. Third, we have formally specified some of the required agent properties through LTL formulae, which are then formally verified with the AJPF verification tool. Finally, within the MCAPL framework (which comprises all the tools used in previous stages) we have obtained formal verification of our AV agent in terms of its specific behaviours. For example, the agent plans responsible for selecting an obstacle with low potential damage, instead of a higher damage obstacle (when possible) can be formally verified within MCAPL.We must emphasise that the major goal (of our present approach) lies in the formal verification of agent plans, rather than evaluating real-world applications. For this reason we utilised a simple matrix representation concerning the environment used by our agent. © 2017 L. Fernandes, V. Custodio, G. Alves & M. Fisher.	Accidents; Computer software; Formal verification; Fuel economy; Traffic congestion; Vehicles; Agent programming languages; Automotive environment; Autonomous Vehicles; Hardware and software; Matrix representation; Software component; Vehicle recoveries; Verification tools; Autonomous agents	Fernandes, Lucas E.R.; Custodio, Vinicius; Alves, Gleifer V.; Fisher, Michael	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.5		35 – 42	"@CONFERENCE{Fernandes201735,
    author = ""Fernandes, Lucas E.R. and Custodio, Vinicius and Alves, Gleifer V. and Fisher, Michael"",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""A rational agent controlling an autonomous vehicle: Implementation and formal verification"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""35 – 42"",
    doi = ""10.4204/EPTCS.257.5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101519\&doi=10.4204\%2fEPTCS.257.5\&partnerID=40\&md5=afd12f85812acf2a0c4a00b832fc77ad"",
    affiliations = ""Informatics Department, UTFPR - Federal University of Technology - Parańa, Campus Ponta Grossa, Ponta Grossa, Brazil; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom"",
    abstract = ""The development and deployment of Autonomous Vehicles (AVs) on our roads is not only realistic in the near future but can also bring significant benefits. In particular, it can potentially solve several problems relating to vehicles and traffic, for instance: (i) possible reduction of traffic congestion, with the consequence of improved fuel economy and reduced driver inactivity; (ii) possible reduction in the number of accidents, assuming that an AV can minimise the human errors that often cause traffic accidents; and (iii) increased ease of parking, especially when one considers the potential for shared AVs. In order to deploy an AV there are significant steps that must be completed in terms of hardware and software. As expected, software components play a key role in the complex AV system and so, at least for safety, we should assess the correctness of these components. In this paper, we are concerned with the high-level software component(s) responsible for the decisions in an AV. We intend to model an AV capable of navigation; obstacle avoidance; obstacle selection (when a crash is unavoidable) and vehicle recovery, etc, using a rational agent. To achieve this, we have established the following stages. First, the agent plans and actions have been implemented within the GWENDOLEN agent programming language. Second, we have built a simulated automotive environment in the Java language. Third, we have formally specified some of the required agent properties through LTL formulae, which are then formally verified with the AJPF verification tool. Finally, within the MCAPL framework (which comprises all the tools used in previous stages) we have obtained formal verification of our AV agent in terms of its specific behaviours. For example, the agent plans responsible for selecting an obstacle with low potential damage, instead of a higher damage obstacle (when possible) can be formally verified within MCAPL.We must emphasise that the major goal (of our present approach) lies in the formal verification of agent plans, rather than evaluating real-world applications. For this reason we utilised a simple matrix representation concerning the environment used by our agent. © 2017 L. Fernandes, V. Custodio, G. Alves \& M. Fisher."",
    keywords = ""Accidents; Computer software; Formal verification; Fuel economy; Traffic congestion; Vehicles; Agent programming languages; Automotive environment; Autonomous Vehicles; Hardware and software; Matrix representation; Software component; Vehicle recoveries; Verification tools; Autonomous agents"",
    correspondence_address = ""L.E.R. Fernandes; Informatics Department, UTFPR - Federal University of Technology - Parańa, Campus Ponta Grossa, Ponta Grossa, Brazil; email: lucfer@alunos.utfpr.edu.br"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 14; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	 A rational agent controlling an autonomous vehicle: Implementation and formal verification	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101519&doi=10.4204%2fEPTCS.257.5&partnerID=40&md5=afd12f85812acf2a0c4a00b832fc77ad	Open Publishing Association	nan; References
3	TestNN	A safety concept for camera based ADAS based on multicore MCU	With the introduction of camera based ADAS systems; there is a need to consider the systems design in terms of functional safety. This is especially so in cases where system image identification results in decision to control the vehicle like in autonomous braking. Firstly, a review of functional safety is followed by a safety analysis of a camera based forward collision warning system. Potential hazards and safety goals will be described. A functional safety concept of the ECU based on multi core MCU is introduced based on image data flow from camera sensor to MCU. Safety mechanisms are introduced at each stage ensuring the correct processed image and decision based on that image. An actual MCU based design that implements these safety mechanisms is also described. © 2014 IEEE.	Alarm systems; Cameras; Image processing; Autonomous braking; Forward collision warning system; Functional Safety; Functional safety concepts; Image identification; Potential hazards; Processed images; Safety mechanisms; Microcontrollers	Tan, Robert	2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014	https://doi.org/10.1109/ICVES.2014.7063714		1 – 6	"@CONFERENCE{Tan20141,
    author = ""Tan, Robert"",
    title = ""A safety concept for camera based ADAS based on multicore MCU"",
    year = ""2014"",
    journal = ""2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014"",
    pages = ""1 – 6"",
    doi = ""10.1109/ICVES.2014.7063714"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934284774\&doi=10.1109\%2fICVES.2014.7063714\&partnerID=40\&md5=65782eadc62bcf44540445a927e78eab"",
    affiliations = ""Infineon Technologies Asia Pacific, United States"",
    abstract = ""With the introduction of camera based ADAS systems; there is a need to consider the systems design in terms of functional safety. This is especially so in cases where system image identification results in decision to control the vehicle like in autonomous braking. Firstly, a review of functional safety is followed by a safety analysis of a camera based forward collision warning system. Potential hazards and safety goals will be described. A functional safety concept of the ECU based on multi core MCU is introduced based on image data flow from camera sensor to MCU. Safety mechanisms are introduced at each stage ensuring the correct processed image and decision based on that image. An actual MCU based design that implements these safety mechanisms is also described. © 2014 IEEE."",
    keywords = ""Alarm systems; Cameras; Image processing; Autonomous braking; Forward collision warning system; Functional Safety; Functional safety concepts; Image identification; Potential hazards; Processed images; Safety mechanisms; Microcontrollers"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147991882-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE Int. Conf. Veh. Electron. Saf., ICVES"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014; Conference date: 16 December 2014 through 17 December 2014; Conference code: 112416""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2014	 A Safety Concept for Camera Based ADAS Based on MultiCore MCU	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934284774&doi=10.1109%2fICVES.2014.7063714&partnerID=40&md5=65782eadc62bcf44540445a927e78eab	Institute of Electrical and Electronics Engineers Inc.	nan; References
4	TestNN	Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators	Deep neural networks have become a ubiquitous tool for mastering complex classification tasks. Current research focuses on the development of power-efficient and fast neural network hardware accelerators for mobile and embedded devices. However, when used in safety-critical applications, for example autonomously operating vehicles, the reliability of such accelerators becomes a further optimization criterion which can stand in contrast to power-efficiency and latency. Furthermore, ensuring hardware reliability becomes increasingly challenging for shrinking structure widths and rising power densities in the nanometer semiconductor technology era. One solution to this challenge is the exploitation of fault tolerant parts in deep neural networks. In this paper we propose a new method for predicting the error resilience of neurons in deep neural networks and show that this method significantly improves upon existing methods in terms of accuracy as well as interpretability. We evaluate prediction accuracy by simulating hardware faults in networks trained on the CIFAR-10 and ILSVRC image classification benchmarks and protecting neurons according to the resilience estimations. In addition, we demonstrate how our resilience prediction can be used for a flexible trade-off between reliability and efficiency in neural network hardware accelerators. © 2018 EDAA.	Economic and social effects; Efficiency; Forecasting; Hardware; Neural networks; Neurons; Reliability; Safety engineering; Semiconductor device manufacture; Classification tasks; Fast neural networks; Hardware reliability; Nanometer semiconductor technologies; Neural network hardware; Optimization criteria; Reliability management; Safety critical applications; Deep neural networks	Schorn, Christoph; Guntoro, Andre; Ascheid, Gerd	Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018	https://doi.org/10.23919/DATE.2018.8342151		979 – 984	"@CONFERENCE{Schorn2018979,
    author = ""Schorn, Christoph and Guntoro, Andre and Ascheid, Gerd"",
    title = ""Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators"",
    year = ""2018"",
    journal = ""Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018"",
    volume = ""2018-January"",
    pages = ""979 – 984"",
    doi = ""10.23919/DATE.2018.8342151"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048779488\&doi=10.23919\%2fDATE.2018.8342151\&partnerID=40\&md5=6570c2c004d25bbca0a01496acb7c11e"",
    affiliations = ""Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany"",
    abstract = ""Deep neural networks have become a ubiquitous tool for mastering complex classification tasks. Current research focuses on the development of power-efficient and fast neural network hardware accelerators for mobile and embedded devices. However, when used in safety-critical applications, for example autonomously operating vehicles, the reliability of such accelerators becomes a further optimization criterion which can stand in contrast to power-efficiency and latency. Furthermore, ensuring hardware reliability becomes increasingly challenging for shrinking structure widths and rising power densities in the nanometer semiconductor technology era. One solution to this challenge is the exploitation of fault tolerant parts in deep neural networks. In this paper we propose a new method for predicting the error resilience of neurons in deep neural networks and show that this method significantly improves upon existing methods in terms of accuracy as well as interpretability. We evaluate prediction accuracy by simulating hardware faults in networks trained on the CIFAR-10 and ILSVRC image classification benchmarks and protecting neurons according to the resilience estimations. In addition, we demonstrate how our resilience prediction can be used for a flexible trade-off between reliability and efficiency in neural network hardware accelerators. © 2018 EDAA."",
    keywords = ""Economic and social effects; Efficiency; Forecasting; Hardware; Neural networks; Neurons; Reliability; Safety engineering; Semiconductor device manufacture; Classification tasks; Fast neural networks; Hardware reliability; Nanometer semiconductor technologies; Neural network hardware; Optimization criteria; Reliability management; Safety critical applications; Deep neural networks"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-398192631-6"",
    language = ""English"",
    abbrev_source_title = ""Proc. Des., Autom. Test Europe Conf. Exhib., DATE"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 58; Conference name: 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018; Conference date: 19 March 2018 through 23 March 2018; Conference code: 136090""
}
"	Included	Included	new_screen			1	Scopus	2018	 Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048779488&doi=10.23919%2fDATE.2018.8342151&partnerID=40&md5=6570c2c004d25bbca0a01496acb7c11e	Institute of Electrical and Electronics Engineers Inc.	nan; References
5	TestNN	Adversarial attacks on computer vision algorithms using natural perturbations	Verifying the correctness of intelligent embedded systems is notoriously difficult due to the use of machine learning algorithms that cannot provide guarantees of deterministic correctness. In this paper, our validation efforts demonstrate that the OpenCV Histogram of Oriented Gradients (HOG) implementation for human detection is susceptible to errors due to both malicious perturbations and naturally occurring fog phenomena. To the best of our knowledge, we are the first to explicitly employ a natural perturbation (like fog) as an adversarial attack using methods from computer graphics. Our experimental results show that computer vision algorithms are susceptible to errors under a small set of naturally occurring perturbations even if they are robust to a majority of such perturbations. Our methods and results may be of interest to the designers, developers and validation teams of intelligent cyber-physical systems such as autonomous cars.		Arvind Ramanathan; Laura Pullum; Zubir Husein; Sunny Raj; Neslisah Torosdagli; Sumanta Pattanaik; Sumit K. Jha	2017 Tenth International Conference on Contemporary Computing (IC3)	https://doi.org/10.1109/IC3.2017.8284294	"1.S. Thrun, ""Toward robotic cars"", Communications of the ACM, vol. 53, no. 4, pp. 99-106, 2010. CrossRef  Google Scholar; 2.C. Mack, ""The multiple lives of moores law"", IEEE Spectrum, vol. 52, no. 4, pp. 31-31, 2015. View Article  Google Scholar; 3.I. L. Markov, ""Limits on fundamental limits to computation"", Nature, vol. 512, no. 7513, pp. 147-154, 2014. CrossRef  Google Scholar; 4.N. Dalal and B. Triggs, ""Histograms of oriented gradients for human detection"", Computer Vision and Pattern Recognition 2005. CVPR 2005. IEEE Computer Society Conference, vol. 1, pp. 886-893, 2005. View Article  Google Scholar; 5.G. Bradski and A. Kaebler, Computer vision with the opencv library, 2008. Google Scholar; 6.C.-R. Hwang, ""Simulated annealing: theory and applications"", Acta Applicandae Mathematicae, vol. 12, no. 1, pp. 108-111, 1988. CrossRef  Google Scholar; 7.I. J. Goodfellow, J. Shlens and C. Szegedy, Explaining and harnessing adversarial examples, 2014. Google Scholar; 8.A. Nguyen, J. Yosinski and J. Clune, ""Deep neural networks are easily fooled: High confidence predictions for unrecognizable images"", 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436, 2015. View Article  Google Scholar; 9.A. Ramanathan, L. L. Pullum, F. Hussain, D. Chakrabarty and S. K. Jha, ""Integrating symbolic and statistical methods for testing intelligent systems: Applications to machine learning and computer vision"", 2016 Design Automation  Test in Europe Conference  Exhibition (DATE), pp. 786-791, 2016. CrossRef  Google Scholar; 10.A. Kurakin, I. Goodfellow and S. Bengio, Adversarial examples in the physical world, 2016. Google Scholar; 11.M. Pacula, Unit-testing statistical software, February 2011,  [online]  Available: http://blog.mpacula.com/2011/02/17/unit-testing-statistical-software/. Google Scholar; 12.R. B. Grosse and D. K. Duvenaud, Testing mcmc code, 2014. Google Scholar; 13.T. Ball, B. Cook, V. Levin and S. K. Rajamani, ""Slam and static driver verifier: Technology transfer of formal methods inside microsoft"", International Conference on Integrated Formal Methods, pp. 1-20, 2004. CrossRef  Google Scholar; 14.L. Fix, ""Fifteen years of formal property verification in intel"" in 25 Years of Model Checking, Springer, pp. 139-144, 2008. CrossRef  Google Scholar; 15.R. Kaivola, R. Ghughal, N. Narasimhan, A. Telfer, J. Whittemore, S. Pandav, A. Slobodová, C. Taylor, V. Frolov, E. Reeber et al., ""Replacing testing with formal verification in intel coretm i7 processor execution engine validation"", International Conference on Computer Aided Verification, pp. 414-429, 2009. CrossRef  Google Scholar; 16.G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish et al., ""se14: Formal verification of an os kernel"", Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, pp. 207-220, 2009. CrossRef  Google Scholar; 17.A. Gupta, ""Formal hardware verification methods: A survey"" in Computer-Aided Verification, Springer, pp. 5-92, 1993. Google Scholar; 18.E. M. Clarke, O. Grumberg and D. Peled, Model checking, MIT press, 1999. Google Scholar; 19.M. Kwiatkowska, G. Norman and D. Parker, ""Stochastic model checking"" in Formal methods for performance evaluation, Springer, pp. 220-270, 2007. CrossRef  Google Scholar; 20.J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill and L.-J. Hwang, ""Symbolic model checking: 10 20 states and beyond"", Logic in Computer Science 1990. LICS‘90 Proceedings. Fifth Annual IEEE Symposium on e, pp. 428-439, 1990. View Article  Google Scholar; 21.A. Legay, B. Delahaye and S. Bensalem, ""Statistical model checking: An overview"" in Runtime Verification, Springer, pp. 122-135, 2010. CrossRef  Google Scholar; 22.S. Kirkpatrick, ""Optimization by simulated annealing: Quantitative studies"", Journal of statistical physics, vol. 34, no. 5–6, pp. 975-986, 1984. CrossRef  Google Scholar; 23.E. Aarts, J. Korst and W. Michiels, ""Simulated annealing"" in Search methodologies, Springer, pp. 265-285, 2014. CrossRef  Google Scholar; 24.E. Aarts and J. Korst, Simulated annealing and boltzmann machines, 1988. Google Scholar; 25.R. Mantiuk, K. J. Kim, A. G. Rempel and W. Heidrich, ""Hdr-vdp-2: a calibrated visual metric for visibility and quality predictions in all luminance conditions"", ACM Transactions on Graphics (TOG), vol. 30, no. 4, pp. 40, 2011. CrossRef  Google Scholar; 26.K. Perlin, SIGGRAPH Comput. Graph., vol. 19, no. 3, pp. 287-296, Jul. 1985. CrossRef  Google Scholar; 27.N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. Berkay Celik and A. Swami, Practical black-box attacks against deep learning systems using adversarial examples, 2016. Google Scholar"			Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2017	 Adversarial attacks on computer vision algorithms using natural perturbations		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
6	TestNN	Analysis of the Random Direction Mobility Model with a Sense-and-Avoid Protocol	Random mobility models (RMMs) capture the random movement patterns of mobile agents, and have been widely used in the evaluation and design of mobile networks. Existing RMMs (e.g. random walk and random direction) assume every mobile agent to move independently. Unmanned aerial systems (UASs), on the other hand, need to maintain a separation distance for the safety of the airspace, and hence their mobility patterns violate the independent movement assumption of existing RMMs. In this paper, for the first time in the literature per knowledge of authors, we enhance the Random Direction RMM through equipping it with a commonly used decentralized sense and avoid protocol-- sense-and-stop (S&S). We provide analytical results on critical networking statistics such as stationary node distribution and inter-vehicle distance distribution in a two-dimensional (2-D) space using the Markov type of analysis. The analysis and simulation studies lead to interesting insights such as that the commonly used S&S protocol is not effective when the randomness of UAV mobility is high, as it increases the probability for a UAS to stay within the collision distance.		Mushuang Liu; Yan Wan; Frank L. Lewis	2017 IEEE Globecom Workshops (GC Wkshps)	https://doi.org/10.1109/GLOCOMW.2017.8269071	"1.Commercial uav market analysis by product (fixed wing rotary blade nano hybrid) by application (agriculture energy government media and entertainment) and segment forecasts to 2022,  [online]  Available: http://www.grandviewresearch.com/press-release/commercial-drone-market. Google Scholar; 2.Faa news,  [online]  Available: https://www.faa.gov/uas/media/Part_107_Summary.pdf. Google Scholar; 3.J. Yan, Y. Wan, S. Fu, J. Xie, S. Li and K. Lu, ""Received signal strength indicator-based decentralised control for robust long-range aerial networking using directional antennas"", IET Control Theory & Applications, 2017. CrossRef  Google Scholar; 4.J. Chen, J. Xie, Y. Gu, S. Li, S. Fu, Y. Wan, et al., ""Long-range and broadband aerial communication using directional antennas (acda): Design and implementation"", IEEE Transactions on Vehicular Technology, 2017. View Article  Google Scholar; 5.J. Xie, Y. Wan, J.H. Kim, S. Fu and K. Namuduri, ""A survey and analysis of mobility models for airborne networks"", IEEE Communications Surveys & Tutorials, vol. 16, no. 3, pp. 1221-1238, 2014. View Article  Google Scholar; 6.Y. Wan, K. Namuduri, Y. Zhou and S. Fu, ""A smooth-turn mobility model for airborne networks"", IEEE Transactions on Vehicular Technology, vol. 62, no. 7, pp. 3359-3370, 2013. View Article  Google Scholar; 7.Z. Cheng and W.B. Heinzelman, ""Exploring long lifetime routing (llr) in ad hoc networks"", Proceedings of the 7th ACM international symposium on Modeling analysis and simulation of wireless and mobile systems, pp. 203-210, 2004. CrossRef  Google Scholar; 8.G. Lim, K. Shin, S. Lee, H. Yoon and J.S. Ma, ""Link stability and route lifetime in ad-hoc wireless networks"", Parallel Processing Workshops 2002. Proceedings. International Conference on, pp. 116-123, 2002. Google Scholar; 9.P. Nain, D. Towsley, B. Liu and Z. Liu, ""Properties of random direction models"", INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE, vol. 3, pp. 1897-1907, 2005. CrossRef  Google Scholar; 10.T. Camp, J. Boleng and V. Davies, ""A survey of mobility models for ad hoc network research"", Wireless Communications and Mobile Computing, vol. 2, no. 5, pp. 483-502, 2002. CrossRef  Google Scholar; 11.J. Xie, Y. Wan, J.H. Kim, S. Fu and K. Namuduri, ""A survey and analysis of mobility models for airborne networks"", IEEE Communications Surveys & Tutorials, vol. 16, no. 3, pp. 1221-1238, 2014. View Article  Google Scholar; 12.A. Van Zanten, ""Cyclic distance-preserving codes on a constant-weight basis"", Discrete applied mathematics, vol. 114, no. 1, pp. 289-294, 2001. CrossRef  Google Scholar"			Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2017	 Analysis of the Random Direction Mobility Model with a Sense-and-Avoid Protocol		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
7	TestNN	Application of fuzzy logic for safe autonomous subsea IMR operations	Numerous technical and knowledge gaps pose challenges towards implementation of autonomous subsea intervention, maintenance, and repair operations. One such gap is related to development of methods for ensuring subsea asset and operational safety during autonomous subsea interventions. This paper describes a novel approach of using fuzzy logic to develop an asset safety decision support basis in resident underwater vehicles. A fuzzy inference system is developed with remotely operated vehicle envelope and sensor condition as input variables. Fuzzy sets and their respective membership functions are defined. On the basis of existing subsea knowledge in subsea operations, fifteen fuzzy rules are derived. The aggregated conclusions vary for different range values of ROV envelopes and conditions of the sensor system. The initial findings from simulation of the fuzzy inference system show that application of fuzzy logic to subsea intervention operations can be valuable for development of asset safety related aspects, such as for consequence analysis, operational safety, and development of safety philosophies. © 2015 Taylor & Francis Group, London.	Computer circuits; Decision support systems; Fuzzy logic; Fuzzy systems; Membership functions; Philosophical aspects; Reliability; Remotely operated vehicles; Repair; Consequence analysis; Decision supports; Fuzzy inference systems; Input variables; Operational safety; Repair operations; Sub-sea operations; Underwater vehicles; Fuzzy inference	Hegde, J.; Utne, I.B.; Schjølberg, I.; Thorkildsen, B.	Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015	https://doi.org/10.1201/b19094-58		415 – 422	"@CONFERENCE{Hegde2015415,
    author = ""Hegde, J. and Utne, I.B. and Schjølberg, I. and Thorkildsen, B."",
    editor = ""L., Podofillini and B., Sudret and B., Stojadinović and E., Zio and W., Kröger"",
    title = ""Application of fuzzy logic for safe autonomous subsea IMR operations"",
    year = ""2015"",
    journal = ""Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015"",
    pages = ""415 – 422"",
    doi = ""10.1201/b19094-58"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010981\&doi=10.1201\%2fb19094-58\&partnerID=40\&md5=474ee0be547665f0ae4e162f4f16067e"",
    affiliations = ""Department of Marine Technology, Norwegian University of Science and Technology, Trondheim, Norway; FMC Kongsberg Subsea AS, Kongsberg, Norway"",
    abstract = ""Numerous technical and knowledge gaps pose challenges towards implementation of autonomous subsea intervention, maintenance, and repair operations. One such gap is related to development of methods for ensuring subsea asset and operational safety during autonomous subsea interventions. This paper describes a novel approach of using fuzzy logic to develop an asset safety decision support basis in resident underwater vehicles. A fuzzy inference system is developed with remotely operated vehicle envelope and sensor condition as input variables. Fuzzy sets and their respective membership functions are defined. On the basis of existing subsea knowledge in subsea operations, fifteen fuzzy rules are derived. The aggregated conclusions vary for different range values of ROV envelopes and conditions of the sensor system. The initial findings from simulation of the fuzzy inference system show that application of fuzzy logic to subsea intervention operations can be valuable for development of asset safety related aspects, such as for consequence analysis, operational safety, and development of safety philosophies. © 2015 Taylor \& Francis Group, London."",
    keywords = ""Computer circuits; Decision support systems; Fuzzy logic; Fuzzy systems; Membership functions; Philosophical aspects; Reliability; Remotely operated vehicles; Repair; Consequence analysis; Decision supports; Fuzzy inference systems; Input variables; Operational safety; Repair operations; Sub-sea operations; Underwater vehicles; Fuzzy inference"",
    publisher = ""CRC Press/Balkema"",
    isbn = ""978-113802879-1"",
    language = ""English"",
    abbrev_source_title = ""Saf. Reliab. Complex. Eng. syst. - Proc. Eur. Saf. Reliab. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 7; Conference name: 25th European Safety and Reliability Conference, ESREL 2015; Conference date: 7 September 2015 through 10 September 2015; Conference code: 139809""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2015	 Application of fuzzy logic for safe autonomous subsea IMR operations	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010981&doi=10.1201%2fb19094-58&partnerID=40&md5=474ee0be547665f0ae4e162f4f16067e	CRC Press/Balkema	nan; References
8	TestNN	Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuvers	For manual driving, human drivers always look both ahead and behind to make the proper decision for assuring driving safety. It is the purpose of this paper to design an autonomous intelligent cruise control (AICC) which mimics this human driving behavior. The proposed AICC law uses information not only from the immediate predecessor but also from the immediate follower to make the proper control decision. Constant time headway safety policy is used in the design and analysis of AICC law. The individual vehicle stability, and platoon stability in both directions (backward and forward) are guaranteed by the proposed AICC law. In addition, the proposed controller can also be used to operate vehicles with constant spacing safety policy in a platoon. The platoon stability is achieved by the proposed controller (which uses only information from the immediate predecessor and follower) without any preview information from the platoon leader.		C.C. Chien; Youping Zhang; C.Y. Cheng	Proceedings of 1995 American Control Conference - ACC'95	https://doi.org/10.1109/ACC.1995.532085	"1.C. C. Chien and P. Ioannou, ""Automatic vehicle following"", Proc. American Control Conference, pp. 1748-1752, 1992. View Article  Google Scholar; 2.P. Ioannou and C. C. Chien, ""Autonomous intelligent cruise control"", IEEE Transactions on Vehicular Technology, vol. 42, pp. 657-672, Nov. 1993. View Article  Google Scholar; 3.D. Swaroop, J. K. Hedrick, C. C. Chien and P. Ioannou, ""A comparision of spacing and headway control laws for automatically controlled vehicle"", Journal of Vehicle System Dynamics, 1994. CrossRef  Google Scholar; 4.C. C. Chien and P. Ioannou, ""Michael Lai. Entrainment and vehicle following controller design for autonomous intelligent vehicle"", Proc. American Control Conference, pp. 6-10, 1994. View Article  Google Scholar; 5.S. Shladover, Operation of automated guideway transit vehicles in dynamically reconfigured trains and platoons, 1979. Google Scholar; 6.S. Sheikholeslam, Control of a class of interconnected nonlinear dynamical system: the platoon problem, 1991. Google Scholar; 7.S. E. Shiadover, ""Longitudinal control of automotive vehicles in close-formation platoons"", ASME Journal of Dynamic System Measurement and Control, vol. 113, pp. 231-241, 1991. CrossRef  Google Scholar; 8.S. E. Shiadover, C. A. Desoer, J. K. Hedrick, M. Tomizuka, J. Walrand, W. B. Zhang, et al., ""Automatic vehicle control developments in the path program"", IEEE Transactions on Vehicular Technology, vol. 40, pp. 114-130, 1991. View Article  Google Scholar; 9.J. K. Hedrick, D. McMahon, V. Narendran and D. Swaroop, ""Longitudinal vehicle controller design for IVHS systems"", Proc. American Control Conference, pp. 3107-3112, 1991. View Article  Google Scholar; 10.Y. T. Yang and B. H. Tingue. A new control approach for platoon operations during vehicle exit/entry. pre-print, 1993.; 11.C. C. Chien and Y. Zhang. Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuversemac. Preprint, 1994."			Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	IEEE	1995	 Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuvers		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
9	TestNN	Autonomous NAS flight control for UAV by fuzzy concept	The autonomous flight control methodology for the Unmanned Aerial Vehicle, applying the Fuzzy Expert Control Concept is discussed. When it comes to the problem of co-existence with the Manned Aircraft in the National Air Space for the UAV, The UAV for the NAS flight is required to carry the same level of control laws and systems integrity as those for the Manned Aircraft. As for the autonomous traffic control in NAS flight, the Fuzzy Expert Concept is applied to control as a core law for both of the steps. First is a decision making step for a change of the flight plan meeting with the needs in the actual traffic situations for the avoidance from intruders, or from an uneasy weather area for example. Second is an action step to carry out the altered flight plan until the point, from where the Flight Management System of the vehicle resumes the control. Those are illustrated with some MATLAB simulation results. The Fuzzy Expert Control Concept is effective and useful, because the conformation of the laws is very practical basing on the Expert Concept, compensating the defects of the Expert System by taking the fussiness of the conditions into consideration to complete the autonomous control, with no leaning time. The UAV for the NAS flight is also referred to have the same level of reliability and safety as the one for the civil transports, with the certification of the vehicle and the qualified ground pilot. Copyright © 2004 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.	Air traffic control; Collision avoidance; Computer simulation; Decision making; Flight dynamics; Fuzzy control; Laws and legislation; Unmanned vehicles; Autonomous control; NAS flight; National Air Space (NAS); Unmanned aerial vehicals (UAV); Aerospace vehicles	Sumita, Junichiro	Collection of Technical Papers - AIAA Guidance, Navigation, and Control Conference			1058 – 1066	"@CONFERENCE{Sumita20041058,
    author = ""Sumita, Junichiro"",
    title = ""Autonomous NAS flight control for UAV by fuzzy concept"",
    year = ""2004"",
    journal = ""Collection of Technical Papers - AIAA Guidance, Navigation, and Control Conference"",
    volume = ""2"",
    pages = ""1058 – 1066"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-19644397580\&partnerID=40\&md5=480b674fe4a27552a8d0c069f5d41f90"",
    affiliations = ""Nishinippon Institute of Technology, Fukuoka-Pref, 1-11 Kanda, Japan"",
    abstract = ""The autonomous flight control methodology for the Unmanned Aerial Vehicle, applying the Fuzzy Expert Control Concept is discussed. When it comes to the problem of co-existence with the Manned Aircraft in the National Air Space for the UAV, The UAV for the NAS flight is required to carry the same level of control laws and systems integrity as those for the Manned Aircraft. As for the autonomous traffic control in NAS flight, the Fuzzy Expert Concept is applied to control as a core law for both of the steps. First is a decision making step for a change of the flight plan meeting with the needs in the actual traffic situations for the avoidance from intruders, or from an uneasy weather area for example. Second is an action step to carry out the altered flight plan until the point, from where the Flight Management System of the vehicle resumes the control. Those are illustrated with some MATLAB simulation results. The Fuzzy Expert Control Concept is effective and useful, because the conformation of the laws is very practical basing on the Expert Concept, compensating the defects of the Expert System by taking the fussiness of the conditions into consideration to complete the autonomous control, with no leaning time. The UAV for the NAS flight is also referred to have the same level of reliability and safety as the one for the civil transports, with the certification of the vehicle and the qualified ground pilot. Copyright © 2004 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved."",
    author_keywords = ""Autonomous Control; Fuzzy Control; NAS Flight; Navigation; UAV"",
    keywords = ""Air traffic control; Collision avoidance; Computer simulation; Decision making; Flight dynamics; Fuzzy control; Laws and legislation; Unmanned vehicles; Autonomous control; NAS flight; National Air Space (NAS); Unmanned aerial vehicals (UAV); Aerospace vehicles"",
    correspondence_address = ""J. Sumita; Nishinippon Institute of Technology, Fukuoka-Pref, 1-11 Kanda, Japan; email: sumita@nishitech.ac.jp"",
    isbn = ""1563476703"",
    language = ""English"",
    abbrev_source_title = ""Collect. Tech. Pap. AIAA Guid. Navig. Control. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: Collection of Technical Papers - AIAA Guidance, Navigation, and Control Conference; Conference date: 16 August 2004 through 19 August 2004; Conference code: 64922""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2004	 Autonomous NAS flight control for UAV by fuzzy concept	https://www.scopus.com/inward/record.uri?eid=2-s2.0-19644397580&partnerID=40&md5=480b674fe4a27552a8d0c069f5d41f90		nan; References; DOI; Publisher
10	TestNN	Autonomous real-time software & systems testing	For theInternet of Things(IoT), for safety in automotive, or for data protection, to be legally compliant requires testing the impact of any actions before allowing them to occur. However, system boundaries change at runtime. When adding a new, previously unknown device to an IoT orchestra, or when an autonomous car meets another, or with truck platooning, the original base system expands and needs being tested before it can do decisions with the potential of affecting harm to humans. This paper explains the theory and outlines the implementation approach a framework for autonomous real-time testing of a software-based system while in operation, with an example from IoT.		ThomasFehlmann; EberhardKranich	IWSM Mensura '17: Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement	https://doi.org/10.1145/3143434.3143444		4-63		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ACM	2017	 Autonomous real-time software & systems testing		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
11	TestNN	Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems	There is a current drive towards enabling the deployment of increasingly autonomous systems in the National Airspace System (NAS). However, shifting the traditional roles and responsibilities between humans and automation for safety critical tasks must be managed carefully, otherwise the current emergent safety properties of the NAS may be disrupted. In this paper, a verification activity to assess the emergent safety properties of a clearly defined, safety critical, operational scenario that possesses tasks that can be fluidly allocated between human and automated agents is conducted. Task allocation role sets were proposed for a human-automation team performing a contingency maneuver in a reduced crew context. A safety critical contingency procedure (engine out on takeoff) was modeled in the Soar cognitive architecture, then translated into the Hybrid Input Output formalism. Verification activities were then performed to determine whether or not the safety properties held over the increasingly autonomous system. The verification activities lead to the development of several key insights regarding the implicit assumptions on agent capability. It subsequently illustrated the usefulness of task annotations associated with specialized requirements (e.g., communication, timing etc.), and demonstrated the feasibility of this approach. © 2016 American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.	Automation; Automated agents; Autonomous systems; National airspace system; Operational scenario; Safety property; Safety requirements; Soar cognitive architectures; Verification activities; Safety engineering	Neogi, Natasha A.	16th AIAA Aviation Technology, Integration, and Operations Conference	https://doi.org/10.2514/6.2016-3594			"@CONFERENCE{Neogi2016,
    author = ""Neogi, Natasha A."",
    title = ""Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems"",
    year = ""2016"",
    journal = ""16th AIAA Aviation Technology, Integration, and Operations Conference"",
    doi = ""10.2514/6.2016-3594"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088771295\&doi=10.2514\%2f6.2016-3594\&partnerID=40\&md5=030db9af785cd1cbeb808707533eb079"",
    affiliations = ""NASA Langley Research Center, Mail Stop 130, Hampton, 23666, VA, United States"",
    abstract = ""There is a current drive towards enabling the deployment of increasingly autonomous systems in the National Airspace System (NAS). However, shifting the traditional roles and responsibilities between humans and automation for safety critical tasks must be managed carefully, otherwise the current emergent safety properties of the NAS may be disrupted. In this paper, a verification activity to assess the emergent safety properties of a clearly defined, safety critical, operational scenario that possesses tasks that can be fluidly allocated between human and automated agents is conducted. Task allocation role sets were proposed for a human-automation team performing a contingency maneuver in a reduced crew context. A safety critical contingency procedure (engine out on takeoff) was modeled in the Soar cognitive architecture, then translated into the Hybrid Input Output formalism. Verification activities were then performed to determine whether or not the safety properties held over the increasingly autonomous system. The verification activities lead to the development of several key insights regarding the implicit assumptions on agent capability. It subsequently illustrated the usefulness of task annotations associated with specialized requirements (e.g., communication, timing etc.), and demonstrated the feasibility of this approach. © 2016 American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Automation; Automated agents; Autonomous systems; National airspace system; Operational scenario; Safety property; Safety requirements; Soar cognitive architectures; Verification activities; Safety engineering"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410440-4"",
    language = ""English"",
    abbrev_source_title = ""Aviat. Technol. Integr. Oper. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 8; Conference name: 16th AIAA Aviation Technology, Integration, and Operations Conference, 2016; Conference date: 13 June 2016 through 17 June 2016; Conference code: 175899; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2016	 Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088771295&doi=10.2514%2f6.2016-3594&partnerID=40&md5=030db9af785cd1cbeb808707533eb079	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
12	TestNN	 Computational methods for the verification of adaptive control systems			Prasanth, R., J. Boskovic and R. Mehra	Signal Processing, Sensor Fusion, and Target Recognition XIII, April 12, 2004 - April 14, 2004 Orlando, FL, United states					Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1		2004				
13	TestNN	Computer-aided design for safe autonomous vehicles	This paper details the design of an autonomous vehicle CAD toolchain, which captures formal descriptions of driving scenarios in order to develop a safety case for an autonomous vehicle (AV). Rather than focus on a particular component of the AV, like adaptive cruise control, the toolchain models the end-to-end dynamics of the AV in a formal way suitable for testing and verification. First, a domain-specific language capable of describing the scenarios that occur in the day-to-day operation of an AV is defined. The language allows the description and composition of traffic participants (e.g., other vehicles and traffic control devices), and the specification of formal correctness requirements. A scenario described in this language is an executable that can be processed by a specification-guided automated test generator (bug hunting), and by an exhaustive reachability tool. The toolchain allows the user to exploit and integrate the strengths of both testing and reachability, in a way not possible when each is run alone. Finally, given a particular execution of the scenario that violates the requirements, a visualization tool can display this counter-example and generate labeled sensor data. The effectiveness of the approach is demonstrated on three autonomous driving scenarios drawn from a collection of 36 scenarios that account for over 95% of accidents nationwide. These case studies demonstrate robustness-guided verification heuristics to reduce analysis time, counterexample visualization for identifying controller bugs in both the discrete decision logic and low-level analog (continuous) dynamics, and identification of modeling errors (e.g., traffic behaviors) that lead to unrealistic environment behavior.		Matthew O'Kelly; Houssam Abbas; Rahul Mangharam	2017 Resilience Week (RWS)	https://doi.org/10.1109/RWEEK.2017.8088654	"1.M. Althoff and J.M. Dolan, ""Reachability computation of low-order models for the safety verification of high-order road vehicle models"", American Control Conference (ACC) 2012, pp. 3559-3566, 2012. CrossRef  Google Scholar; 2.M. Althoff and J.M. Dolan, ""Online verification of automated road vehicles using reachability analysis"", IEEE Transactions on Robotics, vol. 30, no. 4, pp. 903-918, 2014. View Article  Google Scholar; 3.R. Alur, C. Courcoubetis, N. Halbwachs, T.A. Henzinger, P.-H. Ho, X. Nicollin, et al., ""The algorithmic analysis of hybrid systems"", Theoretical Computer Science, vol. 138, no. 1, pp. 3-34, 1995. CrossRef  Google Scholar; 4.Y.S.R. Annapureddy and G.E. Fainekos, ""Ant colonies for temporal logic falsification of hybrid systems"", Proc. of the 36th Annual Conference of IEEE Industrial Electronics, pp. 91-96, 2010. CrossRef  Google Scholar; 5.W. Damm, H.-J. Peter, J. Rakow and B. Westphal, ""Can we build it: formal synthesis of control strategies for cooperative driver assistance systems"", Mathematical Structures in computer Science, vol. 23, no. 04, pp. 676-725, 2013. CrossRef  Google Scholar; 6.G. Fainekos and G. Pappas, ""Robustness of temporal logic specifications for continuous-time signals"", Theoretical Computer Science, vol. 410, no. 42, pp. 4262-4291, September 2009. CrossRef  Google Scholar; 7.E. Gat, ""On three-layer architectures"" in Artificial Intelligence and Mobile Robots, MIT Press, 1998. Google Scholar; 8.D. Heß, M. Althoff and T. Sattel, ""Formal verification of maneuver automata for parameterized motion primitives"", Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1474-1481, 2014. Google Scholar; 9.S. Kong, S. Gao, W. Chen and E.M. Clarke, ""dreach: Delta-reachability analysis for hybrid systems"", Tools and Algorithms for the Construction and Analysis of Systems — 21st International Conference TACAS 2015, pp. 200-205, 2015. CrossRef  Google Scholar; 10.R. Koymans, ""Specifying real-time properties with metric temporal logic"", Real-Time Systems, vol. 2, no. 4, pp. 255-299, 1990. CrossRef  Google Scholar; 11.S. Linker and M. Hilscher, ""Proof theory of a multi-lane spatial logic"", International Colloquium on Theoretical Aspects of Computing, pp. 231-248, 2013. CrossRef  Google Scholar; 12.S.M. Loos, A. Platzer and L. Nistor, ""Adaptive cruise control: Hybrid distributed and now formally verified"", International Symposium on Formal Methods, pp. 42-56, 2011. CrossRef  Google Scholar; 13.A. Mehra, W.-L. Ma, F. Berg, P. Tabuada, J.W. Grizzle and A.D. Ames, ""Adaptive cruise control: Experimental validation of advanced controllers on scale-model cars"", 2015 American Control Conference (ACC), pp. 1411-1418, 2015. CrossRef  Google Scholar; 14.W.G. Najm, J.D. Smith and M. Yanagisawa, ""Pre-crash scenario typology for crash avoidance research"" in DOT HS, Citeseer, 2007. Google Scholar; 15.Federal automated vehicles policy, September 2016. Google Scholar; 16.M. O'Kelly, H. Abbas, S. Gao, S. Shiraishi, S. Kato and R. Mang-haram, ""Apex: Autonomous vehicle plan verification and execution"", SAE World Congress, vol. 1, Apr 2016. CrossRef  Google Scholar; 17.M. OKelly, H. Abbas and R. Mangharam, ""Computer-aided design for safe autonomous vehicles"", Technical report Scholarly Commons, April 2017. View Article  Google Scholar; 18.B. Paden, S.Z. Yong, D. Yershov and E. Frazzoli, ""A survey of motion planning and control techniques for self-driving urban vehicles"", IEEE Transactions on Intelligent Vehicles, vol. 1, no. 1, pp. 33-55, March 2016. View Article  Google Scholar; 19.T.P. Pavlic, P.A. Sivilotti, A.D. Weide and B.W. Weide, ""Comments on adaptive cruise control: hybrid distributed and now formally verified"", OSU CSE Dept TR22, 2011. Google Scholar; 20.A. Rizaldi and M. Althoff, ""Formalising traffic rules for accountability of autonomous vehicles"", 2015 IEEE 18th International Conference on Intelligent Transportation Systems, pp. 1658-1665, 2015. CrossRef  Google Scholar; 21.O. Stursberg, A. Fehnker, Z. Han and B.H. Krogh, ""Verification of a cruise control system using counterexample-guided search"", Control Engineering Practice, vol. 12, no. 10, pp. 1269-1278, 2004. CrossRef  Google Scholar; 22.C. Urmson, J. Anhalt, D. Bagnell, C. Baker, R. Bittner, M. Clark, J. Dolan, D. Duggins, T. Galatali, C. Geyer et al., ""Autonomous driving in urban environments: Boss and the urban challenge"", Journal of Field Robotics, vol. 25, no. 8, pp. 425-466, 2008. CrossRef  Google Scholar; 23.T. Wongpiromsarn, U. Topcu and R.M. Murray, ""Receding horizon control for temporal logic specifications"", Proceedings of the 13th ACM international conference on Hybrid systems: computation and control, pp. 101-110, 2010. CrossRef  Google Scholar"			Included	Included	new_screen			1	IEEE	2017	 Computer-aided design for safe autonomous vehicles		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
14	TestNN	Convoy active safety technologies Warfighter Experiment I	The operational ability to project and sustain forces in distant, anti-access and area denial environments poses new challenges for combatant commanders. One of the new challenges is the ability to conduct sustainment operations at operationally feasible times and places on the battlefield. Combatant commanders require a sustainment system that is agile, versatile, and survivable throughout the range of military operations and across the spectrum of conflict. A key component of conducting responsive, operationally feasible sustainment operations is the ability to conduct sustainment convoys. Sustainment convoys are critical to providing combatant commanders the right support, at the right time and place, and in the right quantities, across the full range of military operations. The ability to conduct sustainment convoys in a variety of hostile environments require force protection measures that address the enemy threat and protect the Soldier. One cost effective, technically feasible method of increasing the force protection for sustainment convoys is the use of robotic follower technology and autonomous navigation. The Convoy Active Safety Technologies (CAST) system is a driver assist, convoy autopilot technology aimed to address these issues. Warfigher Experiment I, held at A.P. Hill, VA in the fall of 2007, tested the utility of this vehicle following technology not only in measures of system integrity and performance vs. manual driving, but also the physiological effects on the operators themselves. This paper will detail the Warfigher Experiment's methodology, analysis, results and conclusions.	Autonomous agents; Collision avoidance; Cost effectiveness; Robotics; Safety engineering; Technology transfer; Convoy active safety technologies; Situational awareness; Military operations	Schoenherr, Edward; Theisen, Bernard L.; Animashaun, Asisat; Davis, James; Day, L.T.C. Christopher	Proceedings of SPIE - The International Society for Optical Engineering	https://doi.org/10.1117/12.780357			"@CONFERENCE{Schoenherr2008,
    author = ""Schoenherr, Edward and Theisen, Bernard L. and Animashaun, Asisat and Davis, James and Day, L.T.C. Christopher"",
    title = ""Convoy active safety technologies Warfighter Experiment I"",
    year = ""2008"",
    journal = ""Proceedings of SPIE - The International Society for Optical Engineering"",
    volume = ""6962"",
    doi = ""10.1117/12.780357"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349149770\&doi=10.1117\%2f12.780357\&partnerID=40\&md5=928492b85ae608792415eac8c7d56d2b"",
    affiliations = ""U.S. Anny Tank Automotive Research, Development, and Engineering Center, Detroit Arsenal, Warren, MI, United States; Army Research Laboratory, Aberdeen Proving Ground, MD, United States; U.S. Army Combined Arms Support Command, Fort Lee, VA, United States"",
    abstract = ""The operational ability to project and sustain forces in distant, anti-access and area denial environments poses new challenges for combatant commanders. One of the new challenges is the ability to conduct sustainment operations at operationally feasible times and places on the battlefield. Combatant commanders require a sustainment system that is agile, versatile, and survivable throughout the range of military operations and across the spectrum of conflict. A key component of conducting responsive, operationally feasible sustainment operations is the ability to conduct sustainment convoys. Sustainment convoys are critical to providing combatant commanders the right support, at the right time and place, and in the right quantities, across the full range of military operations. The ability to conduct sustainment convoys in a variety of hostile environments require force protection measures that address the enemy threat and protect the Soldier. One cost effective, technically feasible method of increasing the force protection for sustainment convoys is the use of robotic follower technology and autonomous navigation. The Convoy Active Safety Technologies (CAST) system is a driver assist, convoy autopilot technology aimed to address these issues. Warfigher Experiment I, held at A.P. Hill, VA in the fall of 2007, tested the utility of this vehicle following technology not only in measures of system integrity and performance vs. manual driving, but also the physiological effects on the operators themselves. This paper will detail the Warfigher Experiment's methodology, analysis, results and conclusions."",
    author_keywords = ""Autonomous; Convoy; Follower; Mobility; Obstacle avoidance; Situational awareness; Sustainment"",
    keywords = ""Autonomous agents; Collision avoidance; Cost effectiveness; Robotics; Safety engineering; Technology transfer; Convoy active safety technologies; Situational awareness; Military operations"",
    correspondence_address = ""E. Schoenherr; U.S. Anny Tank Automotive Research, Development, and Engineering Center, Detroit Arsenal, Warren, MI, United States; email: edward.schoenherr@gmail.com"",
    issn = ""0277786X"",
    isbn = ""978-081947153-6"",
    coden = ""PSISD"",
    language = ""English"",
    abbrev_source_title = ""Proc SPIE Int Soc Opt Eng"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 3; Conference name: Unmanned Systems Technology X; Conference date: 17 March 2008 through 20 March 2008; Conference code: 72124""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2008	 Convoy active safety technologies Warfighter Experiment I	https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349149770&doi=10.1117%2f12.780357&partnerID=40&md5=928492b85ae608792415eac8c7d56d2b		nan; References; Pages; Publisher
15	TestNN	DeepXplore:Automated Whitebox Testing of Deep Learning Systems	Over the past few years, Deep Learning (DL) has made tremendous progress, achieving or surpassing human-level performance for a diverse set of tasks, including image classification, speech recognition, and playing games like Go. These advances have led to widespread adoption and deployment of DL in security- and safety-critical systems, such as selfdriving cars, malware detection, and aircraft collision avoidance systems.		KexinPei; YinzhiCao; JunfengYang; SumanJana	GetMobile: Mobile Computing and Communications	https://doi.org/10.1145/3308755.3308767		6-38		Included	Included	new_screen			1	ACM	2017	 DeepXplore: Automated Whitebox Testing of Deep Learning Systems		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
16	TestNN	Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures	In this paper, we evaluate the reliability of the You Only Look Once (YOLO) object detection framework. We have exposed to controlled neutron beams GPUs designed with three different architectures (Kepler, Maxwell, and Pascal) running Darknet, a Convolutional Neural Network for automotive applications, detecting objects in both Caltech and Visual Object Classes data sets. By analyzing the neural network corrupted output, we can distinguish between tolerable errors and critical errors, i.e., errors that could impact on real-time system execution.Additionally, we propose an Algorithm-Based Fault-Tolerance (ABFT) strategy to apply to the matrix multiplication kernels of neural networks able to detect and correct 50% to 60% of radiation induced corruptions. We experimentally validate our hardening solution and compare its efficiency and efficacy with the available ECC. © 2017 IEEE.	Errors; Fault tolerance; Graphics processing unit; Interactive computer systems; Network architecture; Neural networks; Object recognition; Program processors; Radiation hardening; Real time systems; Algorithm based fault tolerance; Automotive applications; Convolutional neural network; Detecting objects; Detection framework; Its efficiencies; MAtrix multiplication; Radiation-induced; Object detection	Santos, Fernando Fernandes Dos; Draghetti, Lucas; Weigel, Lucas; Carro, Luigi; Navaux, Philippe; Rech, Paolo	Proceedings - 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017	https://doi.org/10.1109/DSN-W.2017.47		169 – 176	"@CONFERENCE{Santos2017169,
    author = ""Santos, Fernando Fernandes Dos and Draghetti, Lucas and Weigel, Lucas and Carro, Luigi and Navaux, Philippe and Rech, Paolo"",
    title = ""Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures"",
    year = ""2017"",
    journal = ""Proceedings - 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017"",
    pages = ""169 – 176"",
    doi = ""10.1109/DSN-W.2017.47"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031755400\&doi=10.1109\%2fDSN-W.2017.47\&partnerID=40\&md5=5c935116899adc89921a3b353c3fd38d"",
    affiliations = ""Instituto de Informatica, Universidade Federal Do Rio Grande Do sul, Porto Alegre, Brazil"",
    abstract = ""In this paper, we evaluate the reliability of the You Only Look Once (YOLO) object detection framework. We have exposed to controlled neutron beams GPUs designed with three different architectures (Kepler, Maxwell, and Pascal) running Darknet, a Convolutional Neural Network for automotive applications, detecting objects in both Caltech and Visual Object Classes data sets. By analyzing the neural network corrupted output, we can distinguish between tolerable errors and critical errors, i.e., errors that could impact on real-time system execution.Additionally, we propose an Algorithm-Based Fault-Tolerance (ABFT) strategy to apply to the matrix multiplication kernels of neural networks able to detect and correct 50\% to 60\% of radiation induced corruptions. We experimentally validate our hardening solution and compare its efficiency and efficacy with the available ECC. © 2017 IEEE."",
    keywords = ""Errors; Fault tolerance; Graphics processing unit; Interactive computer systems; Network architecture; Neural networks; Object recognition; Program processors; Radiation hardening; Real time systems; Algorithm based fault tolerance; Automotive applications; Convolutional neural network; Detecting objects; Detection framework; Its efficiencies; MAtrix multiplication; Radiation-induced; Object detection"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153862272-8"",
    language = ""English"",
    abbrev_source_title = ""Proc. - Annu. IEEE/IFIP Int. Conf. Dependable Syst. Networks Workshops, DSN-W"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 59; Conference name: 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017; Conference date: 26 June 2017 through 29 June 2017; Conference code: 130335""
}
"	Included	Included	new_screen			1	Scopus	2017	 Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031755400&doi=10.1109%2fDSN-W.2017.47&partnerID=40&md5=5c935116899adc89921a3b353c3fd38d	Institute of Electrical and Electronics Engineers Inc.	nan; References
17	TestNN	Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study	One of the most challenging factors in the development of autonomous vehicles and advanced driver assistance systems is the imitation of an expert driver system which is the observer and interpreter of the technical system in the related driving scenario. To achieve an expert human-like situational understanding and decision making may be an important feature to fulfill the necessary active safety requirements. In this paper, an exploratory study on a multimodal adaptive driver assistance system is presented. The main goal is to determine the human driver's attention and authority level in a cognitive model and to trigger the timely warnings according to his/her driving intents and driving skills with respect to the possible driving situation and hazard scenarios. In the previous studies, a fairly restrictive vision-based driver assistance system has been deployed to detect lane departure, blind-spot and to monitor following distance, headway time. This vision-based driver assistance system considers the driver's driving performance metric sampled during the longitudinal and lateral vehicle control tasks as well as the processed information about the surrounding traffic environment consisting of the interactions with the other vehicles and the road situations. The presented active safety system models the driving task in a cognitive architecture and assesses the cognition of the human driver by modeling the situation awareness of the driver by using fuzzy sets. Each fuzzy set simply represents the expert driver's perception in both of the longitudinal and lateral traffic. The presented system evaluates the driver's driving skills and attention level by comparing the expert and human driver's reactions suited in a finite set of decision and maneuvering task. In case of hazard analysis, the system triggers timely warnings pointing the driver's attention at the lateral or longitudinal maneuvering tasks depending on the interpreted situation. Introductory experiments are performed with a limited number of participants, the test driving data including the driver's perception and reaction to the surrounding vehicles and traffic situations are collected by the use of a vehicle simulator. And the presented multimodal adaptive driver assistance system is evaluated by the simulator. The preliminary results seem to be promising. Copyright © 2012 by ASME.	Active safety systems; Automobile simulators; Cognitive systems; Control system synthesis; Fluid mechanics; Fuzzy sets; Hazards; Maneuverability; Systems analysis; Autonomous Vehicles; Cognitive architectures; Driver assistance system; Driving performance; Exploratory studies; Processed information; Situation awareness; Traffic environment; Automobile drivers	Uluer, Pinar; Goçmenoglu, Can; Acarman, Tankut	ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012	https://doi.org/10.1115/ESDA2012-82675		803 – 811	"@CONFERENCE{Uluer2012803,
    author = ""Uluer, Pinar and Goçmenoglu, Can and Acarman, Tankut"",
    title = ""Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study"",
    year = ""2012"",
    journal = ""ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012"",
    volume = ""2"",
    pages = ""803 – 811"",
    doi = ""10.1115/ESDA2012-82675"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883892834\&doi=10.1115\%2fESDA2012-82675\&partnerID=40\&md5=de6337a976edd5c03a53ecc03d951d97"",
    affiliations = ""Galatasaray University, Computer Engineering Department, Istanbul, Turkey"",
    abstract = ""One of the most challenging factors in the development of autonomous vehicles and advanced driver assistance systems is the imitation of an expert driver system which is the observer and interpreter of the technical system in the related driving scenario. To achieve an expert human-like situational understanding and decision making may be an important feature to fulfill the necessary active safety requirements. In this paper, an exploratory study on a multimodal adaptive driver assistance system is presented. The main goal is to determine the human driver's attention and authority level in a cognitive model and to trigger the timely warnings according to his/her driving intents and driving skills with respect to the possible driving situation and hazard scenarios. In the previous studies, a fairly restrictive vision-based driver assistance system has been deployed to detect lane departure, blind-spot and to monitor following distance, headway time. This vision-based driver assistance system considers the driver's driving performance metric sampled during the longitudinal and lateral vehicle control tasks as well as the processed information about the surrounding traffic environment consisting of the interactions with the other vehicles and the road situations. The presented active safety system models the driving task in a cognitive architecture and assesses the cognition of the human driver by modeling the situation awareness of the driver by using fuzzy sets. Each fuzzy set simply represents the expert driver's perception in both of the longitudinal and lateral traffic. The presented system evaluates the driver's driving skills and attention level by comparing the expert and human driver's reactions suited in a finite set of decision and maneuvering task. In case of hazard analysis, the system triggers timely warnings pointing the driver's attention at the lateral or longitudinal maneuvering tasks depending on the interpreted situation. Introductory experiments are performed with a limited number of participants, the test driving data including the driver's perception and reaction to the surrounding vehicles and traffic situations are collected by the use of a vehicle simulator. And the presented multimodal adaptive driver assistance system is evaluated by the simulator. The preliminary results seem to be promising. Copyright © 2012 by ASME."",
    keywords = ""Active safety systems; Automobile simulators; Cognitive systems; Control system synthesis; Fluid mechanics; Fuzzy sets; Hazards; Maneuverability; Systems analysis; Autonomous Vehicles; Cognitive architectures; Driver assistance system; Driving performance; Exploratory studies; Processed information; Situation awareness; Traffic environment; Automobile drivers"",
    isbn = ""978-079184485-4"",
    language = ""English"",
    abbrev_source_title = ""ASME Bienn. Conf. Eng. Syst. Des. Anal., ESDA"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012; Conference date: 2 July 2012 through 4 July 2012; Conference code: 99242""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2012	 Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883892834&doi=10.1115%2fESDA2012-82675&partnerID=40&md5=de6337a976edd5c03a53ecc03d951d97		nan; References; Publisher
18	TestNN	Guaranteed safe online learning via reachability: Tracking a ground target using a quadrotor	While machine learning techniques have become popular tools in the design of autonomous systems, the asymptotic nature of their performance guarantees means that they should not be used in scenarios in which safety and robustness are critical for success. By pairing machine learning algorithms with rigorous safety analyses, such as Hamilton-Jacobi-Isaacs (HJI) reachability, this limitation can be overcome. Guaranteed Safe Online Learning via Reachability (GSOLR) is a framework which combines HJI reachability with general machine learning techniques, allowing for the design of robotic systems which demonstrate both high performance and guaranteed safety. In this paper we show how the GSOLR framework can be applied to a target tracking problem, in which an observing quadrotor helicopter must keep a target ground vehicle with unknown (but bounded) dynamics inside its field of view at all times, while simultaneously attempting to build a motion model of the target. The resulting algorithm was implemented on board the Stanford Testbed of Autonomous Rotorcraft for Multi-Agent Control, and was compared to a naive safety-only algorithm and a learning-only algorithm. Experimental results illustrate the success of the GSOLR algorithm, even under scenarios in which the machine learning algorithm performed poorly (and would otherwise lead to unsafe actions), thus demonstrating the power of this technique. © 2012 IEEE.	Aircraft detection; E-learning; Learning systems; Multi agent systems; Online systems; Robotics; Autonomous rotorcrafts; Autonomous systems; Hamilton-Jacobi-Isaacs; Machine learning techniques; Multiagent control; Performance guarantees; Quadrotor helicopter; Safety analysis; Learning algorithms	Gillula, Jeremy H.; Tomlin, Claire J.	Proceedings - IEEE International Conference on Robotics and Automation	https://doi.org/10.1109/ICRA.2012.6225136		2723 – 2730	"@CONFERENCE{Gillula20122723,
    author = ""Gillula, Jeremy H. and Tomlin, Claire J."",
    title = ""Guaranteed safe online learning via reachability: Tracking a ground target using a quadrotor"",
    year = ""2012"",
    journal = ""Proceedings - IEEE International Conference on Robotics and Automation"",
    pages = ""2723 – 2730"",
    doi = ""10.1109/ICRA.2012.6225136"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864441922\&doi=10.1109\%2fICRA.2012.6225136\&partnerID=40\&md5=dd36cc0c299b0731245592321a6090a2"",
    affiliations = ""Computer Science Department, Stanford University, Stanford, CA 94305-4035, United States; Department of Electrical Engineering and Computer Sciences, UC Berkeley, Berkeley, CA 94720-1770, United States"",
    abstract = ""While machine learning techniques have become popular tools in the design of autonomous systems, the asymptotic nature of their performance guarantees means that they should not be used in scenarios in which safety and robustness are critical for success. By pairing machine learning algorithms with rigorous safety analyses, such as Hamilton-Jacobi-Isaacs (HJI) reachability, this limitation can be overcome. Guaranteed Safe Online Learning via Reachability (GSOLR) is a framework which combines HJI reachability with general machine learning techniques, allowing for the design of robotic systems which demonstrate both high performance and guaranteed safety. In this paper we show how the GSOLR framework can be applied to a target tracking problem, in which an observing quadrotor helicopter must keep a target ground vehicle with unknown (but bounded) dynamics inside its field of view at all times, while simultaneously attempting to build a motion model of the target. The resulting algorithm was implemented on board the Stanford Testbed of Autonomous Rotorcraft for Multi-Agent Control, and was compared to a naive safety-only algorithm and a learning-only algorithm. Experimental results illustrate the success of the GSOLR algorithm, even under scenarios in which the machine learning algorithm performed poorly (and would otherwise lead to unsafe actions), thus demonstrating the power of this technique. © 2012 IEEE."",
    keywords = ""Aircraft detection; E-learning; Learning systems; Multi agent systems; Online systems; Robotics; Autonomous rotorcrafts; Autonomous systems; Hamilton-Jacobi-Isaacs; Machine learning techniques; Multiagent control; Performance guarantees; Quadrotor helicopter; Safety analysis; Learning algorithms"",
    correspondence_address = ""J.H. Gillula; Computer Science Department, Stanford University, Stanford, CA 94305-4035, United States; email: jgillula@cs.stanford.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10504729"",
    isbn = ""978-146731403-9"",
    coden = ""PIIAE"",
    language = ""English"",
    abbrev_source_title = ""Proc IEEE Int Conf Rob Autom"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 68; Conference name: 2012 IEEE International Conference on Robotics and Automation, ICRA 2012; Conference date: 14 May 2012 through 18 May 2012; Conference code: 115022""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2012	 Guaranteed safe online learning via reachability: tracking a ground target using a quadrotor	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864441922&doi=10.1109%2fICRA.2012.6225136&partnerID=40&md5=dd36cc0c299b0731245592321a6090a2	Institute of Electrical and Electronics Engineers Inc.	nan; References
19	TestNN	Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles	DISTRIBUTION STATEMENT A; APPROVAL FOR PUBLIC RELEASE DISTRIBUTION IS UNLIMITED. A gap currently exists in the industry's ability to carry out safe, rigorous testing of autonomous unmanned vehicles (AUVs). In 2013, the Test Resource Management Center (TRMC) initiated an effort to design an infrastructure for carrying out complex and safe tests of AUVs under the Safe Testing of Autonomy in Complex Environments (TACE) program. The TACE infrastructure watches over the system under test's (SUT) autonomous decisions to assure that the SUT does not violate safety constraints during a test. TACE also provides complex, interactive, stimulation to the SUT autonomy necessary to assess SUT performance. To reduce cost and help increase safety during a test, the stimulation of the autonomy must often be synthetic, such as simulating other vehicles in the same test as the SUT. Additionally, a vendor may wish to test live autonomous systems interacting with simulated cooperative systems, allowing autonomous cooperative behavior to be tested without the risk and expense of having a larger number of SUTs. This paper will detail the software written to simulate autonomous agents, including communications between live and virtual autonomous agents. TRMC's Test and Training Enabling Architecture (TENA) was used to handle the networking layer, while the Naval Air Systems Command's (NAVAIR) Joint Integrated Mission Model (JIMM) was used to simulate the battlespace environment and maintain ground truth. The Johns Hopkins University Applied Physics Laboratory (JHUAPL)-developed Autonomy Tool Kit (ATK) was used as the autonomy engine driving both the live SUT and the virtual cooperative agents. © Copyright 2015, SISO, Inc.	Ability testing; Autonomous underwater vehicles; Behavioral research; Integration testing; Interoperability; Microwave circuits; Network layers; Safety engineering; Software agents; Software testing; Supersonic aerodynamics; Unmanned aerial vehicles (UAV); Unmanned vehicles; Vehicles; Autonomy; Hard-ware-in-the-loop; Mission models; Safe testings; TACE; Virtual agent; Autonomous agents	John, Brendan A.	2015 Fall Simulation Interoperability Workshop, SIW 2015				"@CONFERENCE{John2015,
    author = ""John, Brendan A."",
    title = ""Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles"",
    year = ""2015"",
    journal = ""2015 Fall Simulation Interoperability Workshop, SIW 2015"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964054299\&partnerID=40\&md5=476e20cdf98d6819103711a7d20c757a"",
    affiliations = ""Johns Hopkins University, Applied Physics Laboratory, 11100 Johns Hopkins Rd, Laurel, 20723, MD, United States"",
    abstract = ""DISTRIBUTION STATEMENT A; APPROVAL FOR PUBLIC RELEASE DISTRIBUTION IS UNLIMITED. A gap currently exists in the industry's ability to carry out safe, rigorous testing of autonomous unmanned vehicles (AUVs). In 2013, the Test Resource Management Center (TRMC) initiated an effort to design an infrastructure for carrying out complex and safe tests of AUVs under the Safe Testing of Autonomy in Complex Environments (TACE) program. The TACE infrastructure watches over the system under test's (SUT) autonomous decisions to assure that the SUT does not violate safety constraints during a test. TACE also provides complex, interactive, stimulation to the SUT autonomy necessary to assess SUT performance. To reduce cost and help increase safety during a test, the stimulation of the autonomy must often be synthetic, such as simulating other vehicles in the same test as the SUT. Additionally, a vendor may wish to test live autonomous systems interacting with simulated cooperative systems, allowing autonomous cooperative behavior to be tested without the risk and expense of having a larger number of SUTs. This paper will detail the software written to simulate autonomous agents, including communications between live and virtual autonomous agents. TRMC's Test and Training Enabling Architecture (TENA) was used to handle the networking layer, while the Naval Air Systems Command's (NAVAIR) Joint Integrated Mission Model (JIMM) was used to simulate the battlespace environment and maintain ground truth. The Johns Hopkins University Applied Physics Laboratory (JHUAPL)-developed Autonomy Tool Kit (ATK) was used as the autonomy engine driving both the live SUT and the virtual cooperative agents. © Copyright 2015, SISO, Inc."",
    author_keywords = ""Autonomy; Hardware in the Loop; Mission Modeling; Safe Testing; TACE; Unmanned Aerial Vehicles; Virtual Agents"",
    keywords = ""Ability testing; Autonomous underwater vehicles; Behavioral research; Integration testing; Interoperability; Microwave circuits; Network layers; Safety engineering; Software agents; Software testing; Supersonic aerodynamics; Unmanned aerial vehicles (UAV); Unmanned vehicles; Vehicles; Autonomy; Hard-ware-in-the-loop; Mission models; Safe testings; TACE; Virtual agent; Autonomous agents"",
    correspondence_address = ""B.A. John; Johns Hopkins University, Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Rd, 20723, United States; email: brendan.john@jhuapl.edu"",
    publisher = ""SISO - Simulation Interoperability Standards Organization"",
    language = ""English"",
    abbrev_source_title = ""Fall Simul. Interoper. Workshop, SIW"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: 2015 Fall Simulation Interoperability Workshop, SIW 2015; Conference date: 31 August 2015 through 4 September 2015; Conference code: 118772""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2015	 Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964054299&partnerID=40&md5=476e20cdf98d6819103711a7d20c757a	SISO - Simulation Interoperability Standards Organization	nan; References; Pages; DOI
20	TestNN	Intelligent sensor attack detection and identification for automotive cyber-physical systems	This paper addresses the problem of detection and identification of the sensor attacks when most sensors are attacked. Sensors can play a key role to improve safety and convenience in automotive Cyber-Physical Systems (CPS). A dramatic increase in connectivity and openness of the automotive CPS brings high security risks. If multiple and heterogeneous sensors equipped for braking and steering provides false sensing information for their controllers under deception attacks, it might cause catastrophic situations during driving. If the existing machine learning approaches are applied for sensor attacks while the majority of sensors is attacked, it cannot guarantee to identify deceptions as cyber-physical attacks. To address this problem, we propose an intelligent sensor attack detection and identification method based on Deep Neural Network (DNN) techniques, called deep learning, without a prior knowledge about the deception attacks modifying sensing data in time. We investigate an autonomous vehicle with Inertial Measurement Unit (IMU) and wheel encoder sensors under conditions of uncertainty and nonlinearity during driving. We firstly identify all possible attacks category on the sensors of it, choose what model to use and then systematically design its architecture on which the performance of deep learning highly depends. We train and then validate the proposed method's performance on real measurement data obtained from an unmanned ground vehicle. Finally, we show analytically the superiority of our method in terms of accuracy, precision, and computation time, including the worst situation where two among three sensors are simultaneously attacked. © 2017 IEEE.	Cybersecurity; Deep neural networks; Embedded systems; Intelligent control; Intelligent systems; Intelligent vehicle highway systems; Uncertainty analysis; Attack detection; Automotive cybe-physical system; Automotives; Cybe-physical systems; Cyber-physical systems; Detection and identifications; Gated recurrent unit; Heterogeneous sensors; Intelligent sensors; Performance; Cyber Physical System	Shin, Jongho; Baek, Youngmi; Eun, Yongsoon; Son, Sang Hyuk	2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings	https://doi.org/10.1109/SSCI.2017.8280915		1 – 8	"@CONFERENCE{Shin20171,
    author = ""Shin, Jongho and Baek, Youngmi and Eun, Yongsoon and Son, Sang Hyuk"",
    title = ""Intelligent sensor attack detection and identification for automotive cyber-physical systems"",
    year = ""2017"",
    journal = ""2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings"",
    volume = ""2018-January"",
    pages = ""1 – 8"",
    doi = ""10.1109/SSCI.2017.8280915"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046095781\&doi=10.1109\%2fSSCI.2017.8280915\&partnerID=40\&md5=f87d334210e368e9056ab8cf748dc05a"",
    affiliations = ""Department of Information and Communication Engineering, DGIST, Daegu, South Korea"",
    abstract = ""This paper addresses the problem of detection and identification of the sensor attacks when most sensors are attacked. Sensors can play a key role to improve safety and convenience in automotive Cyber-Physical Systems (CPS). A dramatic increase in connectivity and openness of the automotive CPS brings high security risks. If multiple and heterogeneous sensors equipped for braking and steering provides false sensing information for their controllers under deception attacks, it might cause catastrophic situations during driving. If the existing machine learning approaches are applied for sensor attacks while the majority of sensors is attacked, it cannot guarantee to identify deceptions as cyber-physical attacks. To address this problem, we propose an intelligent sensor attack detection and identification method based on Deep Neural Network (DNN) techniques, called deep learning, without a prior knowledge about the deception attacks modifying sensing data in time. We investigate an autonomous vehicle with Inertial Measurement Unit (IMU) and wheel encoder sensors under conditions of uncertainty and nonlinearity during driving. We firstly identify all possible attacks category on the sensors of it, choose what model to use and then systematically design its architecture on which the performance of deep learning highly depends. We train and then validate the proposed method's performance on real measurement data obtained from an unmanned ground vehicle. Finally, we show analytically the superiority of our method in terms of accuracy, precision, and computation time, including the worst situation where two among three sensors are simultaneously attacked. © 2017 IEEE."",
    author_keywords = ""Attack detection; Automotive cyber-physical systems; Gated Recurrent Unit; Heterogeneous sensors; Long Short-Term Memory"",
    keywords = ""Cybersecurity; Deep neural networks; Embedded systems; Intelligent control; Intelligent systems; Intelligent vehicle highway systems; Uncertainty analysis; Attack detection; Automotive cybe-physical system; Automotives; Cybe-physical systems; Cyber-physical systems; Detection and identifications; Gated recurrent unit; Heterogeneous sensors; Intelligent sensors; Performance; Cyber Physical System"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153862725-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE Symp. Ser. Comput. Intell., SSCI - Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 28; Conference name: 2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017; Conference date: 27 November 2017 through 1 December 2017; Conference code: 134337""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2018	 Intelligent sensor attack detection and identification for automotive cyber-physical systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046095781&doi=10.1109%2fSSCI.2017.8280915&partnerID=40&md5=f87d334210e368e9056ab8cf748dc05a	Institute of Electrical and Electronics Engineers Inc.	nan; References
21	TestNN	Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical & Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system. © 2017 IEEE.	Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment	Khastgir, Siddartha; Sivencrona, Hakan; Dhadyalla, Gunwant; Billing, Peter; Birrell, Stewart; Jennings, Paul	IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC	https://doi.org/10.1109/ITSC.2017.8317868		1 – 6	"@CONFERENCE{Khastgir20171,
    author = ""Khastgir, Siddartha and Sivencrona, Hakan and Dhadyalla, Gunwant and Billing, Peter and Birrell, Stewart and Jennings, Paul"",
    title = ""Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles"",
    year = ""2017"",
    journal = ""IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC"",
    volume = ""2018-March"",
    pages = ""1 – 6"",
    doi = ""10.1109/ITSC.2017.8317868"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261765\&doi=10.1109\%2fITSC.2017.8317868\&partnerID=40\&md5=95943814807438cbe7f8afe9498c3e48"",
    affiliations = ""WMG, University of Warwick Coventry, United Kingdom; Qamcom Research and Technology AB, Göteborg, Sweden"",
    abstract = ""Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical \& Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system. © 2017 IEEE."",
    author_keywords = ""HARA; Hazards; ISO 26262; Tactical decisions"",
    keywords = ""Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment"",
    correspondence_address = ""S. Khastgir; WMG, University of Warwick Coventry, United Kingdom; email: S.Khastgir@warwick.ac.uk"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153861525-6"",
    language = ""English"",
    abbrev_source_title = ""IEEE Conf Intell Transport Syst Proc ITSC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 14; Conference name: 20th IEEE International Conference on Intelligent Transportation Systems, ITSC 2017; Conference date: 16 October 2017 through 19 October 2017; Conference code: 135272; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2018	 Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261765&doi=10.1109%2fITSC.2017.8317868&partnerID=40&md5=95943814807438cbe7f8afe9498c3e48	Institute of Electrical and Electronics Engineers Inc.	nan; References
22	TestNN	Introspective perception: Learning to predict failures in vision systems	As robots aspire for long-term autonomous operations in complex dynamic environments, the ability to reliably take mission-critical decisions in ambiguous situations becomes critical. This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision. We call this self-evaluating capability as introspection. In this paper, we take a small step in this direction and propose a generic framework for introspective behavior in perception systems. Our goal is to learn a model to reliably predict failures in a given system, with respect to a task, directly from input sensor data. We present this in the context of vision-based autonomous MAV flight in outdoor natural environments, and show that it effectively handles uncertain situations. © 2016 IEEE.	Computer vision; Robots; Autonomous operations; Complex dynamics; Generic frameworks; Mission-critical decisions; Natural environments; Perception systems; Situational awareness; Vision systems; Intelligent robots	Daftry, Shreyansh; Zeng, Sam; Bagnell, J. Andrew; Hebert, Martial	IEEE International Conference on Intelligent Robots and Systems	https://doi.org/10.1109/IROS.2016.7759279		1743 – 1750	"@CONFERENCE{Daftry20161743,
    author = ""Daftry, Shreyansh and Zeng, Sam and Bagnell, J. Andrew and Hebert, Martial"",
    title = ""Introspective perception: Learning to predict failures in vision systems"",
    year = ""2016"",
    journal = ""IEEE International Conference on Intelligent Robots and Systems"",
    volume = ""2016-November"",
    pages = ""1743 – 1750"",
    doi = ""10.1109/IROS.2016.7759279"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006345776\&doi=10.1109\%2fIROS.2016.7759279\&partnerID=40\&md5=2054a57ed46dbdd1b91e488a8455c514"",
    affiliations = ""Robotics Institute, Carnegie Mellon University, Pittsburgh, 15213, PA, United States"",
    abstract = ""As robots aspire for long-term autonomous operations in complex dynamic environments, the ability to reliably take mission-critical decisions in ambiguous situations becomes critical. This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision. We call this self-evaluating capability as introspection. In this paper, we take a small step in this direction and propose a generic framework for introspective behavior in perception systems. Our goal is to learn a model to reliably predict failures in a given system, with respect to a task, directly from input sensor data. We present this in the context of vision-based autonomous MAV flight in outdoor natural environments, and show that it effectively handles uncertain situations. © 2016 IEEE."",
    keywords = ""Computer vision; Robots; Autonomous operations; Complex dynamics; Generic frameworks; Mission-critical decisions; Natural environments; Perception systems; Situational awareness; Vision systems; Intelligent robots"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""21530858"",
    isbn = ""978-150903762-9"",
    coden = ""85RBA"",
    language = ""English"",
    abbrev_source_title = ""IEEE Int Conf Intell Rob Syst"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 56; Conference name: 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2016; Conference date: 9 October 2016 through 14 October 2016; Conference code: 125056; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2016	 Introspective perception: Learning to predict failures in vision systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006345776&doi=10.1109%2fIROS.2016.7759279&partnerID=40&md5=2054a57ed46dbdd1b91e488a8455c514	Institute of Electrical and Electronics Engineers Inc.	nan; References
23	TestNN	Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid	Deep neural networks have been widely adopted in recent years, exhibiting impressive performances in several application domains. It has however been shown that they can be fooled by adversarial examples, i.e., images altered by a barely-perceivable adversarial noise, carefully crafted to mislead classification. In this work, we aim to evaluate the extent to which robot-vision systems embodying deep-learning algorithms are vulnerable to adversarial examples, and propose a computationally efficient countermeasure to mitigate this threat, based on rejecting classification of anomalous inputs. We then provide a clearer understanding of the safety properties of deep networks through an intuitive empirical analysis, showing that the mapping learned by such networks essentially violates the smoothness assumption of learning algorithms. We finally discuss the main limitations of this work, including the creation of real-world adversarial examples, and sketch promising research directions. © 2017 IEEE.	Computer vision; Deep neural networks; Computationally efficient; Empirical analysis; Real-world; Robot vision systems; Safety property; Learning algorithms	Melis, Marco; Demontis, Ambra; Biggio, Battista; Brown, Gavin; Fumera, Giorgio; Roli, Fabio	Proceedings - 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017	https://doi.org/10.1109/ICCVW.2017.94		751 – 759	"@CONFERENCE{Melis2017751,
    author = ""Melis, Marco and Demontis, Ambra and Biggio, Battista and Brown, Gavin and Fumera, Giorgio and Roli, Fabio"",
    title = ""Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid"",
    year = ""2017"",
    journal = ""Proceedings - 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017"",
    volume = ""2018-January"",
    pages = ""751 – 759"",
    doi = ""10.1109/ICCVW.2017.94"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046297726\&doi=10.1109\%2fICCVW.2017.94\&partnerID=40\&md5=d3daf5b7ac861edde196b1c71ff85756"",
    affiliations = ""Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Pluribus One, Italy; School of Computer Science, University of Manchester, United Kingdom"",
    abstract = ""Deep neural networks have been widely adopted in recent years, exhibiting impressive performances in several application domains. It has however been shown that they can be fooled by adversarial examples, i.e., images altered by a barely-perceivable adversarial noise, carefully crafted to mislead classification. In this work, we aim to evaluate the extent to which robot-vision systems embodying deep-learning algorithms are vulnerable to adversarial examples, and propose a computationally efficient countermeasure to mitigate this threat, based on rejecting classification of anomalous inputs. We then provide a clearer understanding of the safety properties of deep networks through an intuitive empirical analysis, showing that the mapping learned by such networks essentially violates the smoothness assumption of learning algorithms. We finally discuss the main limitations of this work, including the creation of real-world adversarial examples, and sketch promising research directions. © 2017 IEEE."",
    keywords = ""Computer vision; Deep neural networks; Computationally efficient; Empirical analysis; Real-world; Robot vision systems; Safety property; Learning algorithms"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153861034-3"",
    language = ""English"",
    abbrev_source_title = ""Proc. - IEEE Int. Conf. Comput. Vis. Workshops, ICCVW"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 59; Conference name: 16th IEEE International Conference on Computer Vision Workshops, ICCVW 2017; Conference date: 22 October 2017 through 29 October 2017; Conference code: 134301; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	 Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046297726&doi=10.1109%2fICCVW.2017.94&partnerID=40&md5=d3daf5b7ac861edde196b1c71ff85756	Institute of Electrical and Electronics Engineers Inc.	nan; References
24	TestNN	Machine learning and deep neural network - Artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation	Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile & V-model, where test & validation (T&V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning & deep neural network (AI-core) for lab & real-world T&V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T&V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T&V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T&V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous. © 2017 IEEE.	Advanced driver assistance systems; Automotive industry; Autonomous vehicles; Deep neural networks; Verification; Virtual reality; Advanced driver assistance system system; AI-core; Autonomous Vehicles; Efficient; High quality; Machine-learning; Simulation; Test and validation; Test scenario; Test validation; Automobile drivers	Vishnukumar, Harsha Jakkanahalli; Butting, Bjorn; Muller, Christian; Sax, Eric	2017 Intelligent Systems Conference, IntelliSys 2017	https://doi.org/10.1109/IntelliSys.2017.8324372		714 – 721	"@CONFERENCE{Vishnukumar2017714,
    author = ""Vishnukumar, Harsha Jakkanahalli and Butting, Bjorn and Muller, Christian and Sax, Eric"",
    title = ""Machine learning and deep neural network - Artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation"",
    year = ""2017"",
    journal = ""2017 Intelligent Systems Conference, IntelliSys 2017"",
    volume = ""2018-January"",
    pages = ""714 – 721"",
    doi = ""10.1109/IntelliSys.2017.8324372"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051091232\&doi=10.1109\%2fIntelliSys.2017.8324372\&partnerID=40\&md5=5e1900c49e38ecc92460e1f3dfa9d681"",
    affiliations = ""Department of Measurement and Test Technology, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Manager Test and Measurement Systems, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Direct. Measurement and Test Technology, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Institut für Technik der Informationsverarbeitung (ITIV), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany"",
    abstract = ""Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile \& V-model, where test \& validation (T\&V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning \& deep neural network (AI-core) for lab \& real-world T\&V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T\&V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T\&V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T\&V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous. © 2017 IEEE."",
    author_keywords = ""ADAS systems; AI-core; Artificial Intelligence; Autonomous Vehicles; Efficient; High quality; Machine Learning; Simulation; Test and Validation"",
    keywords = ""Advanced driver assistance systems; Automotive industry; Autonomous vehicles; Deep neural networks; Verification; Virtual reality; Advanced driver assistance system system; AI-core; Autonomous Vehicles; Efficient; High quality; Machine-learning; Simulation; Test and validation; Test scenario; Test validation; Automobile drivers"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-150906435-9"",
    language = ""English"",
    abbrev_source_title = ""Intell. Syst. Conf., IntelliSys"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 73; Conference name: 2017 Intelligent Systems Conference, IntelliSys 2017; Conference date: 7 September 2017 through 8 September 2017; Conference code: 135475""
}
"	Included	Included	new_screen			1	Scopus	2017	 Machine learning and deep neural network - artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051091232&doi=10.1109%2fIntelliSys.2017.8324372&partnerID=40&md5=5e1900c49e38ecc92460e1f3dfa9d681	Institute of Electrical and Electronics Engineers Inc.	nan; References
25	TestNN	 MAR-CPS: Measurable Augmented Reality for Prototyping Cyber-Physical Systems			Omidshafiei, S., A. A. Agha-mohammadi, C. Yu Fan, N. K. Ure, J. P. How, J. Vian and R. Surati	AIAA Infotech@Aerospace Conference, 5-9 Jan. 2015 Reston, VA, USA					Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1		2015				
26	TestNN	Mission reconfiguration based on real-time system reliability assessment	Unmanned Aerial Vehicles (UAVs) must be reliable and have the ability to take appropriate action when some functionality is lost due to failure. Fast system reliability assessment techniques such as the Binary Decision Diagram (BDD) technique can be used as part of the decision making process to decide when the likelihood of the autonomous vehicle successfully performing its intended task becomes unacceptably low and what action needs to be taken to mitigate this situation. A UAV is used in this paper to demonstrate the technique. Its mission objectives are specified and the way that this will be achieved is expressed as a phased mission. If the reliability analysis of this phased mission is acceptable it will go ahead. However the UAV must have the ability to respond to changing conditions. Such changes can occur due to component failures causing loss of functionality or reduced redundancy, changing weather conditions, or the emergence of a threat such as another aircraft in the locality. When these conditions are reported the mission success likelihood is re-evaluated accounting for the new conditions and the number of phases already successfully completed. In the event that this new mission reliability is below the acceptable threshold, reconfiguration is initiated. Mission reconfiguration for a UAV selects a new route, new mission objectives, or to abort the mission and make an emergency landing. The focus of the method presented in this paper is the mission reconfiguration process which is based on optimising the mission reliability under its current conditions and environment. This is demonstrated using a UAV carrying out a search and rescue operation. © 2010 Taylor & Francis Group.	Binary decision diagrams; Real time systems; Unmanned aerial vehicles (UAV); Autonomous Vehicles; Component failures; Decision making process; Emergency landing; Fast systems; Mission objectives; Mission reliability; Mission success; Phased mission; Reconfiguration process; Reduced redundancy; Search and rescue operations; Weather conditions; Reliability analysis	Brazenaite, K.; Chen, W.-H.; Andrews, J.D.	Reliability, Risk and Safety: Back to the Future			480 – 486	"@CONFERENCE{Brazenaite2010480,
    author = ""Brazenaite, K. and Chen, W.-H. and Andrews, J.D."",
    title = ""Mission reconfiguration based on real-time system reliability assessment"",
    year = ""2010"",
    journal = ""Reliability, Risk and Safety: Back to the Future"",
    pages = ""480 – 486"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861665782\&partnerID=40\&md5=4de1c339a9eb51bc8838068ac2601da7"",
    affiliations = ""Department of Aeronautical and Automotive Engineering, Loughborough University, United Kingdom; Nottingham Transportation Engineering Centre, University of Nottingham, United Kingdom"",
    abstract = ""Unmanned Aerial Vehicles (UAVs) must be reliable and have the ability to take appropriate action when some functionality is lost due to failure. Fast system reliability assessment techniques such as the Binary Decision Diagram (BDD) technique can be used as part of the decision making process to decide when the likelihood of the autonomous vehicle successfully performing its intended task becomes unacceptably low and what action needs to be taken to mitigate this situation. A UAV is used in this paper to demonstrate the technique. Its mission objectives are specified and the way that this will be achieved is expressed as a phased mission. If the reliability analysis of this phased mission is acceptable it will go ahead. However the UAV must have the ability to respond to changing conditions. Such changes can occur due to component failures causing loss of functionality or reduced redundancy, changing weather conditions, or the emergence of a threat such as another aircraft in the locality. When these conditions are reported the mission success likelihood is re-evaluated accounting for the new conditions and the number of phases already successfully completed. In the event that this new mission reliability is below the acceptable threshold, reconfiguration is initiated. Mission reconfiguration for a UAV selects a new route, new mission objectives, or to abort the mission and make an emergency landing. The focus of the method presented in this paper is the mission reconfiguration process which is based on optimising the mission reliability under its current conditions and environment. This is demonstrated using a UAV carrying out a search and rescue operation. © 2010 Taylor \& Francis Group."",
    keywords = ""Binary decision diagrams; Real time systems; Unmanned aerial vehicles (UAV); Autonomous Vehicles; Component failures; Decision making process; Emergency landing; Fast systems; Mission objectives; Mission reliability; Mission success; Phased mission; Reconfiguration process; Reduced redundancy; Search and rescue operations; Weather conditions; Reliability analysis"",
    isbn = ""978-041560427-7"",
    language = ""English"",
    abbrev_source_title = ""Reliab., Risk Saf.: Back Future"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: European Safety and Reliability Annual Conference: Reliability, Risk and Safety: Back to the Future, ESREL 2010; Conference date: 5 September 2010 through 9 September 2010; Conference code: 89976""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2010	 Mission reconfiguration based on real-time system reliability assessment	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861665782&partnerID=40&md5=4de1c339a9eb51bc8838068ac2601da7		nan; References; DOI; Publisher
27	TestNN	Mitigating catastrophic failure at intersections of autonomous vehicles	"Fully autonomous vehicles promise enormous gains in safety, efficiency, and economy. Before such gains can be realized, safety and reliability concerns must be addressed. We have previously introduced a system for managing such vehicles at intersections that is capable of handling more vehicles and causing fewer delays than traffic lights and stop signs [2], While the system is safe under normal operating conditions, we have not discussed the possibility or implications of unforeseen mechanical failures. Because the system orchestrates such precarious ""close calls"" the tolerance for such errors is small. In this paper, we introduce safety features of the system designed to deal with these types of failures, and perform a basic failure mode analysis, demonstrating that without these features, the system is unsuitable for deployment due to a propensity for catastrophic failure modes. Copyright © 2008, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved."	Autonomous agents; Failure modes; Intelligent systems; Safe handling; Traffic signs; Autonomous Vehicles; Catastrophic failures; Failure mode analysis; Fully-autonomous vehicles; Intelligent transportation systems; Intersection control; Mechanical failures; Normal operating conditions; Multi agent systems	Dresner, Kurt; Stone, Peter	Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS			1361 – 1364	"@CONFERENCE{Dresner20081361,
    author = ""Dresner, Kurt and Stone, Peter"",
    title = ""Mitigating catastrophic failure at intersections of autonomous vehicles"",
    year = ""2008"",
    journal = ""Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS"",
    volume = ""3"",
    pages = ""1361 – 1364"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899895199\&partnerID=40\&md5=8dfa67a3deb79e0795cfdad1637e15cc"",
    affiliations = ""University of Texas at Austin, Department of Computer Sciences, Austin, TX 78712, United States"",
    abstract = {Fully autonomous vehicles promise enormous gains in safety, efficiency, and economy. Before such gains can be realized, safety and reliability concerns must be addressed. We have previously introduced a system for managing such vehicles at intersections that is capable of handling more vehicles and causing fewer delays than traffic lights and stop signs [2], While the system is safe under normal operating conditions, we have not discussed the possibility or implications of unforeseen mechanical failures. Because the system orchestrates such precarious ""close calls"" the tolerance for such errors is small. In this paper, we introduce safety features of the system designed to deal with these types of failures, and perform a basic failure mode analysis, demonstrating that without these features, the system is unsuitable for deployment due to a propensity for catastrophic failure modes. Copyright © 2008, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
    author_keywords = ""Autonomous vehicles; Intelligent transportation systems; Intersection control; Multiagent systems"",
    keywords = ""Autonomous agents; Failure modes; Intelligent systems; Safe handling; Traffic signs; Autonomous Vehicles; Catastrophic failures; Failure mode analysis; Fully-autonomous vehicles; Intelligent transportation systems; Intersection control; Mechanical failures; Normal operating conditions; Multi agent systems"",
    publisher = ""International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)"",
    issn = ""15488403"",
    isbn = ""978-160560470-1"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 18; Conference name: 7th International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS 2008; Conference date: 12 May 2008 through 16 May 2008; Conference code: 105064""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2008	 Mitigating catastrophic failure at intersections of autonomous vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899895199&partnerID=40&md5=8dfa67a3deb79e0795cfdad1637e15cc	International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)	nan; References; DOI
28	TestNN	Modeling risk perception for mars rover supervisory control: Before and after wheel damage	The perception of risk can dramatically influence the human selection of semi-autonomous system control strategies, particularly in safety-critical systems like unmanned vehicle operation. Thus, the ability to understand the components of risk perception can be extremely valuable in developing either operational strategies or decision support technologies. To this end, this paper analyzes the differences in human supervisory control of Mars Science Laboratory rover operation before and after the discovery of wheel damage. This paper identifies four operational factors sensitive to risk perception changes including rover distance traveled, utilization frequency of the autonomous driving capability (AutoNav), terrain risk weighting, and changes in high-level mission planning. A resulting Rover Risk Perception Model illustrates how these operational factors relate to increased perception of risk. Based on these results, we propose aiding risk perception mitigation strategies such that risk can be appropriately anchored. Such strategies can include a change in system design including adding technology and decision support tools, or changing the training of operators who use the system. © 2017 IEEE.	Decision support systems; Martian surface analysis; Personnel training; Remotely operated vehicles; Systems analysis; Wheels; Decision support tools; Human supervisory control; Mars science laboratory; Mitigation strategy; Operational strategies; Safety critical systems; Semi-autonomous systems; Supervisory control; Risk perception	Stimpson, Alex J.; Tucker, Matthew B.; Ono, Masahiro; Steffy, Amanda; Cummings, Mary L.	IEEE Aerospace Conference Proceedings	https://doi.org/10.1109/AERO.2017.7943871			"@CONFERENCE{Stimpson2017,
    author = ""Stimpson, Alex J. and Tucker, Matthew B. and Ono, Masahiro and Steffy, Amanda and Cummings, Mary L."",
    title = ""Modeling risk perception for mars rover supervisory control: Before and after wheel damage"",
    year = ""2017"",
    journal = ""IEEE Aerospace Conference Proceedings"",
    doi = ""10.1109/AERO.2017.7943871"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021191452\&doi=10.1109\%2fAERO.2017.7943871\&partnerID=40\&md5=c8131000db7959851d9d24eac97eb2f0"",
    affiliations = ""Humans and Autonomy Lab., 144 Hudson Hall, Durham, 27708, NC, United States; NASA Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, 91109, CA, United States"",
    abstract = ""The perception of risk can dramatically influence the human selection of semi-autonomous system control strategies, particularly in safety-critical systems like unmanned vehicle operation. Thus, the ability to understand the components of risk perception can be extremely valuable in developing either operational strategies or decision support technologies. To this end, this paper analyzes the differences in human supervisory control of Mars Science Laboratory rover operation before and after the discovery of wheel damage. This paper identifies four operational factors sensitive to risk perception changes including rover distance traveled, utilization frequency of the autonomous driving capability (AutoNav), terrain risk weighting, and changes in high-level mission planning. A resulting Rover Risk Perception Model illustrates how these operational factors relate to increased perception of risk. Based on these results, we propose aiding risk perception mitigation strategies such that risk can be appropriately anchored. Such strategies can include a change in system design including adding technology and decision support tools, or changing the training of operators who use the system. © 2017 IEEE."",
    keywords = ""Decision support systems; Martian surface analysis; Personnel training; Remotely operated vehicles; Systems analysis; Wheels; Decision support tools; Human supervisory control; Mars science laboratory; Mitigation strategy; Operational strategies; Safety critical systems; Semi-autonomous systems; Supervisory control; Risk perception"",
    publisher = ""IEEE Computer Society"",
    issn = ""1095323X"",
    isbn = ""978-150901613-6"",
    language = ""English"",
    abbrev_source_title = ""IEEE Aerosp. Conf. Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 8; Conference name: 2017 IEEE Aerospace Conference, AERO 2017; Conference date: 4 March 2017 through 11 March 2017; Conference code: 128213""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2017	 Modeling risk perception for mars rover supervisory control: Before and after wheel damage	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021191452&doi=10.1109%2fAERO.2017.7943871&partnerID=40&md5=c8131000db7959851d9d24eac97eb2f0	IEEE Computer Society	nan; References; Pages
29	TestNN	On the Robustness of a Neural Network	With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the black box aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons' activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements.		El Mahdi El Mhamdi; Rachid Guerraoui; Sébastien Rouault	2017 IEEE 36th Symposium on Reliable Distributed Systems (SRDS)	https://doi.org/10.1109/SRDS.2017.21				Included	Included	new_screen			1	IEEE	2017	 On the Robustness of a Neural Network		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
30	TestNN	Preemptive detection of unsafe motion liable for hazard	Establishing a safety standard for autonomous vehicles operating in open and dynamic environment is a challenge. As collisions are inevitable in over-constrained situations, we focus on deciding the liability for a hazard. Our insight is that hazards caused by malfunctions of autonomous vehicles result from loss of functional integrity. Design defects may leave it unnoticed, or the real-world may make integrity- preserving motion infeasible. Guarantee of functional integrity in an observable way at run-time is indispensable for revealing defects by using formal root-cause analysis, and for supporting safety claims by dismissing unreasonable doubts about design defects. From a practitical standpoint, we attempt to formalize a verification problem that consists of a novel criterion for determining liability for hazard, a safety claim comprised of confirmed observable states, and assumptions underlying the safety claim. We propose a run-time scheme of monitoring events that may lead to violations of the assumptions and a precursor to root-causes leading to loss of functional integrity and consequent hazards. We formulate a means of preemptively detecting unsafe motions liable to be hazardous as satisfiability problem within the framework of an adversarial motion planning subject to assumptions on maneuverability of movers. A numerical study shows that the run-time scheme using non-linear programming (NLP) encoding is viable in a real-world setting. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.	Computer games; Deep learning; Defects; Embedded systems; Hazards; Knowledge based systems; Maneuverability; Motion analysis; Motion planning; Nonlinear programming; Operations research; Autonomous Vehicles; Dynamic environments; Functional integrities; Over-constrained; Real world setting; Root cause analysis; Satisfiability problems; Verification problems; Problem solving	Nishi, Masataka	AAAI Workshop - Technical Report			153 – 160	"@CONFERENCE{Nishi2017153,
    author = ""Nishi, Masataka"",
    title = ""Preemptive detection of unsafe motion liable for hazard"",
    year = ""2017"",
    journal = ""AAAI Workshop - Technical Report"",
    volume = ""WS-17-01 - WS-17-15"",
    pages = ""153 – 160"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046083868\&partnerID=40\&md5=d892239482e2ab70b6931e5059667bac"",
    affiliations = ""Hitachi Research Laboratory, Hitachi Ltd., Japan"",
    abstract = ""Establishing a safety standard for autonomous vehicles operating in open and dynamic environment is a challenge. As collisions are inevitable in over-constrained situations, we focus on deciding the liability for a hazard. Our insight is that hazards caused by malfunctions of autonomous vehicles result from loss of functional integrity. Design defects may leave it unnoticed, or the real-world may make integrity- preserving motion infeasible. Guarantee of functional integrity in an observable way at run-time is indispensable for revealing defects by using formal root-cause analysis, and for supporting safety claims by dismissing unreasonable doubts about design defects. From a practitical standpoint, we attempt to formalize a verification problem that consists of a novel criterion for determining liability for hazard, a safety claim comprised of confirmed observable states, and assumptions underlying the safety claim. We propose a run-time scheme of monitoring events that may lead to violations of the assumptions and a precursor to root-causes leading to loss of functional integrity and consequent hazards. We formulate a means of preemptively detecting unsafe motions liable to be hazardous as satisfiability problem within the framework of an adversarial motion planning subject to assumptions on maneuverability of movers. A numerical study shows that the run-time scheme using non-linear programming (NLP) encoding is viable in a real-world setting. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."",
    keywords = ""Computer games; Deep learning; Defects; Embedded systems; Hazards; Knowledge based systems; Maneuverability; Motion analysis; Motion planning; Nonlinear programming; Operations research; Autonomous Vehicles; Dynamic environments; Functional integrities; Over-constrained; Real world setting; Root cause analysis; Satisfiability problems; Verification problems; Problem solving"",
    correspondence_address = ""M. Nishi; Hitachi Research Laboratory, Hitachi Ltd., Japan; email: masataka.nishi.en@hitachi.com"",
    publisher = ""AI Access Foundation"",
    isbn = ""978-157735786-5"",
    language = ""English"",
    abbrev_source_title = ""AAAI Workshop Tech. Rep."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 31st AAAI Conference on Artificial Intelligence, AAAI 2017; Conference date: 4 February 2017 through 5 February 2017; Conference code: 135573""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	 Preemptive detection of unsafe motion liable for hazard	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046083868&partnerID=40&md5=d892239482e2ab70b6931e5059667bac	AI Access Foundation	nan; References; DOI
31	TestNN	Reasoning About Risk in Agent’s Deliberation Process: A Jadex Implementation	Autonomous agents and multi-agent systems have been proved to be useful in several safety-critical applications. However, in current agent architectures (particularly BDI architectures) the deliberation process does not include any form of risk analysis. In this paper, we propose guidelines to implement Tropos Goal-Risk reasoning. Our proposal aims at introducing risk reasoning in the deliberation process of a BDI agent so that the overall set of possible plans is evaluated with respect to risk. When the level of risk results too high, agents can consider and introduce additional plans, called treatments, that produce an overall reduction of the risk. Side effects of treatments are also considered as part of the model. To make the discussion more concrete, we illustrate the proposal with a case study on the Unmanned Aerial Vehicle agent.	Multiagent System; Unmanned Aerial Vehicle; Autonomous Agent; Reasoning Mechanism; Agent Platform	Yudistira Asnar1,; Paolo Giorgini1&; Nicola Zannone1	International Workshop on Agent-Oriented Software Engineering	https://doi.org/10.1007/978-3-540-79488-2_9		pp 118–131		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2008	 Reasoning about risk in agent's deliberation process: a Jadex implementation		Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
32	TestNN	Reluplex: An efficient smt solver for verifying deep neural networks	Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods. © Springer International Publishing AG 2017.	Aircraft accidents; Computer aided analysis; Linear programming; Safety engineering; Activation functions; Airborne collision avoidance systems; Counter examples; Real-world problem; Safety critical systems; Simplex methods; Simplifying assumptions; Unmanned aircrafts; Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-319-63387-9_5		97 – 117	"@ARTICLE{Katz201797,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""V., Kuncak and R., Majumdar"",
    title = ""Reluplex: An efficient smt solver for verifying deep neural networks"",
    year = ""2017"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""10426 LNCS"",
    pages = ""97 – 117"",
    doi = ""10.1007/978-3-319-63387-9\_5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026742103\&doi=10.1007\%2f978-3-319-63387-9\_5\&partnerID=40\&md5=9dc7582088aa6f998ebc7f22fd957068"",
    affiliations = ""Stanford University, Stanford, United States"",
    abstract = ""Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods. © Springer International Publishing AG 2017."",
    keywords = ""Aircraft accidents; Computer aided analysis; Linear programming; Safety engineering; Activation functions; Airborne collision avoidance systems; Counter examples; Real-world problem; Safety critical systems; Simplex methods; Simplifying assumptions; Unmanned aircrafts; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, Stanford, United States; email: guyk@stanford.edu"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-331963386-2"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1003; Conference name: 29th International Conference on Computer Aided Verification, CAV 2017; Conference date: 24 July 2017 through 28 July 2017; Conference code: 195249; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	 Reluplex: An efficient SMT solver for verifying deep neural networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026742103&doi=10.1007%2f978-3-319-63387-9_5&partnerID=40&md5=9dc7582088aa6f998ebc7f22fd957068	Springer Verlag	nan; References
33	TestNN	Runtime Analysis with R2U2: A Tool Exhibition Report	We present R2U2 (Realizable, Responsive, Unobtrusive Unit), a hardware-supported tool and framework for the continuous monitoring of safety-critical and embedded cyber-physical systems. With the widespread advent of autonomous systems such as Unmanned Aerial Systems (UAS), satellites, rovers, and cars, real-time, on-board decision making requires unobtrusive monitoring of properties for safety, performance, security, and system health. R2U2 models combine past-time and future-time Metric Temporal Logic, “mission time” Linear Temporal Logic, probabilistic reasoning with Bayesian Networks, and model-based prognostics.The R2U2 monitoring engine can be instantiated as a hardware solution, running on an FPGA, or as a software component. The FPGA realization enables R2U2 to monitor complex cyber-physical systems without any overhead or instrumentation of the flight software. In this tool exhibition report, we present R2U2 and demonstrate applications on system runtime monitoring, diagnostics, software health management, and security monitoring for a UAS. Our tool demonstration uses a hardware-based processor-in-the-loop “iron-bird” configuration.	Metric Temporal Logic (MTL); Software Health Management; Flight Software; Unmanned Aerial Systems (UAS); Model Ru	Johann Schumann15,; Patrick Moosbrugger16&; Kristin Y. Rozier17	International Conference on Runtime Verification	https://doi.org/10.1007/978-3-319-46982-9_35		pp 504–509		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2016	 Runtime Analysis with R2U2: A Tool Exhibition Report		Springer, Cham	nan; References; Year; Bibtex; Link
34	TestNN	Safety analysis of Autonomous Ground Vehicle optical systems: Bayesian belief networks approach	Autonomous Ground Vehicles (AGV) require diverse sensor systems to support the navigation and sense-and-avoid tasks. Two of these systems are discussed in the paper: dual camera-based computer vision (CV) and laser-based detection and ranging (LIDAR). Reliable operation of these optical systems is critical to safety since potential faults or failures could result in mishaps leading to loss of life and property. The paper identifies basic hazards and, using fault tree analysis, the causes and effects of these hazards as related to LIDAR and CV systems. A Bayesian Belief Network approach (BN) supported by automated tool is subsequently used to obtain quantitative probabilistic estimation of system safety.		Daniel Reyes Duran; Elliot Robinson; Andrew J. Kornecki; Janusz Zalewski	2013 Federated Conference on Computer Science and Information Systems		"1.D. Coombs, K. Murphy, A. Lacaze, A. and S. Legowik, ""Driving autonomously offroad up to 35 km/h"". Proceedings of the IEEE Intelligent Vehicles Symposium, Dearborn, Michigan. 2000. View Article  Google Scholar; 2.T.H. Hong, M.O. Shneier, C. Rasmussen and T. Chang, ""Road detection and tracking for autonomous mobile robots"". SPIE 16th Annual International Symposium on Aerospace/Defense Sensing, Simulation, and Controls, Orlando, Florida. 2002. Google Scholar; 3.C. Rasmussen, ""Combining laser range, color, and texture cues for autonomous road following"", IEEE International Conference on Robotics and Automation, Washington, DC. 2002. View Article  Google Scholar; 4.J.A. Bornstein and C.M. Shoemaker, ""Army ground robotics research program"", Unmanned Ground Vehicle Technology V, Orlando, Florida. SPIE Proceedings Series, Volume 5083, pp. 303-310, 2003. CrossRef  Google Scholar; 5.C. Urmson, Navigation regimes for off-road driving, Technical Report No. CMU-RI-TR-05-23. Pittsburgh, PA: Carnegie Mellon University, Robotics Institute, 2005. Google Scholar; 6.W. Vesely et al., Fault Tree Handbook with Aerospace Applications, NASA Office of Safety and Mission Assurance, August 2002. Google Scholar; 7.L. Portinale, ""Bayesian Belief Networks in Reliability"", Tutorial Notes, 2012 Annual Reliability and Maintainability Symposium, Reno, NV, URL: http://www.xcdsystem.com/rams2012/cdrom/tutorials/ 09a.pdf Google Scholar; 8.N.E. Fenton and M. Neil, Risk Assessment and Decision Analysis with Bayesian Networks, CRC Press, ISBN: 9781439809105, 2012. Google Scholar; 9.F.V. Jensen and T.D. Nielsen, Bayesian Networks and Decision Graphs. Second Edition, Springer-Verlag, 2007. CrossRef  Google Scholar; 10.Netica Software Package. Norsys Software Corp., Vancouver, BC. URL: http://www.norsys.com/netica.html. Google Scholar; 11.R. Chalupa, Failure Modes, Effects and Diagnostics Analysis. Report No. 06-11-25-R001, Rosemount Corp., Eden Prairie, Minn. 2007. Google Scholar"			Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2013	 Safety analysis of Autonomous Ground Vehicle optical systems: Bayesian belief networks approach		IEEE	nan; Keywords; Pages; Year; Bibtex; DOI; Link
35	TestNN	Safety verification of autonomous vehicles for coordinated evasive maneuvers	The verification of evasive maneuvers for autonomous vehicles driving with constant velocity is considered. Modeling uncertainties, uncertain measurements, and disturbances can cause substantial deviations from an initially planned evasive maneuver. From this follows that the maneuver, which is safe under perfect conditions, might become unsafe. In this work, the possible set of deviations is computed with methods from reachability analysis, which allows to verify evasive maneuvers under consideration of the mentioned uncertainties. Since the presented approach has a short response time, it can be applied for real time safety decisions. The methods are presented for a numerical example where two autonomous cars plan a coordinated evasive maneuver in order to prevent a collision with a wrong-way driver. ©2010 IEEE.	Intelligent vehicle highway systems; Numerical methods; Uncertainty analysis; Autonomous car; Autonomous Vehicles; Constant velocities; Modeling uncertainties; Numerical example; Reachability analysis; Real time; Safety verification; Short response time; Uncertain measurements; Vehicles	Althoff, Matthias; Althoff, Daniel; Wollherr, Dirk; Buss, Martin	IEEE Intelligent Vehicles Symposium, Proceedings	https://doi.org/10.1109/IVS.2010.5548121		1078 – 1083	"@CONFERENCE{Althoff20101078,
    author = ""Althoff, Matthias and Althoff, Daniel and Wollherr, Dirk and Buss, Martin"",
    title = ""Safety verification of autonomous vehicles for coordinated evasive maneuvers"",
    year = ""2010"",
    journal = ""IEEE Intelligent Vehicles Symposium, Proceedings"",
    pages = ""1078 – 1083"",
    doi = ""10.1109/IVS.2010.5548121"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956510770\&doi=10.1109\%2fIVS.2010.5548121\&partnerID=40\&md5=34d6e272a2766882b7dbc47c37247d96"",
    affiliations = ""Institute of Automatic Control Engineering (LSR), Technische Universität München, 80290 München, Germany"",
    abstract = ""The verification of evasive maneuvers for autonomous vehicles driving with constant velocity is considered. Modeling uncertainties, uncertain measurements, and disturbances can cause substantial deviations from an initially planned evasive maneuver. From this follows that the maneuver, which is safe under perfect conditions, might become unsafe. In this work, the possible set of deviations is computed with methods from reachability analysis, which allows to verify evasive maneuvers under consideration of the mentioned uncertainties. Since the presented approach has a short response time, it can be applied for real time safety decisions. The methods are presented for a numerical example where two autonomous cars plan a coordinated evasive maneuver in order to prevent a collision with a wrong-way driver. ©2010 IEEE."",
    keywords = ""Intelligent vehicle highway systems; Numerical methods; Uncertainty analysis; Autonomous car; Autonomous Vehicles; Constant velocities; Modeling uncertainties; Numerical example; Reachability analysis; Real time; Safety verification; Short response time; Uncertain measurements; Vehicles"",
    correspondence_address = ""M. Althoff; Institute of Automatic Control Engineering (LSR), Technische Universität München, 80290 München, Germany; email: althoff@tum.de"",
    isbn = ""978-142447866-8"",
    language = ""English"",
    abbrev_source_title = ""IEEE Intell Veh Symp Proc"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 53; Conference name: 2010 IEEE Intelligent Vehicles Symposium, IV 2010; Conference date: 21 June 2010 through 24 June 2010; Conference code: 81688; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2010	 Safety Verification of Autonomous Vehicles for Coordinated Evasive Maneuvers	https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956510770&doi=10.1109%2fIVS.2010.5548121&partnerID=40&md5=34d6e272a2766882b7dbc47c37247d96		nan; References; Publisher
36	TestNN	STPA-based hazard analysis of a complex UAV system in take-off	The ATRC-UAV system is a multifunction system with close subsystem component interactions. Considering its complexity, component hardware failures are no longer the only reason for flight testing accidents, and a comprehensive approach is needed for hazard analysis. Systems-Theoretic Process Analysis (STPA) is a novel technique based on systems theory rather than traditional reliability theories. It addresses safety of complex systems as a control problem rather than a failure problem. In this paper, we adopt STPA on a subscale Unmanned Aerial Vehicle (UAV) system take-off hazard analysis and the potential feasibility of STPA for complex UAV system is demonstrated. Unsafe control actions during take-off and their relevant control flaws are identified and safety constrains at different levels are specified. In addition to component failures, we discover that component interactions and flawed human decision making might also lead to violation of safety constrains by using STPA. © 2015 IEEE.	Accidents; Decision making; Large scale systems; Reliability analysis; Reliability theory; Unmanned aerial vehicles (UAV); Accident models; Component failures; Component interaction; Hardware failures; Hazard analysis; Human decision making; Multifunction systems; Unmanned aerial vehicle systems; Hazards	Chen, Jieyu; Zhang, Shuguang; Lu, Yi; Tang, Peng	ICTIS 2015 - 3rd International Conference on Transportation Information and Safety, Proceedings	https://doi.org/10.1109/ICTIS.2015.7232133		774 – 779	"@CONFERENCE{Chen2015774,
    author = ""Chen, Jieyu and Zhang, Shuguang and Lu, Yi and Tang, Peng"",
    title = ""STPA-based hazard analysis of a complex UAV system in take-off"",
    year = ""2015"",
    journal = ""ICTIS 2015 - 3rd International Conference on Transportation Information and Safety, Proceedings"",
    pages = ""774 – 779"",
    doi = ""10.1109/ICTIS.2015.7232133"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960091468\&doi=10.1109\%2fICTIS.2015.7232133\&partnerID=40\&md5=929660a1c32f0609155def6582d44f2b"",
    affiliations = ""School of Transportation Science and Engineering, Airworthiness Technologies Research Center, Beihang University, Beijing, 100191, China; School of Energy and Power Engineering, Beijing Key Laboratory of Aircraft/Engine, Beihang University, Beijing, 100191, China"",
    abstract = ""The ATRC-UAV system is a multifunction system with close subsystem component interactions. Considering its complexity, component hardware failures are no longer the only reason for flight testing accidents, and a comprehensive approach is needed for hazard analysis. Systems-Theoretic Process Analysis (STPA) is a novel technique based on systems theory rather than traditional reliability theories. It addresses safety of complex systems as a control problem rather than a failure problem. In this paper, we adopt STPA on a subscale Unmanned Aerial Vehicle (UAV) system take-off hazard analysis and the potential feasibility of STPA for complex UAV system is demonstrated. Unsafe control actions during take-off and their relevant control flaws are identified and safety constrains at different levels are specified. In addition to component failures, we discover that component interactions and flawed human decision making might also lead to violation of safety constrains by using STPA. © 2015 IEEE."",
    author_keywords = ""accident model; complex system; hazard analysis; STAMP/STPA; UAV"",
    keywords = ""Accidents; Decision making; Large scale systems; Reliability analysis; Reliability theory; Unmanned aerial vehicles (UAV); Accident models; Component failures; Component interaction; Hardware failures; Hazard analysis; Human decision making; Multifunction systems; Unmanned aerial vehicle systems; Hazards"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147998694-1"",
    language = ""English"",
    abbrev_source_title = ""ICTIS - Int. Conf. Transp. Inf. Saf., Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 15; Conference name: 3rd International Conference on Transportation Information and Safety, ICTIS 2015; Conference date: 25 June 2015 through 28 June 2015; Conference code: 117960""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2015	 STPA-based hazard analysis of a complex UAV system in take-off	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960091468&doi=10.1109%2fICTIS.2015.7232133&partnerID=40&md5=929660a1c32f0609155def6582d44f2b	Institute of Electrical and Electronics Engineers Inc.	nan; References
37	TestNN	System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization	Autonomous and semi-autonomous aerial systems (AES) are often needed to perform tasks in complex and dynamic environments, especially in search and rescue applications. The safe navigation assurance as well as safety assurance of AES are open research issues. This paper investigates modeling of fallback layer for AES assurance. To realize given advanced requirement the System Safety Surveillance and Control (SSSC) system concept is introduced. To fulfill safety requirements also for software developments formal requirements are formulated, to be realized with the formal modeling technique Strictly Formalized Situation-Operator-Modeling (sf-SOM). Fall-back system integration into AES can achieve system safety by separated safety consideration and emergency behavior integration and realization. Universally concept design permits the fall-back layer realization also for other applications. This in turn allows the first proof of concept of sf-SOM based SSSC system for fall-back layer realization using an experimental example. Here a Threetank system is used to show the successful fall-back layer realization and the concept transferability to the introduced AES example. Copyright © 2016 by ASME.	Antennas; Manipulators; Motion planning; Multi agent systems; Networked control systems; Robot applications; Robot programming; Robots; Robustness (control systems); Traffic control; Vibrations (mechanical); Behavior integration; Dynamic environments; Safety considerations; Safety requirements; Search-and-rescue applications; Semi-autonomous systems; System integration; Three-Tank-System; Advanced vehicle control systems	Hägele, Georg; Söffker, Dirk	ASME 2016 Dynamic Systems and Control Conference, DSCC 2016	https://doi.org/10.1115/DSCC2016-9718			"@CONFERENCE{Hägele2016,
    author = ""Hägele, Georg and Söffker, Dirk"",
    title = ""System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization"",
    year = ""2016"",
    journal = ""ASME 2016 Dynamic Systems and Control Conference, DSCC 2016"",
    volume = ""2"",
    doi = ""10.1115/DSCC2016-9718"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015635348\&doi=10.1115\%2fDSCC2016-9718\&partnerID=40\&md5=fb34966efec337afbfee65ef62cf146e"",
    affiliations = ""Department of Dynamics and Control, University of Duisburg-Essen, Germany"",
    abstract = ""Autonomous and semi-autonomous aerial systems (AES) are often needed to perform tasks in complex and dynamic environments, especially in search and rescue applications. The safe navigation assurance as well as safety assurance of AES are open research issues. This paper investigates modeling of fallback layer for AES assurance. To realize given advanced requirement the System Safety Surveillance and Control (SSSC) system concept is introduced. To fulfill safety requirements also for software developments formal requirements are formulated, to be realized with the formal modeling technique Strictly Formalized Situation-Operator-Modeling (sf-SOM). Fall-back system integration into AES can achieve system safety by separated safety consideration and emergency behavior integration and realization. Universally concept design permits the fall-back layer realization also for other applications. This in turn allows the first proof of concept of sf-SOM based SSSC system for fall-back layer realization using an experimental example. Here a Threetank system is used to show the successful fall-back layer realization and the concept transferability to the introduced AES example. Copyright © 2016 by ASME."",
    keywords = ""Antennas; Manipulators; Motion planning; Multi agent systems; Networked control systems; Robot applications; Robot programming; Robots; Robustness (control systems); Traffic control; Vibrations (mechanical); Behavior integration; Dynamic environments; Safety considerations; Safety requirements; Search-and-rescue applications; Semi-autonomous systems; System integration; Three-Tank-System; Advanced vehicle control systems"",
    publisher = ""American Society of Mechanical Engineers"",
    isbn = ""978-079185070-1"",
    language = ""English"",
    abbrev_source_title = ""ASME Dyn. Syst. Control Conf., DSCC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 3; Conference name: ASME 2016 Dynamic Systems and Control Conference, DSCC 2016; Conference date: 12 October 2016 through 14 October 2016; Conference code: 126470""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2016	 System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015635348&doi=10.1115%2fDSCC2016-9718&partnerID=40&md5=fb34966efec337afbfee65ef62cf146e	American Society of Mechanical Engineers	nan; References; Pages
38	TestNN	The human should be part of the control loop?	The capabilities of autonomy have grown to encompass new application spaces that until recently were considered exclusive to humans. In the past, automation has focused on applications where it was preferable to completely replace the human. Today, though, we have the opportunity to leverage the complementary strengths of both human and autonomy technologies to maximize performance and limit risk, and the human should therefore remain “in” or “on” the loop. To adequately assess when and how to accomplish this, it requires us to assess not only the capabilities, but the risks and the ethical questions; coupled to this are the issues with degradation of performance in specific instances (for instance, recovery from failure) that may require a human to remain the sole control authority. This paper investigates the contributors to success/failure in current human-autonomy integration frameworks, and proposes guidelines for safe and resilient use of humans and autonomy with regard to performance, consequence, and the stability of human-machine switching. Key to our proposed approach are (i) the relative error rate between the human and autonomy and (ii) the consequence of possible events.		William D. Nothwang; Michael J. McCourt; Ryan M. Robinson; Samuel A. Burden; J. Willard Curtis	2016 Resilience Week (RWS)	https://doi.org/10.1109/RWEEK.2016.7573336	"1.D. E. Nye, America s Assembly Line, MIT Press, 2013. Google Scholar; 2.F. W. Meredith, ""The modern autopilot"", Aeronautical Journal, 1949. Google Scholar; 3.A. Wolman, ""Industrial water supply from processed sewage treatment plant effluent at Baltimore Md"", Sewage Works Journal, vol. 20, no. 1, pp. 15-21, 1948. Google Scholar; 4.Y. Harrison and J. A. Horne, ""The impact of sleep deprivation on decision making: a review"", Journal of Experimental Psychology, vol. 6, no. 3, pp. 236-249, 2000. CrossRef  Google Scholar; 5.B. Donmez, C. Neheme and M. L. Cummings, ""Modeling workload impact in multiple unnmanned vehicle supervisory control"", IEEE Transactions on Systems Man and Cybernetics, vol. 40, no. 6, pp. 1180-1190, 2010. View Article  Google Scholar; 6.R. Parasuraman and D. Manzey, ""Complacency and bias in human use of automation: an attentional integration"", Human Factors: The Journal of the Human Factors and Ergonomics Society, vol. 52, no. 3, pp. 381-410, 2010. CrossRef  Google Scholar; 7.P. Scharre and M. Horowitz, ""An introduction to autonomy in weapon systems"", Center for New American Security, 2015. Google Scholar; 8.L. Onnasch, C. D. Wickens, H. Li and D. Manzey, ""Human performance consequences of stages and levels of automation: an integrated meta-analysis"", Human Factors: The Journal of the Human Factors and Ergonomics Society, vol. 56, no. 3, pp. 476-488, May 2014. CrossRef  Google Scholar; 9.M. Pilling, ""Issues regarding the future application of autonomous systems to command and control (C2)"", Defense Science and Technology Organisation Australian Department of Defense DSTO-TR-3112, 2015. Google Scholar; 10.A. R. Lanfranco, A. E. Castellanos, J. P. Desai and W. C. Meyers, ""Robotic surgery a current perspective"", Annals of surgery, vol. 239, no. 1, pp. 14-21, 2004. CrossRef  Google Scholar; 11.M. A. Talamini, S. Chapman, S. Horgan and W. S. Melvin, ""A prospective analysis of 211 robotic-assisted surgical procedures"", Surg Endosc, vol. 17, pp. 1521-1524, 2003. CrossRef  Google Scholar; 12.A. M. Okamura, ""Methods for haptic feedback in teleoperated robot-assisted surgery"", Industrial Robot, vol. 31, no. 6, pp. 499-508, 2004. CrossRef  Google Scholar; 13.H. Ding, J. Heyn, B. Matthias and H. Staab, ""Structured collaborative behavior of industrial robots in mixed human-robot environments"", IEEE International Conference on Automation Science, pp. 1101-1106, 2013. View Article  Google Scholar; 14.A. M. Zanchettin, N. M. Ceriani, P. Rocco, H. Ding and B. Matthias, ""Safety in human-robot collaborative manufacturing environments: metrics and control"", IEEE Trans. on Automation Science and Engineeriing, vol. 13, no. 2, pp. 882-893, April 2016. View Article  Google Scholar; 15.K. Wagner, ""Facebooks virtual assistant ‘M’ is super smart. Its also probably a human"", Recode, Nov. 2015,  [online]  Available: http://www.recode.net/2015/11/3/11620286/facebooks-virtual-assistant-m-is-super-smart-its-also-probably-a-human. Google Scholar; 16.""Collaborative Operations in Denied Environment (CODE)"",  [online]  Available: http://www.darpa.mil/program/collaborative-operations-in-denied-environment. Google Scholar; 17.K. He, X. Zhang, S. Ren and J. Sun, ""Delving deep into rectifiers: surpassing human-level performance on ImageNet classification"", IEEE International Conference on Computer Vision, pp. 1026-1034, Feb. 2015. View Article  Google Scholar; 18.S. Ioffe and C. Szegedy, ""Batch normalization: accelerating deep network training by reducing internal covariate shift"", International Conference on Machine Learning, pp. 448-456, 2015. Google Scholar; 19.V. Mnih, K. Kavukcuoglu, D. Silver, A.A. Rusu, J. Veness, M. G. Bellemare, A. Graves et al., ""Human-level control through deep reinforcement learning"", Nature, vol. 518, no. 7540, pp. 529-533, 2015. CrossRef  Google Scholar; 20.D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser et al., ""Mastering the game of Go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, pp. 484-489, 2016. CrossRef  Google Scholar; 21.C. Moyer, ""How Googles AlphaGo beat a Go world champion"", The Atlantic, March 2016,  [online]  Available: http://www.theatlantic.com/technology/archive/2016/03/theinvisibleopponent/475611/. Google Scholar; 22.P. M. Fitts, ""Human Engineering for an effective air-navigation and traffic-control system"" in , Washington, DC:National Research Council, 1951. Google Scholar; 23.B. Kantowitz and R. Sorkin, ""Allocation of functions"" in Handbook of Human Factors, New York:Wiley, pp. 365-369. Google Scholar; 24.J.-M. Hoc, ""Towards a cognitive approach to human-machine cooperation in dynamic situations"", Int. J. Human-Computer Studies, vol. 54, pp. 509-540, 2001. CrossRef  Google Scholar; 25.J. M. Bradshaw, V. Dignum, C. Jonker and M. Sierhuis, ""Human-agent-robot teamwork"", IEEE Intelligent Systems, vol. 27, no. 2, pp. 8-13, 2012. View Article  Google Scholar; 26.M. Johnson, J. M. Bradshaw, P. J. Feltovich, C. M. Jonker, M. B. van Riemsdijk and M. Sierhuis, ""Coactive design: designing support for interdependence in joint activity"", Journal of Human-Robot Interaction, vol. 3, no. 1, pp. 43-69, 2014. CrossRef  Google Scholar; 27.R. M. Robinson, D. Scobee, S. A. Burden and S. S. Sastry, ""Dynamic inverse models in human-cyber-physical systems"", SPIE Conference on Defense and Commercial Sensing, April 2016. Google Scholar; 28.M. Korber, W. Schneider and M. Zimmerman, ""Vigilance boredom proneness and detection time of a malfunction in partially automated driving"", IEEE Collaboration Technologies and Systems, pp. 70-76, 2015. View Article  Google Scholar; 29.R. J. Jagacinski and J. M. Flach, Control Theory for Humans: Quantiitative Approaches to Modeling Performance, CRC Press, 2003. Google Scholar; 30.J. Wise, ""What really happened aboard Air France 447"", Popular Mechanics, Dec. 2011,  [online]  Available: http://www.popularmechanics.com/flight/a3115/what-really-happened-aboard-air-france-447-6611877/. Google Scholar"			Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	IEEE	2016	 The human should be part of the control loop?		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
39	TestNN	The Robustly-Safe Automated Driving System for Enhanced Active Safety	Road safety is one of the major concerns for automated vehicles. In order for these vehicles to interact safely and efficiently with the other road participants, the behavior of the automated vehicles should be carefully designed. Liu and Tomizuka proposed the Robustly-safe Automated Driving system (ROAD) which prevents or minimizes occurrences of collisions of the automated vehicle with other road participants while maintaining efficiency. In this paper, a set of design principles are elaborated as an extension of the previous work, including robust perception and cognition algorithms for environment monitoring and high level decision making and low level control algorithms for safe maneuvering of the automated vehicle. The autonomous driving problem in mixed traffic is posed as a stochastic optimization problem, which is solved by 1) behavior classification and trajectory prediction of other road participants, and 2) a unique parallel planner architecture which addresses the efficiency goal in the long term and the safety goal in the short term separately. Moreover, a python-based high fidelity simulation system is developed and extensive simulations are performed to evaluate the effectiveness of the proposed algorithm, where both high level decision making and low level vehicle regulation are considered. Two typical scenarios are studied, driving on freeway and driving in unstructured environments such as parking lots. In the simulation, multiple moving agents representing surrounding vehicles and pedestrians are added to the environment, some of which are controlled by human subjects in order to test the real time response of the automated vehicle. © 2017 SAE International.	Automation; Computer software; Decision making; Efficiency; Motor transportation; Optimization; Roads and streets; Automated driving systems; Behavior classification; Environment monitoring; High-fidelity simulation systems; Perception and cognition; Stochastic optimization problems; Trajectory prediction; Unstructured environments; Maneuverability	Liu, Changliu; Chen, Jianyu; Nguyen, Trong-Duy; Tomizuka, Masayoshi	SAE Technical Papers	https://doi.org/10.4271/2017-01-1406			"@ARTICLE{Liu2017,
    author = ""Liu, Changliu and Chen, Jianyu and Nguyen, Trong-Duy and Tomizuka, Masayoshi"",
    title = ""The Robustly-Safe Automated Driving System for Enhanced Active Safety"",
    year = ""2017"",
    journal = ""SAE Technical Papers"",
    volume = ""2017-March"",
    number = ""March"",
    doi = ""10.4271/2017-01-1406"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018385891\&doi=10.4271\%2f2017-01-1406\&partnerID=40\&md5=e6c5b3667f5191203491243f70f91399"",
    affiliations = ""University of California, Berkeley, United States; DENSO International America Inc., United States"",
    abstract = ""Road safety is one of the major concerns for automated vehicles. In order for these vehicles to interact safely and efficiently with the other road participants, the behavior of the automated vehicles should be carefully designed. Liu and Tomizuka proposed the Robustly-safe Automated Driving system (ROAD) which prevents or minimizes occurrences of collisions of the automated vehicle with other road participants while maintaining efficiency. In this paper, a set of design principles are elaborated as an extension of the previous work, including robust perception and cognition algorithms for environment monitoring and high level decision making and low level control algorithms for safe maneuvering of the automated vehicle. The autonomous driving problem in mixed traffic is posed as a stochastic optimization problem, which is solved by 1) behavior classification and trajectory prediction of other road participants, and 2) a unique parallel planner architecture which addresses the efficiency goal in the long term and the safety goal in the short term separately. Moreover, a python-based high fidelity simulation system is developed and extensive simulations are performed to evaluate the effectiveness of the proposed algorithm, where both high level decision making and low level vehicle regulation are considered. Two typical scenarios are studied, driving on freeway and driving in unstructured environments such as parking lots. In the simulation, multiple moving agents representing surrounding vehicles and pedestrians are added to the environment, some of which are controlled by human subjects in order to test the real time response of the automated vehicle. © 2017 SAE International."",
    keywords = ""Automation; Computer software; Decision making; Efficiency; Motor transportation; Optimization; Roads and streets; Automated driving systems; Behavior classification; Environment monitoring; High-fidelity simulation systems; Perception and cognition; Stochastic optimization problems; Trajectory prediction; Unstructured environments; Maneuverability"",
    publisher = ""SAE International"",
    issn = ""01487191"",
    language = ""English"",
    abbrev_source_title = ""SAE Techni. Paper."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: SAE World Congress Experience, WCX 2017; Conference date: 4 April 2017 through 6 April 2017; Conference code: 127407""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	 The Robustly-Safe Automated Driving System for Enhanced Active Safety	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018385891&doi=10.4271%2f2017-01-1406&partnerID=40&md5=e6c5b3667f5191203491243f70f91399	SAE International	nan; References; Pages
40	TestNN	The role of situation awareness in assuring safety of autonomous vehicles	Assuring safety of autonomous vehicles operating in an open environment requires reliable situation awareness, action planning and prediction of actions of other vehicles and objects. Factors that also have to be considered are certainty and completeness of available information and trust in information sources and other entities. The paper discusses the problem of autonomous vehicle safety assurance and proposes dynamic situation assessment to cope with the problem of environment dynamics and incomplete and uncertain situation knowledge. The approach is presented for a simple example of a simulated autonomous vehicle. The situation awareness model and autonomous vehicle control system architecture is presented. The problems of justifying system safety are discussed. © Springer-Verlag Berlin Heidelberg 2006.	Autonomous agents; Computer architecture; Computer simulation; Information analysis; Problem solving; Unmanned vehicles; Autonomous vehicle control system architecture; Autonomous vehicles; Safety assurance; Simulated autonomous vehicles; Accident prevention	Wardziński, Andrzej	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)			205 – 218	"@ARTICLE{Wardziński2006205,
    author = ""Wardziński, Andrzej"",
    title = ""The role of situation awareness in assuring safety of autonomous vehicles"",
    year = ""2006"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""4166 LNCS"",
    pages = ""205 – 218"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750994641\&partnerID=40\&md5=c979dec7bbc3efac765f12443bc4dd9d"",
    affiliations = ""PROKOM Software SA, 81-321 Gdynia, Podolska 21, Poland"",
    abstract = ""Assuring safety of autonomous vehicles operating in an open environment requires reliable situation awareness, action planning and prediction of actions of other vehicles and objects. Factors that also have to be considered are certainty and completeness of available information and trust in information sources and other entities. The paper discusses the problem of autonomous vehicle safety assurance and proposes dynamic situation assessment to cope with the problem of environment dynamics and incomplete and uncertain situation knowledge. The approach is presented for a simple example of a simulated autonomous vehicle. The situation awareness model and autonomous vehicle control system architecture is presented. The problems of justifying system safety are discussed. © Springer-Verlag Berlin Heidelberg 2006."",
    keywords = ""Autonomous agents; Computer architecture; Computer simulation; Information analysis; Problem solving; Unmanned vehicles; Autonomous vehicle control system architecture; Autonomous vehicles; Safety assurance; Simulated autonomous vehicles; Accident prevention"",
    correspondence_address = ""A. Wardziński; PROKOM Software SA, 81-321 Gdynia, Podolska 21, Poland; email: wardzinskia@prokom.pl"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""3540457623; 978-354045762-6"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 16; Conference name: 25th International Conference on Computer Safety, Reliability, and Security, SAFECOMP 2006; Conference date: 27 September 2006 through 29 September 2006; Conference code: 68507""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus	2006	 The role of situation awareness in assuring safety of autonomous vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750994641&partnerID=40&md5=c979dec7bbc3efac765f12443bc4dd9d	Springer Verlag	nan; References; DOI
41	TestNN	Towards Evaluating the Robustness of Neural Networks	Abstract:Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input $x$ and any target classification $t$, it is possible to find a new input $x'$ that is similar to $x$ but classified as $t$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from $95\%$ to $0.5\%$.In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with $100\%$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.		Nicholas Carlini; David Wagner	2017 IEEE Symposium on Security and Privacy (SP) 	https://doi.org/10.48550/arXiv.1608.04644				Included	Included	new_screen			1	arXiv	2017	 Towards Evaluating the Robustness of Neural Networks			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
42	TestNN	Trust Bit: Reward-based intelligent vehicle commination using blockchain paper	The Intelligent vehicle is experiencing revolutionary growth in research and industry, but it still suffers from a lot of security vulnerabilities. Traditional security methods are incapable of providing secure IV, mainly in terms of communication. In IV communication, major issues are trust and data accuracy of received and broadcasted reliable data in the communication channel. Blockchain technology works for the cryptocurrency, Bitcoin which has been recently used to build trust and reliability in peer-to-peer networks with similar topologies to IV Communication world. IV to IV, communicate in a decentralized manner within communication networks. In this paper, we have proposed, Trust Bit (TB) for IV communication among IVs using Blockchain technology. Our proposed trust bit provides surety for each IVs broadcasted data, to be secure and reliable in every particular networks. Our Trust Bit is a symbol of trustworthiness of vehicles behavior, and vehicles legal and illegal action. Our proposal also includes a reward system, which can exchange some TB among IVs, during successful communication. For the data management of this trust bit, we have used blockchain technology in the vehicular cloud, which can store all Trust bit details and can be accessed by IV anywhere and anytime. Our proposal provides secure and reliable information. We evaluate our proposal with the help of IV communication on intersection use case which analyzes a variety of trustworthiness between IVs during communication. © 2018 IEEE.	Blockchain; Communication; Distributed computer systems; Electronic money; Indium compounds; Industrial research; Information management; Intelligent vehicle highway systems; Internet of things; Peer to peer networks; Vehicles; Data accuracy; Illegal actions; Reward systems; Security; Security methods; Security vulnerabilities; Use-case; Vehicular clouds; Network security	Singh, Madhusudan; Kim, Shiho	IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings	https://doi.org/10.1109/WF-IoT.2018.8355227		62 – 67	"@CONFERENCE{Singh201862,
    author = ""Singh, Madhusudan and Kim, Shiho"",
    title = ""Trust Bit: Reward-based intelligent vehicle commination using blockchain paper"",
    year = ""2018"",
    journal = ""IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings"",
    volume = ""2018-January"",
    pages = ""62 – 67"",
    doi = ""10.1109/WF-IoT.2018.8355227"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050387319\&doi=10.1109\%2fWF-IoT.2018.8355227\&partnerID=40\&md5=da2bb6f8945e81a20166e755fcdc908c"",
    affiliations = ""Yonsei Institute of Convergence Technology, Yonsei University, Songdo, South Korea; School of Integrated Technology, Yonsei University, Seoul, South Korea"",
    abstract = ""The Intelligent vehicle is experiencing revolutionary growth in research and industry, but it still suffers from a lot of security vulnerabilities. Traditional security methods are incapable of providing secure IV, mainly in terms of communication. In IV communication, major issues are trust and data accuracy of received and broadcasted reliable data in the communication channel. Blockchain technology works for the cryptocurrency, Bitcoin which has been recently used to build trust and reliability in peer-to-peer networks with similar topologies to IV Communication world. IV to IV, communicate in a decentralized manner within communication networks. In this paper, we have proposed, Trust Bit (TB) for IV communication among IVs using Blockchain technology. Our proposed trust bit provides surety for each IVs broadcasted data, to be secure and reliable in every particular networks. Our Trust Bit is a symbol of trustworthiness of vehicles behavior, and vehicles legal and illegal action. Our proposal also includes a reward system, which can exchange some TB among IVs, during successful communication. For the data management of this trust bit, we have used blockchain technology in the vehicular cloud, which can store all Trust bit details and can be accessed by IV anywhere and anytime. Our proposal provides secure and reliable information. We evaluate our proposal with the help of IV communication on intersection use case which analyzes a variety of trustworthiness between IVs during communication. © 2018 IEEE."",
    author_keywords = ""Blockchain Technology; Communication; Intelligent Vehicles; Security"",
    keywords = ""Blockchain; Communication; Distributed computer systems; Electronic money; Indium compounds; Industrial research; Information management; Intelligent vehicle highway systems; Internet of things; Peer to peer networks; Vehicles; Data accuracy; Illegal actions; Reward systems; Security; Security methods; Security vulnerabilities; Use-case; Vehicular clouds; Network security"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-146739944-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE World Forum Internet Things, WF-IoT - Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 70; Conference name: 4th IEEE World Forum on Internet of Things, WF-IoT 2018; Conference date: 5 February 2018 through 8 February 2018; Conference code: 136296""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2018	 Trust Bit: Reward-based intelligent vehicle commination using blockchain paper	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050387319&doi=10.1109%2fWF-IoT.2018.8355227&partnerID=40&md5=da2bb6f8945e81a20166e755fcdc908c	Institute of Electrical and Electronics Engineers Inc.	nan; References
43	TestNN	Trusted machine learning: Model repair and data repair for probabilistic models	When machine learning algorithms are used in life-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level correctness guarantees. We introduce a paradigm called Trusted Machine Learning (TML) with the goal of making learning techniques more trustworthy. We outline methods that show how symbolic analysis (specifically parametric model checking) can be used to learn the dynamical model of a system where the learned model satisfies correctness requirements specified in the form of temporal logic properties (e.g., safety, liveness). When a learned model does not satisfy the desired guarantees, we try two approaches: (1) Model Repair, wherein we modify a learned model directly, and (2) Data Repair, wherein we modify the data so that re-learning from the modified data will result in a trusted model. Model Repair tries to make the minimal changes to the trained model while satisfying the properties, whereas Data Repair tries to make the minimal changes to the dataset used to train the model for ensuring satisfaction of the properties. We show how the Model Repair and Data Repair problems can be solved for the case of probabilistic models, specifically Discrete-Time Markov Chains (DTMC) or Markov Decision Processes (MDP), when the desired properties are expressed in Probabilistic Computation Tree Logic (PCTL). Specifically, we outline how the parameter learning problem in the probabilistic Markov models under temporal logic constraints can be equivalently expressed as a non-linear optimization with non-linear rational constraints, by performing symbolic transformations using a parametric model checker. We illustrate the approach on two case studies: A controller for automobile lane changing, and query router for a wireless sensor network. © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.	Automobile safety devices; Computer circuits; Computer games; Deep learning; Knowledge based systems; Learning algorithms; Linear transformations; Markov processes; Mathematical transformations; Model checking; Nonlinear programming; Operations research; Repair; Temporal logic; Trees (mathematics); Wireless sensor networks; Discrete time Markov chains; Markov Decision Processes; Mission critical applications; Non-linear optimization; Parametric model checking; Probabilistic computation tree logic (PCTL); Probabilistic models; Temporal logic properties; Problem solving	Ghosh, Shalini; Lincoln, Patrick; Tiwari, Ashish; Zhu, Xiaojin	AAAI Workshop - Technical Report			909 – 916	"@CONFERENCE{Ghosh2017909,
    author = ""Ghosh, Shalini and Lincoln, Patrick and Tiwari, Ashish and Zhu, Xiaojin"",
    title = ""Trusted machine learning: Model repair and data repair for probabilistic models"",
    year = ""2017"",
    journal = ""AAAI Workshop - Technical Report"",
    volume = ""WS-17-01 - WS-17-15"",
    pages = ""909 – 916"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046076595\&partnerID=40\&md5=85fef797f658f51285a2c6baf69ce3e0"",
    abstract = ""When machine learning algorithms are used in life-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level correctness guarantees. We introduce a paradigm called Trusted Machine Learning (TML) with the goal of making learning techniques more trustworthy. We outline methods that show how symbolic analysis (specifically parametric model checking) can be used to learn the dynamical model of a system where the learned model satisfies correctness requirements specified in the form of temporal logic properties (e.g., safety, liveness). When a learned model does not satisfy the desired guarantees, we try two approaches: (1) Model Repair, wherein we modify a learned model directly, and (2) Data Repair, wherein we modify the data so that re-learning from the modified data will result in a trusted model. Model Repair tries to make the minimal changes to the trained model while satisfying the properties, whereas Data Repair tries to make the minimal changes to the dataset used to train the model for ensuring satisfaction of the properties. We show how the Model Repair and Data Repair problems can be solved for the case of probabilistic models, specifically Discrete-Time Markov Chains (DTMC) or Markov Decision Processes (MDP), when the desired properties are expressed in Probabilistic Computation Tree Logic (PCTL). Specifically, we outline how the parameter learning problem in the probabilistic Markov models under temporal logic constraints can be equivalently expressed as a non-linear optimization with non-linear rational constraints, by performing symbolic transformations using a parametric model checker. We illustrate the approach on two case studies: A controller for automobile lane changing, and query router for a wireless sensor network. © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."",
    keywords = ""Automobile safety devices; Computer circuits; Computer games; Deep learning; Knowledge based systems; Learning algorithms; Linear transformations; Markov processes; Mathematical transformations; Model checking; Nonlinear programming; Operations research; Repair; Temporal logic; Trees (mathematics); Wireless sensor networks; Discrete time Markov chains; Markov Decision Processes; Mission critical applications; Non-linear optimization; Parametric model checking; Probabilistic computation tree logic (PCTL); Probabilistic models; Temporal logic properties; Problem solving"",
    publisher = ""AI Access Foundation"",
    isbn = ""978-157735786-5"",
    language = ""English"",
    abbrev_source_title = ""AAAI Workshop Tech. Rep."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: 31st AAAI Conference on Artificial Intelligence, AAAI 2017; Conference date: 4 February 2017 through 5 February 2017; Conference code: 135573""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	 Trusted machine learning: Model repair and data repair for probabilistic models	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046076595&partnerID=40&md5=85fef797f658f51285a2c6baf69ce3e0	AI Access Foundation	nan; References; DOI
44	TestNN	Understanding error propagation in deep learning neural network (DNN) accelerators and applications	Deep learning neural networks (DNNs) have been successful in solving a wide range of machine learning problems. Specialized hardware accelerators have been proposed to accelerate the execution of DNN algorithms for high-performance and energy efficiency. Recently, they have been deployed in datacenters (potentially for business-critical or industrial applications) and safety-critical systems such as self-driving cars. Soft errors caused by high-energy particles have been increasing in hardware systems, and these can lead to catastrophic failures in DNN systems. Traditional methods for building resilient systems, e.g., Triple Modular Redundancy (TMR), are agnostic of the DNN algorithm and the DNN accelerator's architecture. Hence, these traditional resilience approaches incur high overheads, which makes them challenging to deploy. In this paper, we experimentally evaluate the resilience characteristics of DNN systems (i.e., DNN software running on specialized accelerators). We find that the error resilience of a DNN system depends on the data types, values, data reuses, and types of layers in the design. Based on our observations, we propose two efficient protection techniques for DNN systems.		GuanpengLi; Siva Kumar SastryHari; MichaelSullivan; TimothyTsai; KarthikPattabiraman; JoelEmer; Stephen W.Keckler	SC '17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis	https://doi.org/10.1145/3126908.3126964		-12		Included	Included	new_screen			1	ACM	2017	 Understanding error propagation in deep learning neural network (DNN) accelerators and applications. 		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
45	TestNN	Verification Methodology for Fully Autonomous Heavy Vehicles	The introduction of fully autonomous vehicles posesa number of concerns regarding the safety and dependability ofvehicle operation. Best practice standards within the automotiveindustry rely on the driver operating the vehicle. With thetransition away from manual control, an increased emphasishas to be placed on verification during the vehicle developmentstages. The work presented within this paper aims to establisha framework for the various verification activities performedduring development, and their impact on the safety of the vehicle, as well as a set of guidelines for verification of the decision makingprocess of autonomous vehicles. © 2016 IEEE.	Crashworthiness; Decision making; Formal verification; Intelligent vehicle highway systems; Mathematical models; Safety testing; Software testing; Vehicles; Autonomous Vehicles; Fully-autonomous vehicles; Road vehicles; Safety and dependability; System testing; Vehicle safety; Verification activities; Verification methodology; Verification	Gustavsson, Joakim	Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016	https://doi.org/10.1109/ICST.2016.42		381 – 382	"@CONFERENCE{Gustavsson2016381,
    author = ""Gustavsson, Joakim"",
    title = ""Verification Methodology for Fully Autonomous Heavy Vehicles"",
    year = ""2016"",
    journal = ""Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016"",
    pages = ""381 – 382"",
    doi = ""10.1109/ICST.2016.42"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983371297\&doi=10.1109\%2fICST.2016.42\&partnerID=40\&md5=10d3bbe1c872db6bbde871c383304e48"",
    affiliations = ""Department of Mechatronics, KTH Royal Institute of Technology, Stockholm, Sweden"",
    abstract = ""The introduction of fully autonomous vehicles posesa number of concerns regarding the safety and dependability ofvehicle operation. Best practice standards within the automotiveindustry rely on the driver operating the vehicle. With thetransition away from manual control, an increased emphasishas to be placed on verification during the vehicle developmentstages. The work presented within this paper aims to establisha framework for the various verification activities performedduring development, and their impact on the safety of the vehicle, as well as a set of guidelines for verification of the decision makingprocess of autonomous vehicles. © 2016 IEEE."",
    author_keywords = ""Formal verification; Intelligent vehicles; Mathematical model; Road vehicles; System testing; Vehicle safety"",
    keywords = ""Crashworthiness; Decision making; Formal verification; Intelligent vehicle highway systems; Mathematical models; Safety testing; Software testing; Vehicles; Autonomous Vehicles; Fully-autonomous vehicles; Road vehicles; Safety and dependability; System testing; Vehicle safety; Verification activities; Verification methodology; Verification"",
    correspondence_address = ""J. Gustavsson; Department of Mechatronics, KTH Royal Institute of Technology, Stockholm, Sweden; email: joagusta@kth.se"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-150901826-0"",
    language = ""English"",
    abbrev_source_title = ""Proc. - IEEE Int. Conf. Softw. Test., Verification Valid., ICST"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 9th IEEE International Conference on Software Testing, Verification and Validation, ICST 2016; Conference date: 10 April 2016 through 15 April 2016; Conference code: 122841""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus	2016	 Verification Methodology for Fully Autonomous Heavy Vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983371297&doi=10.1109%2fICST.2016.42&partnerID=40&md5=10d3bbe1c872db6bbde871c383304e48	Institute of Electrical and Electronics Engineers Inc.	nan; References
46	TestNN	Verification of safety for autonomous unmanned ground vehicles	The existing tools for hardware and software reliability and safety engineering do not supply sufficient solutions regarding AI (Artificial Intelligent) adaptive and learning algorithms, which are being used in autonomous robotics and massively rely on designer experience and include methods such as Heuristic, Rules based decision, Fuzzy Logic, Neural Networks, and Genetic Algorithms, Bayes Networks, etc. Since it is obvious that only this kind of algorithms can deal with the complexity and the uncertainty of the real world environment, suitable safety validation methodology is required. In this paper we present the limitation of the existing reliability and safety engineering tools in dealing with autonomous systems and propose a novel methodology based on statistical testing in simulated environment.		Daniel Meltz; Hugo Guterman	2014 IEEE 28th Convention of Electrical & Electronics Engineers in Israel (IEEEI)	https://doi.org/10.1109/EEEI.2014.7005895				Excluded	Excluded	new_screen		Exclusion: low quality-lack sufficient information	1	IEEE	2014	 Verification of safety for autonomous unmanned ground vehicles		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
47	TestNN	Work-in-progress: Testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks	Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional flters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator. © 2017 Copyright held by the owner/author(s).	Convolution; Cyber Physical System; Embedded software; Embedded systems; Learning systems; Neural networks; Open source software; Computer vision algorithms; Convolutional neural network; Cyber physical systems (CPSs); High resolution; Modern machines; Pedestrian detection; Visual sensory; Work in progress; Deep neural networks	Raj, Sunny; Jha, Sumit Kumar; Ramanathan, Arvind; Pullum, Laura L.	Proceedings of the 13th ACM International Conference on Embedded Software 2017 Companion, EMSOFT 2017	https://doi.org/10.1145/3125503.3125568			"@CONFERENCE{Raj2017,
    author = ""Raj, Sunny and Jha, Sumit Kumar and Ramanathan, Arvind and Pullum, Laura L."",
    title = ""Work-in-progress: Testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks"",
    year = ""2017"",
    journal = ""Proceedings of the 13th ACM International Conference on Embedded Software 2017 Companion, EMSOFT 2017"",
    doi = ""10.1145/3125503.3125568"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034850699\&doi=10.1145\%2f3125503.3125568\&partnerID=40\&md5=d8731a242990b5e245d8fb028ed23508"",
    affiliations = ""Computer Science Department, University of Central Florida, Orlando, FL, United States; Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States"",
    abstract = ""Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional flters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator. © 2017 Copyright held by the owner/author(s)."",
    keywords = ""Convolution; Cyber Physical System; Embedded software; Embedded systems; Learning systems; Neural networks; Open source software; Computer vision algorithms; Convolutional neural network; Cyber physical systems (CPSs); High resolution; Modern machines; Pedestrian detection; Visual sensory; Work in progress; Deep neural networks"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035186-7"",
    language = ""English"",
    abbrev_source_title = ""Proc. ACM Int. Conf. Embed. Softw. Companion, EMSOFT"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: 13th ACM International Conference on Embedded Software, EMSOFT 2017; Conference date: 15 October 2017 through 20 October 2017; Conference code: 131251; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	 Work-in-progress: testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034850699&doi=10.1145%2f3125503.3125568&partnerID=40&md5=d8731a242990b5e245d8fb028ed23508	Association for Computing Machinery, Inc	nan; References; Pages
48	TestNN	A cognitive agent aboard remotely piloted aircraft systems: Development, evaluation, and certification issues	In future air traffic scenarios, remotely piloted aircraft systems are likely to play an increasingly important role. A major use case and subject of research is loss of command and control data link. Therefore, a novel engineering solution is described, which makes use of knowledge-based information processing methods for the implementation of higher cognitive functions in an artificial agent. This agent shall be integrated aboard the airborne vehicle and shall work in a cooperative relationship with the human pilot on the ground for his or her support. With the provision of functional redundancy in flight guidance and mission management related decision-making the overall system safety shall be improved. The article captures the whole development process of the agent including concept, requirements definition, system design, implementation and evaluation. The interactions between the human and the cognitive agent are discussed and the necessity to augment the conventional human-machine interface is deduced. A scenario-based usability study with a group of pilots in addition to real flight tests to evaluate the developed system is described. In addition, considerations on certifiability of such an artificial cognitive associate system are presented. © Institution of Mechanical Engineers.	Command and control systems; Decision making; Fighter aircraft; Human computer interaction; Intelligent agents; Knowledge based systems; Man machine systems; Redundancy; Remote control; Unmanned aerial vehicles (UAV); Cognitive agents; Cooperative relationships; Engineering solutions; Human machine interaction; Human Machine Interface; Pilot assistance; Remotely piloted aircraft; Requirements definition; Cognitive systems	Wohler, Marcus; Schulte, Axel	Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering	https://doi.org/10.1177/0954410015613115		1694 – 1704	"@ARTICLE{Wohler20161694,
    author = ""Wohler, Marcus and Schulte, Axel"",
    title = ""A cognitive agent aboard remotely piloted aircraft systems: Development, evaluation, and certification issues"",
    year = ""2016"",
    journal = ""Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering"",
    volume = ""230"",
    number = ""9"",
    pages = ""1694 – 1704"",
    doi = ""10.1177/0954410015613115"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979049900\&doi=10.1177\%2f0954410015613115\&partnerID=40\&md5=d60629545fb087855fa0dcd105b4eaa8"",
    affiliations = ""Institute of Flight Systems, Aerospace Engineering Department, Bundeswehr University, Munich, Neubiberg, 85577, Germany"",
    abstract = ""In future air traffic scenarios, remotely piloted aircraft systems are likely to play an increasingly important role. A major use case and subject of research is loss of command and control data link. Therefore, a novel engineering solution is described, which makes use of knowledge-based information processing methods for the implementation of higher cognitive functions in an artificial agent. This agent shall be integrated aboard the airborne vehicle and shall work in a cooperative relationship with the human pilot on the ground for his or her support. With the provision of functional redundancy in flight guidance and mission management related decision-making the overall system safety shall be improved. The article captures the whole development process of the agent including concept, requirements definition, system design, implementation and evaluation. The interactions between the human and the cognitive agent are discussed and the necessity to augment the conventional human-machine interface is deduced. A scenario-based usability study with a group of pilots in addition to real flight tests to evaluate the developed system is described. In addition, considerations on certifiability of such an artificial cognitive associate system are presented. © Institution of Mechanical Engineers."",
    author_keywords = ""Cognitive agent; human-machine interaction; pilot assistance; redundancy; remotely piloted aircraft systems"",
    keywords = ""Command and control systems; Decision making; Fighter aircraft; Human computer interaction; Intelligent agents; Knowledge based systems; Man machine systems; Redundancy; Remote control; Unmanned aerial vehicles (UAV); Cognitive agents; Cooperative relationships; Engineering solutions; Human machine interaction; Human Machine Interface; Pilot assistance; Remotely piloted aircraft; Requirements definition; Cognitive systems"",
    correspondence_address = ""A. Schulte; Institute of Flight Systems, Aerospace Engineering Department, Bundeswehr University, Munich, Neubiberg, 85577, Germany; email: axel.schulte@unibw.de"",
    publisher = ""SAGE Publications Ltd"",
    issn = ""09544100"",
    coden = ""PMGEE"",
    language = ""English"",
    abbrev_source_title = ""Proc. Inst. Mech. Eng. Part G J. Aerosp. Eng."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2016	A cognitive agent aboard remotely piloted aircraft systems: development, evaluation, and certification issues	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979049900&doi=10.1177%2f0954410015613115&partnerID=40&md5=d60629545fb087855fa0dcd105b4eaa8	SAGE Publications Ltd	nan; References
49	TestNN	A Motion Certification Concept to Evaluate Operational Safety and Optimizing Operating Parameters at Runtime	For technical systems, which perform highly automated or so-called autonomous actions, there exist a large demand to evaluate their operational safety in a uniform way at runtime based on the combination of environmental threats and the conditions of subordinated system modules. To guarantee a safe motion based on autonomous decisions we have introduced a universal and transparent certification process which not only takes functional aspects like environment detection and collision avoidance techniques into account but especially identifies the associated system condition itself as a key aspect for the determination of operational safety and for an automated optimization of operating parameters. Similar to a feedback loop possible constraints for environment perception of sensor components or the ability of actuator components to interact with their environment have to be taken into account to introduce a generalized safetyevaluation for the entire system. Therefore, a model is derived to evaluate the operational safety for the autonomous driving robot RAVON from TU Kaiserslautern based on an integrated behavior-based control (IB2C).		Sebastian Müller15&; Peter Liggesmeyer15	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-319-24249-1_14		pp 156–166		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2015	A motion certification concept to evaluate operational safety and optimizing operating parameters at runtime		Springer, Cham	nan; Keywords; References; Year; Bibtex; Link
50	TestNN	Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision	Lane detection is a fundamental aspect of most current advanced driver assistance systems U+0028 ADASs U+0029. A large number of existing results focus on the study of vision-based lane detection methods due to the extensive knowledge background and the low-cost of camera devices. In this paper, previous vision-based lane detection studies are reviewed in terms of three aspects, which are lane detection algorithms, integration, and evaluation methods. Next, considering the inevitable limitations that exist in the camera-based lane detection system, the system integration methodologies for constructing more robust detection systems are reviewed and analyzed. The integration methods are further divided into three levels, namely, algorithm, system, and sensor. Algorithm level combines different lane detection algorithms while system level integrates other object detection systems to comprehensively detect lane positions. Sensor level uses multi-modal sensors to build a robust lane recognition system. In view of the complexity of evaluating the detection system, and the lack of common evaluation procedure and uniform metrics in past studies, the existing evaluation methods and metrics are analyzed and classified to propose a better evaluation of the lane detection system. Next, a comparison of representative studies is performed. Finally, a discussion on the limitations of current lane detection systems and the future developing trends toward an Artificial Society, Computational experiment-based parallel lane detection framework is proposed. © 2014 Chinese Association of Automation.	Automobile drivers; Benchmarking; Cameras; Object detection; Signal detection; Acp theories; Artificial societies; Computational experiment; Lane detection; Object detection systems; Parallel vision; performance evaluation; System integration; Advanced driver assistance systems	Xing, Yang; Lv, Chen; Chen, Long; Wang, Huaji; Wang, Hong; Cao, Dongpu; Velenis, Efstathios; Wang, Fei-Yue	IEEE/CAA Journal of Automatica Sinica	https://doi.org/10.1109/JAS.2018.7511063		645 – 661	"@ARTICLE{Xing2018645,
    author = ""Xing, Yang and Lv, Chen and Chen, Long and Wang, Huaji and Wang, Hong and Cao, Dongpu and Velenis, Efstathios and Wang, Fei-Yue"",
    title = ""Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision"",
    year = ""2018"",
    journal = ""IEEE/CAA Journal of Automatica Sinica"",
    volume = ""5"",
    number = ""3"",
    pages = ""645 – 661"",
    doi = ""10.1109/JAS.2018.7511063"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045300346\&doi=10.1109\%2fJAS.2018.7511063\&partnerID=40\&md5=9c0328fd71b91b8c7a5f0f33fe36e891"",
    affiliations = ""Advanced Vehicle Engineering Centre, Cranfield University, Bedford, MK43 0AL, United Kingdom; Vehicle Intelligence Pioneers Ltd, Qingdao, 266000, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, China; Mechanical and Mechatronics Engineering, University of Waterloo, 200 University Avenue West Waterloo, N2L 3G1, ON, Canada; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China"",
    abstract = ""Lane detection is a fundamental aspect of most current advanced driver assistance systems U+0028 ADASs U+0029. A large number of existing results focus on the study of vision-based lane detection methods due to the extensive knowledge background and the low-cost of camera devices. In this paper, previous vision-based lane detection studies are reviewed in terms of three aspects, which are lane detection algorithms, integration, and evaluation methods. Next, considering the inevitable limitations that exist in the camera-based lane detection system, the system integration methodologies for constructing more robust detection systems are reviewed and analyzed. The integration methods are further divided into three levels, namely, algorithm, system, and sensor. Algorithm level combines different lane detection algorithms while system level integrates other object detection systems to comprehensively detect lane positions. Sensor level uses multi-modal sensors to build a robust lane recognition system. In view of the complexity of evaluating the detection system, and the lack of common evaluation procedure and uniform metrics in past studies, the existing evaluation methods and metrics are analyzed and classified to propose a better evaluation of the lane detection system. Next, a comparison of representative studies is performed. Finally, a discussion on the limitations of current lane detection systems and the future developing trends toward an Artificial Society, Computational experiment-based parallel lane detection framework is proposed. © 2014 Chinese Association of Automation."",
    author_keywords = ""ACP theory; Advanced driver assistance systems (ADASs); benchmark; lane detection; parallel vision; performance evaluation"",
    keywords = ""Automobile drivers; Benchmarking; Cameras; Object detection; Signal detection; Acp theories; Artificial societies; Computational experiment; Lane detection; Object detection systems; Parallel vision; performance evaluation; System integration; Advanced driver assistance systems"",
    correspondence_address = ""D. Cao; Mechanical and Mechatronics Engineering, University of Waterloo, 200 University Avenue West Waterloo, N2L 3G1, Canada; email: d.cao@cranfield.ac.uk"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""23299266"",
    language = ""English"",
    abbrev_source_title = ""IEEE CAA J. Autom. Sin."",
    type = ""Review"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 136; All Open Access, Bronze Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: review paper	1	Scopus	2018	Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045300346&doi=10.1109%2fJAS.2018.7511063&partnerID=40&md5=9c0328fd71b91b8c7a5f0f33fe36e891	Institute of Electrical and Electronics Engineers Inc.	nan; References
51	TestNN	An efficient phased mission reliability analysis for autonomous vehicles	Autonomous systems are becoming more commonly used, especially in hazardous situations. Such systems are expected to make their own decisions about future actions when some capabilities degrade due to failures of their subsystems. Such decisions are made without human input, therefore they need to be well-informed in a short time when the situation is analysed and future consequences of the failure are estimated. The future planning of the mission should take account of the likelihood of mission failure. The reliability analysis for autonomous systems can be performed using the methodologies developed for phased mission analysis, where the causes of failure for each phase in the mission can be expressed by fault trees. Unmanned autonomous vehicles (UAVs) are of a particular interest in the aeronautical industry, where it is a long term ambition to operate them routinely in civil airspace. Safety is the main requirement for the UAV operation and the calculation of failure probability of each phase and the overall mission is the topic of this paper. When components or subsystems fail or environmental conditions throughout the mission change, these changes can affect the future mission. The new proposed methodology takes into account the available diagnostics data and is used to predict future capabilities of the UAV in real time. Since this methodology is based on the efficient BDD method, the quickly provided advice can be used in making decisions. When failures occur appropriate actions are required in order to preserve safety of the autonomous vehicle. The overall decision making strategy for autonomous vehicles is explained in this paper. Some limitations of the methodology are discussed and further improvements are presented based on experimental results. © 2009 Elsevier Ltd. All rights reserved.	Binary decision diagrams; Decision making; Failure analysis; Reliability analysis; Remotely operated vehicles; Unmanned aerial vehicles (UAV); Vehicles; Autonomous system; Autonomous systems; Autonomous Vehicles; Civil airspace; Decision-making strategies; Environmental conditions; Failure Probability; Fault-trees; Future mission; Future planning; Long term; Making decision; Phased mission; Real time; Unmanned autonomous vehicles; Quality assurance	Remenyte-Prescott, R.; Andrews, J.D.; Chung, P.W.H.	Reliability Engineering and System Safety	https://doi.org/10.1016/j.ress.2009.10.002		226 – 235	"@ARTICLE{Remenyte-Prescott2010226,
    author = ""Remenyte-Prescott, R. and Andrews, J.D. and Chung, P.W.H."",
    title = ""An efficient phased mission reliability analysis for autonomous vehicles"",
    year = ""2010"",
    journal = ""Reliability Engineering and System Safety"",
    volume = ""95"",
    number = ""3"",
    pages = ""226 – 235"",
    doi = ""10.1016/j.ress.2009.10.002"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-73649107872\&doi=10.1016\%2fj.ress.2009.10.002\&partnerID=40\&md5=a928899598a3420e9f0e763b3edb6bc5"",
    affiliations = ""Nottingham Transportation Engineering Centre, Faculty of Engineering, University of Nottingham, Nottingham, NG7 2RD England, United Kingdom; Department of Computer Science, Loughborough University, Loughborough, LE11 3TU England, United Kingdom"",
    abstract = ""Autonomous systems are becoming more commonly used, especially in hazardous situations. Such systems are expected to make their own decisions about future actions when some capabilities degrade due to failures of their subsystems. Such decisions are made without human input, therefore they need to be well-informed in a short time when the situation is analysed and future consequences of the failure are estimated. The future planning of the mission should take account of the likelihood of mission failure. The reliability analysis for autonomous systems can be performed using the methodologies developed for phased mission analysis, where the causes of failure for each phase in the mission can be expressed by fault trees. Unmanned autonomous vehicles (UAVs) are of a particular interest in the aeronautical industry, where it is a long term ambition to operate them routinely in civil airspace. Safety is the main requirement for the UAV operation and the calculation of failure probability of each phase and the overall mission is the topic of this paper. When components or subsystems fail or environmental conditions throughout the mission change, these changes can affect the future mission. The new proposed methodology takes into account the available diagnostics data and is used to predict future capabilities of the UAV in real time. Since this methodology is based on the efficient BDD method, the quickly provided advice can be used in making decisions. When failures occur appropriate actions are required in order to preserve safety of the autonomous vehicle. The overall decision making strategy for autonomous vehicles is explained in this paper. Some limitations of the methodology are discussed and further improvements are presented based on experimental results. © 2009 Elsevier Ltd. All rights reserved."",
    author_keywords = ""Autonomous system; Binary decision diagram; Fault tree; Phased mission; Reliability"",
    keywords = ""Binary decision diagrams; Decision making; Failure analysis; Reliability analysis; Remotely operated vehicles; Unmanned aerial vehicles (UAV); Vehicles; Autonomous system; Autonomous systems; Autonomous Vehicles; Civil airspace; Decision-making strategies; Environmental conditions; Failure Probability; Fault-trees; Future mission; Future planning; Long term; Making decision; Phased mission; Real time; Unmanned autonomous vehicles; Quality assurance"",
    correspondence_address = ""R. Remenyte-Prescott; Nottingham Transportation Engineering Centre, Faculty of Engineering, University of Nottingham, Nottingham, NG7 2RD England, United Kingdom; email: R.Remenyte-Prescott@nottingham.ac.uk"",
    issn = ""09518320"",
    coden = ""RESSE"",
    language = ""English"",
    abbrev_source_title = ""Reliab Eng Syst Saf"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 55; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2010	An efficient phased mission reliability analysis for autonomous vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-73649107872&doi=10.1016%2fj.ress.2009.10.002&partnerID=40&md5=a928899598a3420e9f0e763b3edb6bc5		nan; References; Publisher
52	TestNN	Autonomous cognition and recovery controller design of UAV spiral	Aiming at dealing with the spiral recovery puzzle of aerial vehicles, we put forward an autonomous spiral cognition and recovery control method of the unmanned aerial vehicle(UAV). First of all, the safety control framework of unmanned aerial vehicles(UAV) based on flight state-cognition is built and the autonomous spiral cognition and recovery controller is designed. Then, the spiral factors are analyzed and the spiral state is recognized by using intuitive fuzzy statistic adjudging and decision-making algorithm according to timing flight variables information afforded by airborne sensors. Finally, the control scheduling of state variables is considered, and nonlinear dynamic inversion control laws are designed, which accomplish the guidance and control of the UAV spiral. Simulation results and their analysis suggest that, compared with the existing strategies, the proposed control method can decrease the time needed for spiral recovery evidently and meanwhile has good dynamic response characteristics. © 2015, Northwestern Polytechnical University. All right reserved.	Air navigation; Aircraft control; Aneroid altimeters; Angle of attack; Angular velocity; Computer control systems; Computer simulation; Computer system recovery; Control; Control surfaces; Control theory; Damping; Data fusion; Decision making; Degrees of freedom (mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight dynamics; Flight simulators; Free flight; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Navigation systems; Probability; Real time control; Real time systems; Recovery; Safety engineering; Scheduling; Sensors; Statistics; Time series; Tracking (position); Unmanned aerial vehicles (UAV); Vehicles; Velocity; Cognition; Control laws; Flight state; Nonlinear dynamic inversion; Safety controls; Spiral statistic adjudging; Controllers	Huang, Hanqiao; Zhao, Xin; Zhou, Huan; Wang, Zutong	Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University			879 – 886	"@ARTICLE{Huang2015879,
    author = ""Huang, Hanqiao and Zhao, Xin and Zhou, Huan and Wang, Zutong"",
    title = ""Autonomous cognition and recovery controller design of UAV spiral"",
    year = ""2015"",
    journal = ""Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University"",
    volume = ""33"",
    number = ""6"",
    pages = ""879 – 886"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954213963\&partnerID=40\&md5=936bb8b273f4cca1068d53267c6b6283"",
    affiliations = ""Aeronautics and Astronautics Engineering College, Air Force Engineering University, Xi'an, 710038, China; Northwestern Polytechnic University, Xi'an, 710038, China"",
    abstract = ""Aiming at dealing with the spiral recovery puzzle of aerial vehicles, we put forward an autonomous spiral cognition and recovery control method of the unmanned aerial vehicle(UAV). First of all, the safety control framework of unmanned aerial vehicles(UAV) based on flight state-cognition is built and the autonomous spiral cognition and recovery controller is designed. Then, the spiral factors are analyzed and the spiral state is recognized by using intuitive fuzzy statistic adjudging and decision-making algorithm according to timing flight variables information afforded by airborne sensors. Finally, the control scheduling of state variables is considered, and nonlinear dynamic inversion control laws are designed, which accomplish the guidance and control of the UAV spiral. Simulation results and their analysis suggest that, compared with the existing strategies, the proposed control method can decrease the time needed for spiral recovery evidently and meanwhile has good dynamic response characteristics. © 2015, Northwestern Polytechnical University. All right reserved."",
    author_keywords = ""Aneroid altimeters; Angle of attack; Angular velocity; Cognition; Computer simulation; Control; Control law; Control scheduling; Control surfaces; Controllers; Damping; Data fusion; Decision making; Degrees of freedom(mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight state; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Nonlinear dynamic inversion(NDI); Probability; Real time control; Recovery; Safety control; Safety engineering; Scheduling; Sensors; Spiral statistic adjudging; Statistics; Time series; Unmanned aerial vehicles(UAV); Velocity"",
    keywords = ""Air navigation; Aircraft control; Aneroid altimeters; Angle of attack; Angular velocity; Computer control systems; Computer simulation; Computer system recovery; Control; Control surfaces; Control theory; Damping; Data fusion; Decision making; Degrees of freedom (mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight dynamics; Flight simulators; Free flight; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Navigation systems; Probability; Real time control; Real time systems; Recovery; Safety engineering; Scheduling; Sensors; Statistics; Time series; Tracking (position); Unmanned aerial vehicles (UAV); Vehicles; Velocity; Cognition; Control laws; Flight state; Nonlinear dynamic inversion; Safety controls; Spiral statistic adjudging; Controllers"",
    publisher = ""Northwestern Polytechnical University"",
    issn = ""10002758"",
    coden = ""XGDUE"",
    language = ""Chinese"",
    abbrev_source_title = ""Xibei Gongye Daxue Xuebao"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0""
}
"	Excluded	Excluded	new_screen		Exclusion: not written in English	1	Scopus	2015	Autonomous cognition and recovery controller design of UAV spiral	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954213963&partnerID=40&md5=936bb8b273f4cca1068d53267c6b6283	Northwestern Polytechnical University	nan; References; DOI
53	TestNN	Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning	Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading.		George Loukas; Tuan Vuong; Ryan Heartfield; Georgia Sakellari; Yongpil Yoon; Diane Gan	IEEE Access	https://doi.org/10.1109/ACCESS.2017.2782159				Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2018	Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
54	TestNN	DeepTest: Automated testing of deep-neural-network-driven autonomous cars	Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge. © 2018 Association for Computing Machinery.	Accidents; Automatic test pattern generation; Automobile manufacture; Autonomous vehicles; Deep learning; Digital storage; Information dissemination; Neural networks; Rain; Software engineering; Tellurium compounds; Testing; Automatically generated; Driving conditions; Human intervention; Lighting conditions; Potentially fatal; Real world accidents; Systematic testing; Testing technique; Deep neural networks	Jana, Suman; Tian, Yuchi; Pei, Kexin; Ray, Baishakhi	Proceedings - International Conference on Software Engineering	https://doi.org/10.1145/3180155.3180220			"@CONFERENCE{Jana2018,
    author = ""Jana, Suman and Tian, Yuchi and Pei, Kexin and Ray, Baishakhi"",
    title = ""DeepTest: Automated testing of deep-neural-network-driven autonomous cars"",
    year = ""2018"",
    journal = ""Proceedings - International Conference on Software Engineering"",
    volume = ""2018-May"",
    doi = ""10.1145/3180155.3180220"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069772253\&doi=10.1145\%2f3180155.3180220\&partnerID=40\&md5=bd81c43f9e437a21d2524b38678cb67f"",
    affiliations = ""Columbia University, United States; University of Virginia, United States"",
    abstract = ""Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge. © 2018 Association for Computing Machinery."",
    author_keywords = ""Autonomous vehicle; Deep learning; Deep neural networks; Neuron coverage; Self-driving cars; Testing"",
    keywords = ""Accidents; Automatic test pattern generation; Automobile manufacture; Autonomous vehicles; Deep learning; Digital storage; Information dissemination; Neural networks; Rain; Software engineering; Tellurium compounds; Testing; Automatically generated; Driving conditions; Human intervention; Lighting conditions; Potentially fatal; Real world accidents; Systematic testing; Testing technique; Deep neural networks"",
    publisher = ""IEEE Computer Society"",
    issn = ""02705257"",
    isbn = ""978-145035663-3"",
    coden = ""PCSED"",
    language = ""English"",
    abbrev_source_title = ""Proc Int Conf Software Eng"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 882; Conference name: 40th International Conference on Software Engineering, ICSE 2018; Conference date: 27 May 2018 through 3 June 2018; Conference code: 137142; All Open Access, Bronze Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	DeepTest: Automated testing of deep-neural-network-driven autonomous cars	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069772253&doi=10.1145%2f3180155.3180220&partnerID=40&md5=bd81c43f9e437a21d2524b38678cb67f	IEEE Computer Society	nan; References; Pages
55	TestNN	Distilling a neural network into a soft decision tree	Deep neural networks have proved to be a very e ective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large [Szegedy et al., 2015, Wu et al., 2016, Jozefowicz et al., 2016, Graves et al., 2013]. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data. Copyright © 2018 for this paper by its authors. Copying permitted for private and academic purposes.	Decision trees; Deep neural networks; Trees (mathematics); Classification decision; Classification tasks; Hierarchical decisions; Hierarchical representation; High-dimensional; Soft decision; Training data; Training example; Neural networks	Frosst, Nicholas; Hinton, Geo rey	CEUR Workshop Proceedings				"@CONFERENCE{Frosst2018,
    author = ""Frosst, Nicholas and Hinton, Geo rey"",
    editor = ""O., Kutz and T.R., Besold"",
    title = ""Distilling a neural network into a soft decision tree"",
    year = ""2018"",
    journal = ""CEUR Workshop Proceedings"",
    volume = ""2071"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045439769\&partnerID=40\&md5=d68db18b132ae555e8babf5608514fb9"",
    affiliations = ""Google Brain Team, United States"",
    abstract = ""Deep neural networks have proved to be a very e ective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large [Szegedy et al., 2015, Wu et al., 2016, Jozefowicz et al., 2016, Graves et al., 2013]. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data. Copyright © 2018 for this paper by its authors. Copying permitted for private and academic purposes."",
    keywords = ""Decision trees; Deep neural networks; Trees (mathematics); Classification decision; Classification tasks; Hierarchical decisions; Hierarchical representation; High-dimensional; Soft decision; Training data; Training example; Neural networks"",
    publisher = ""CEUR-WS"",
    issn = ""16130073"",
    language = ""English"",
    abbrev_source_title = ""CEUR Workshop Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 19; Conference name: 1st International Workshop on Comprehensibility and Explanation in AI and ML, CEX 2017; Conference date: 16 November 2017 through 17 November 2017; Conference code: 135275""
}
"	Included	Included	new_screen			1	Scopus	2017	Distilling a Neural Network Into a Soft Decision Tree	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045439769&partnerID=40&md5=d68db18b132ae555e8babf5608514fb9	CEUR-WS	nan; References; Pages; DOI
56	TestNN	Exploring Strategies for Training Deep Neural Networks	Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.		HugoLarochelle; YoshuaBengio; JérômeLouradour; PascalLamblin	The Journal of Machine Learning Research	https://doi.org/10.5555/1577069.1577070		-40		Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	ACM	2009	Exploring Strategies for Training Deep Neural Networks		JMLR.org	nan; Keywords; References; Year; Bibtex; Link
57	TestNN	Failing to Learn: Autonomously Identifying Perception Failures for Self-Driving Cars	"One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application, such as autonomous driving, the error rates of the current state of the art are still too high to enable safe operation. Moreover, the characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this letter, we propose an automated method to identify mistakes made by object detectors 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">without ground truth labels</i>
. We show that inconsistencies in the object detector output between a pair of similar images can be used as hypotheses for false negatives (e.g., missed detections) and using a novel set of features for each hypothesis, an off-the-shelf binary classifier can be used to find valid errors. In particular, we study two distinct cues–
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">temporal</i>
 and 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">stereo </i>
 inconsistencies—using data that are readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we illustrate the technique on several sets of real world data. We show that a state-of-the-art detector, tracker, and our classifier trained only on synthetic data can identify valid errors on KITTI tracking dataset with an average precision of 0.94. We also release a new tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo images along with ground truth disparity from a game engine to facilitate further research."		Manikandasriram Srinivasan Ramanagopal; Cyrus Anderson; Ram Vasudevan; Matthew Johnson-Roberson	IEEE Robotics and Automation Letters	https://doi.org/10.1109/LRA.2018.2857402				Included	Included	new_screen			1	IEEE	2017	Failing to learn: autonomously identifying perception failures for self-driving cars [arXiv]		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
58	TestNN	Feature-Guided Black-Box Safety Testing of Deep Neural Networks	Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. Most existing approaches for crafting adversarial examples necessitate some knowledge (architecture, parameters, etc) of the network at hand. In this paper, we focus on image classifiers and propose afeature-guidedblack-box approach to test the safety of deep neural networks that requires no such knowledge. Our algorithm employs object detection techniques such as SIFT (Scale Invariant Feature Transform) to extract features from an image. These features are converted into a mutable saliency distribution, where high probability is assigned to pixels that affect the composition of the image with respect to the human visual system. We formulate the crafting of adversarial examples as a two-player turn-based stochastic game, where the first player’s objective is to minimise the distance to an adversarial example by manipulating the features, and the second player can be cooperative, adversarial, or random. We show that, theoretically, the two-player game can converge to the optimal strategy, and that the optimal strategy represents a globally minimal adversarial image. For Lipschitz networks, we also identify conditions that provide safety guarantees that no adversarial examples exist. Using Monte Carlo tree search we gradually explore the game state space to search for adversarial examples. Our experiments show that, despite the black-box setting, manipulations guided by a perception-based saliency distribution are competitive with state-of-the-art methods that rely on white-box saliency matrices or sophisticated optimization procedures. Finally, we show how our method can be used to evaluate robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.	Deep Neural Networks; Adversarial Examples; Monte Carlo Tree Search (MCTS); Scale Invariant Feature Transform (SIFT); Saliency Distribution	Matthew Wicker15,; Xiaowei Huang16&; Marta Kwiatkowska17	International Conference on Tools and Algorithms for the Construction and Analysis of Systems	https://doi.org/10.1007/978-3-319-89960-2_22		pp 408–426		Included	Included	new_screen			1	SpringerLink	2018	Feature-guided black-box safety testing of deep neural networks		Springer, Cham	nan; References; Year; Bibtex; Link
59	TestNN	Formal verification of autonomous vehicle platooning	"<div class=""abstract author-highlights"" id=""ab0020""><h2 class=""section-title u-h4 u-margin-l-top u-margin-xs-bottom"">Highlights</h2><div id=""as0020""><p id=""sp0120""></p><ul class=""list""><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""pr0010"">A combined methodology for the formal verification of autonomous automotive platooning is proposed.</p></span></li><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""pr0020"">Program model-checking is applied for verification of the “actual” agent code used in the implementation of platooning.</p></span></li><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""pr0030"">A model of the agent code is extracted and used for the verification of real-time properties for the system.</p></span></li></ul><p></p></div></div>"	Vehicle platooning; Agent programming; Model checking	Kamali, M., L. A. Dennis, O. McAree, M. Fisher and S. M. Veres	Science of Computer Programming	https://doi.org/10.1016/j.scico.2017.05.006		Volume 148,15 November 2017, Pages 		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ScienceDirect	2017	Formal verification of autonomous vehicle platooning		Science Direct	nan; Authors; References; Year; Bibtex; Link
60	TestNN	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. © 1993-2012 IEEE.	Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles	Li, Nan; Oyler, Dave W.; Zhang, Mengxuan; Yildiz, Yildiray; Kolmanovsky, Ilya; Girard, Anouck R.	IEEE Transactions on Control Systems Technology	https://doi.org/10.1109/TCST.2017.2723574		1782 – 1797	"@ARTICLE{Li20181782,
    author = ""Li, Nan and Oyler, Dave W. and Zhang, Mengxuan and Yildiz, Yildiray and Kolmanovsky, Ilya and Girard, Anouck R."",
    title = ""Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems"",
    year = ""2018"",
    journal = ""IEEE Transactions on Control Systems Technology"",
    volume = ""26"",
    number = ""5"",
    pages = ""1782 – 1797"",
    doi = ""10.1109/TCST.2017.2723574"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873\&doi=10.1109\%2fTCST.2017.2723574\&partnerID=40\&md5=886568f3ecc536e5329fc3b743b980a4"",
    affiliations = ""Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, MI, United States; Department of Mechanical Engineering, Bilkent University, Ankara, 06800, Turkey"",
    abstract = ""Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. © 1993-2012 IEEE."",
    author_keywords = ""Autonomous vehicles; game theory; reinforcement learning (RL); traffic modeling; verification and validation (V\&V)"",
    keywords = ""Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles"",
    correspondence_address = ""N. Li; Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, United States; email: nanli@umich.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10636536"",
    coden = ""IETTE"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans Control Syst Technol"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 184; All Open Access, Bronze Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	Game Theoretic Modeling of Driver and Vehicle Interactions for Verification and Validation of Autonomous Vehicle Control Systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873&doi=10.1109%2fTCST.2017.2723574&partnerID=40&md5=886568f3ecc536e5329fc3b743b980a4	Institute of Electrical and Electronics Engineers Inc.	nan; References
61	TestNN	Measurement of autonomous operation	"While robotic systems and the field of Artificial Intelligence (AI) have been funded through the Department Of Defense (DoD) and Industry for decades, it was not until recent years that the combination of these two technologies has made truly significant advances in the area of Autonomous Operation (AO) systems. Through the efforts of the Defense Advanced Research Project Agency (DARPA) challenges in 2004--2007 timeframe, the academic and industrial communities came together to overcome some significant hurdles for the development of AO ground vehicles in both the rural and desert environments (DARPA Grand Challenge 2004--2005) and the urban environment (DARPA Urban Challenge 2007). Although no AO vehicle succeeded in the 2004 event, the following year four systems completed the 132 mile course within the 10 hour time limit. The winner of the 2005 event (The Stanley from Stanford University) designed an autonomous (learning system) vehicle that fused five Lidars, Radar, and an Electro Optic sensor in addition to the waypoint GPS (provided by DARPA) and an internal Inertial Measurement Unit (IMU) system to produce the situational awareness required to meet the challenge. The team took approximately one year ""training"" the perception and planning sections of the software to compensate for various types of terrain and maneuvering. It was through extensive planning, meticulous design, and thorough testing that the final goal was achieved and it will take a much greater level of effort for DoD to realize a similar capability in the air environment."		W.Hamel	PerMIS '10: Proceedings of the 10th Performance Metrics for Intelligent Systems Workshop	https://doi.org/10.1145/2377576.2377598		12-118		Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	ACM	2010	Measurement of autonomous operation		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
62	TestNN	Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents	Data on traffic accidents clearly point to road black spots, where the accident rate is always high. However, road safety research is still far from understanding why these particular places on a road are risky. The reason is the lack of sufficient knowledge on how pedestrians and drivers interact when facing a potentially dangerous traffic situation, and the lack of an integrated framework that relates the data on human behavior to real-world traffic situations. We attempt to tackle this problem by developing SAFEPED, a multi-agent microscopic three-dimensional (3D) simulation of vehicle and pedestrian dynamics at a black spot. SAFEPED is a test platform for evaluating experimentally estimated drivers and pedestrians behavioral rules, and estimating accident risks in different traffic situations. It aims to analyze the design of existing and future black spots and to assess alternative architectural and environmental solutions in order to identify maximally efficient safety countermeasures. © 2015 Taylor and Francis Group, LLC.	Behavioral research; Computational methods; Computer simulation; Motor transportation; Multi agent systems; Pedestrian safety; Risk assessment; Risk perception; Roads and streets; Agent-based model; Black spot; Integrated frameworks; Microsimulation models; Pedestrian dynamics; Safety countermeasures; Spatially explicit modeling; Three-dimensional (3-D) simulation; accident; numerical model; optimization; road transport; simulation; traffic management; transportation safety; transportation system; Highway accidents	Waizman, Gennady; Shoval, Shraga; Benenson, Itzhak	Journal of Intelligent Transportation Systems: Technology, Planning, and Operations	https://doi.org/10.1080/15472450.2013.856721		63 – 77	"@ARTICLE{Waizman201563,
    author = ""Waizman, Gennady and Shoval, Shraga and Benenson, Itzhak"",
    title = ""Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents"",
    year = ""2015"",
    journal = ""Journal of Intelligent Transportation Systems: Technology, Planning, and Operations"",
    volume = ""19"",
    number = ""1"",
    pages = ""63 – 77"",
    doi = ""10.1080/15472450.2013.856721"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924037275\&doi=10.1080\%2f15472450.2013.856721\&partnerID=40\&md5=700f408fd9b18ba78cb22fd167ae4fcd"",
    affiliations = ""Department of Geography and Human Environment, Tel Aviv University, Ramat Aviv, 69978, Tel Aviv, Israel; Department of Industrial Engineering and Management, Ariel University, Ariel, Israel"",
    abstract = ""Data on traffic accidents clearly point to road black spots, where the accident rate is always high. However, road safety research is still far from understanding why these particular places on a road are risky. The reason is the lack of sufficient knowledge on how pedestrians and drivers interact when facing a potentially dangerous traffic situation, and the lack of an integrated framework that relates the data on human behavior to real-world traffic situations. We attempt to tackle this problem by developing SAFEPED, a multi-agent microscopic three-dimensional (3D) simulation of vehicle and pedestrian dynamics at a black spot. SAFEPED is a test platform for evaluating experimentally estimated drivers and pedestrians behavioral rules, and estimating accident risks in different traffic situations. It aims to analyze the design of existing and future black spots and to assess alternative architectural and environmental solutions in order to identify maximally efficient safety countermeasures. © 2015 Taylor and Francis Group, LLC."",
    author_keywords = ""Agent-Based Modeling; Black Spot; Spatially Explicit Modeling; Traffic Accidents"",
    keywords = ""Behavioral research; Computational methods; Computer simulation; Motor transportation; Multi agent systems; Pedestrian safety; Risk assessment; Risk perception; Roads and streets; Agent-based model; Black spot; Integrated frameworks; Microsimulation models; Pedestrian dynamics; Safety countermeasures; Spatially explicit modeling; Three-dimensional (3-D) simulation; accident; numerical model; optimization; road transport; simulation; traffic management; transportation safety; transportation system; Highway accidents"",
    publisher = ""Taylor and Francis Inc."",
    issn = ""15472450"",
    language = ""English"",
    abbrev_source_title = ""J. Intell. Transp. Syst. Technol. Plann. Oper."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 24""
}
"	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2015	Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924037275&doi=10.1080%2f15472450.2013.856721&partnerID=40&md5=700f408fd9b18ba78cb22fd167ae4fcd	Taylor and Francis Inc.	nan; References
63	TestNN	Output Reachable Set Estimation and Verification for Multilayer Neural Networks	In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches.		Weiming Xiang; Hoang-Dung Tran; Taylor T. Johnson	IEEE Transactions on Neural Networks and Learning Systems	https://doi.org/10.1109/TNNLS.2018.2808470	"1.K. J. Hunt, D. Sbarbaro, R. Żbikowski and P. J. Gawthrop, ""Neural networks for control systems—A survey"", Automatica, vol. 28, no. 6, pp. 1083-1112, 1992. CrossRef  Google Scholar; 2.S. S. Ge, C. C. Hang and T. Zhang, ""Adaptive neural network control of nonlinear systems by state and output feedback"", IEEE Trans. Syst. Man Cybern. B Cybern., vol. 29, no. 6, pp. 818-828, Dec. 1999. View Article  Google Scholar; 3.T. Wang, H. Gao and J. Qiu, ""A combined adaptive neural network and nonlinear model predictive control for multirate networked industrial process control"", IEEE Trans. Neural Netw. Learn. Syst., vol. 27, no. 2, pp. 416-425, Feb. 2016. View Article  Google Scholar; 4.Z.-G. Wu, P. Shi, H. Su and J. Chu, ""Exponential stabilization for sampled-data neural-network-based control systems"", IEEE Trans. Neural Netw. Learn. Syst., vol. 25, no. 12, pp. 2180-2190, Dec. 2014. View Article  Google Scholar; 5.J. Schmidhuber, ""Deep learning in neural networks: An overview"", Neural Netw., vol. 61, pp. 85-117, Jan. 2015. CrossRef  Google Scholar; 6.S. Lawrence, C. L. Giles, A. C. Tsoi and A. D. Back, ""Face recognition: A convolutional neural-network approach"", IEEE Trans. Neural Netw., vol. 8, no. 1, pp. 98-113, Jan. 1997. View Article  Google Scholar; 7.D. Silver et al., ""Mastering the game of Go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, pp. 484-489, 2016. CrossRef  Google Scholar; 8.M. Bojarski et al., End to end learning for self-driving cars, Apr. 2016,  [online]  Available: https://arxiv.org/abs/1604.07316. Google Scholar; 9.G. Katz, C. Barrett, D. L. Dill, K. Julian and M. J. Kochenderfer, ""Reluplex: An efficient SMT solver for verifying deep neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 97-117, 2017. CrossRef  Google Scholar; 10.X. Huang, M. Kwiatkowska, S. Wang and M. Wu, ""Safety verification of deep neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 3-29, 2017. Google Scholar; 11.L. Pulina and A. Tacchella, ""Challenging SMT solvers to verify neural networks"", AI Commun., vol. 25, no. 2, pp. 117-135, 2012. CrossRef  Google Scholar; 12.L. Pulina and A. Tacchella, ""An abstraction-refinement approach to verification of artificial neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 243-257, 2010. CrossRef  Google Scholar; 13.W. Xiang, H.-D. Tran and T. T. Johnson, Reachable set computation and safety verification for neural networks with ReLU activations, Dec. 2017,  [online]  Available: https://arxiv.org/abs/1712.08163. Google Scholar; 14.Z. Xu, H. Su, P. Shi, R. Lu and Z.-G. Wu, ""Reachable set estimation for Markovian jump neural networks with time-varying delays"", IEEE Trans. Cybern., vol. 47, no. 10, pp. 3208-3217, Oct. 2017. View Article  Google Scholar; 15.Z. Zuo, Z. Wang, Y. Chen and Y. Wang, ""A non-ellipsoidal reachable set estimation for uncertain neural networks with time-varying delay"", Commun. Nonlinear Sci. Numer. Simul., vol. 19, no. 4, pp. 1097-1106, 2014. CrossRef  Google Scholar; 16.M. V. Thuan, H. M. Tran and H. Trinh, ""Reachable sets bounding for generalized neural networks with interval time-varying delay and bounded disturbances"" in Neural Computing and Applications, London, U.K.:Springer, pp. 1-12, 2016. Google Scholar; 17.W. Xiang, H.-D. Tran and T. T. Johnson, ""Robust exponential stability and disturbance attenuation for discrete-time switched systems under arbitrary switching"", IEEE Trans. Autom. Control. View Article  Google Scholar; 18.W. Xiang, ""Parameter-memorized Lyapunov functions for discrete-time systems with time-varying parametric uncertainties"", Automatica, vol. 87, pp. 450-454, Jan. 2018. CrossRef  Google Scholar; 19.W. Xiang, J. Lam and J. Shen, ""            Stability analysis and                     \$mathcal {L}_{1}\$            -gain characterization for switched positive systems under dwell-time constraint                  "", Automatica, vol. 85, pp. 1-8, Nov. 2017. CrossRef  Google Scholar; 20.W. Xiang, ""Necessary and sufficient condition for stability of switched uncertain linear systems under dwell-time constraint"", IEEE Trans. Autom. Control, vol. 61, no. 11, pp. 3619-3624, Nov. 2016. View Article  Google Scholar; 21.W. Xiang, H.-D. Tran and T. T. Johnson, ""Output reachable set estimation for switched linear systems and its application in safety verification"", IEEE Trans. Autom. Control, vol. 62, no. 10, pp. 5380-5387, Oct. 2017. View Article  Google Scholar; 22.W. Xiang, H.-D. Tran and T. T. Johnson, ""On reachable set estimation for discrete-time switched linear systems under arbitrary switching"", Proc. Amer. Control Conf. (ACC), pp. 4534-4539, May 2017. View Article  Google Scholar; 23.P. S. Duggirala, S. Mitra, M. Viswanathan and M. Potok, ""C2E2: A verification tool for stateflow models"", Proc. Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 68-82, 2015. CrossRef  Google Scholar; 24.C. Fan, B. Qi, S. Mitra, M. Viswanathan and P. S. Duggirala, ""Automatic reachability analysis for nonlinear hybrid models with C2E2"", Proc. Int. Conf. Comput. Aided Verification, pp. 531-538, 2016. CrossRef  Google Scholar; 25.S. Bak and P. S. Duggirala, ""HyLAA: A tool for computing simulation-equivalent reachability for linear systems"", Proc. 20th Int. Conf. Hybrid Syst. Comput. Control, pp. 173-178, 2017. CrossRef  Google Scholar; 26.K. Hornik, M. Stinchcombe and H. White, ""Multilayer feedforward networks are universal approximators"", Neural Netw., vol. 2, no. 5, pp. 359-366, 1989. CrossRef  Google Scholar; 27.X. Zeng and D. S. Yeung, ""Sensitivity analysis of multilayer perceptron to input and weight perturbations"", IEEE Trans. Neural Netw., vol. 12, no. 6, pp. 1358-1366, Nov. 2001. View Article  Google Scholar; 28.X. Zeng and D. S. Yeung, ""A quantified sensitivity measure for multilayer perceptron to input perturbation"", Neural Comput., vol. 15, no. 1, pp. 183-212, 2003. View Article  Google Scholar; 29.X.-Z. Wang, Q.-Y. Shao, Q. Miao and J.-H. Zhai, ""Architecture selection for networks trained with extreme learning machine using localized generalization error model"", Neurocomputing, vol. 102, pp. 3-9, Feb. 2013. Google Scholar; 30.S. W. Piche, ""The selection of weight accuracies for Madalines"", IEEE Trans. Neural Netw., vol. 6, no. 2, pp. 432-445, Mar. 1995. View Article  Google Scholar"			Included	Included	new_screen			1	IEEE	2018	Output Reachable Set Estimation and Verification for Multilayer Neural Networks		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
64	TestNN	Predictive threat assessment via reachability analysis and set invariance theory	We propose two model-based threat assessment methods for semi-autonomous vehicles, i.e., human-driven vehicles with autonomous driving capabilities. Based on information about the surrounding environment, we introduce a set of constraints on the vehicle states, which are satisfied under safe driving conditions. Then, we formulate the threat assessment problem as a constraint satisfaction problem. Vehicle and driver mathematical models are used to predict future constraint violation, indicating the possibility of accident or loss of vehicle control, hence, the need to assist the driver. The two proposed methods differ in the models used to predict vehicle motion within the surrounding environment. We demonstrate the proposed methods in a roadway departure application and validate them through experimental data. © 2011 IEEE.	Accidents; Constraint theory; Control system synthesis; Decision making; Mathematical models; Rating; Vehicles; Active safety; Invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment; Remotely operated vehicles	Falcone, Paolo; Ali, Mohammad; Sjöberg, Jonas	IEEE Transactions on Intelligent Transportation Systems	https://doi.org/10.1109/TITS.2011.2158210		1352 – 1361	"@ARTICLE{Falcone20111352,
    author = ""Falcone, Paolo and Ali, Mohammad and Sjöberg, Jonas"",
    title = ""Predictive threat assessment via reachability analysis and set invariance theory"",
    year = ""2011"",
    journal = ""IEEE Transactions on Intelligent Transportation Systems"",
    volume = ""12"",
    number = ""4"",
    pages = ""1352 – 1361"",
    doi = ""10.1109/TITS.2011.2158210"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-82455164302\&doi=10.1109\%2fTITS.2011.2158210\&partnerID=40\&md5=3e18c8bf0f28fb9d39a09e27ab08ec8f"",
    affiliations = ""Department of Signals and Systems, Chalmers University of Technology, 412 96 Göteborg, Sweden; Active Safety and Chassis Department, Volvo Car Corporation, 405 31 Göteborg, Sweden"",
    abstract = ""We propose two model-based threat assessment methods for semi-autonomous vehicles, i.e., human-driven vehicles with autonomous driving capabilities. Based on information about the surrounding environment, we introduce a set of constraints on the vehicle states, which are satisfied under safe driving conditions. Then, we formulate the threat assessment problem as a constraint satisfaction problem. Vehicle and driver mathematical models are used to predict future constraint violation, indicating the possibility of accident or loss of vehicle control, hence, the need to assist the driver. The two proposed methods differ in the models used to predict vehicle motion within the surrounding environment. We demonstrate the proposed methods in a roadway departure application and validate them through experimental data. © 2011 IEEE."",
    author_keywords = ""Active safety; decision making; invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment"",
    keywords = ""Accidents; Constraint theory; Control system synthesis; Decision making; Mathematical models; Rating; Vehicles; Active safety; Invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment; Remotely operated vehicles"",
    correspondence_address = ""P. Falcone; Department of Signals and Systems, Chalmers University of Technology, 412 96 Göteborg, Sweden; email: falcone@chalmers.se"",
    issn = ""15249050"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans. Intell. Transp. Syst."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 90""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2011	Predictive threat assessment via reachability analysis and set invariance theory	https://www.scopus.com/inward/record.uri?eid=2-s2.0-82455164302&doi=10.1109%2fTITS.2011.2158210&partnerID=40&md5=3e18c8bf0f28fb9d39a09e27ab08ec8f		nan; References; Publisher
65	TestNN	Risk assessment of an AUV based on an improved SFMEA method	In considering the limitations in risk assessment of AUV (autonomous underwater vehicle) software systems by the traditional SFMEA (software failure modes and effects analysis) method, and on the basis of evaluating failure modes by fuzzy set theory, an improved SFMEA method based on grey region relationship was proposed. In this method, through calculating the grey region degree of relationship between the failure object and the ideal object, a quantitative risk assessment of intelligent planning and decision-making control systems of the AUV was gained, and the failure priority of the failure modes was given. Experimental results prove that the above methods can effectively solve problems which can only deal with a single value of O, S, and D by the existing SFMEA method, and improve the accuracy of the application of SFMEA methods in the AUV.	Autonomous underwater vehicles; Decision making; Failure modes; Fuzzy logic; Fuzzy set theory; Fuzzy sets; Rating; Safety factor; Submersibles; Underwater equipment; Water craft; AUV (autonomous underwater vehicle); Grey region relationship; Intelligent planning; Quantitative risk assessment; Single-value; Software failure; Software failure modes and effects analysis (SFMEA); Software systems; Risk assessment	Shi, Changting; Zhang, Rubo	Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University	https://doi.org/10.3969/j.issn.1006-7043.2011.03.014		345 – 349	"@ARTICLE{Shi2011345,
    author = ""Shi, Changting and Zhang, Rubo"",
    title = ""Risk assessment of an AUV based on an improved SFMEA method"",
    year = ""2011"",
    journal = ""Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University"",
    volume = ""32"",
    number = ""3"",
    pages = ""345 – 349"",
    doi = ""10.3969/j.issn.1006-7043.2011.03.014"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955966021\&doi=10.3969\%2fj.issn.1006-7043.2011.03.014\&partnerID=40\&md5=819dbfa9f5cc81fc59b639cf035b2ea6"",
    affiliations = ""College of Computer Science and Technology, Harbin Engineering University, Harbin 150001, China"",
    abstract = ""In considering the limitations in risk assessment of AUV (autonomous underwater vehicle) software systems by the traditional SFMEA (software failure modes and effects analysis) method, and on the basis of evaluating failure modes by fuzzy set theory, an improved SFMEA method based on grey region relationship was proposed. In this method, through calculating the grey region degree of relationship between the failure object and the ideal object, a quantitative risk assessment of intelligent planning and decision-making control systems of the AUV was gained, and the failure priority of the failure modes was given. Experimental results prove that the above methods can effectively solve problems which can only deal with a single value of O, S, and D by the existing SFMEA method, and improve the accuracy of the application of SFMEA methods in the AUV."",
    author_keywords = ""Autonomous underwater vehicle (AUV); Grey region relationship; Risk assessment; Software failure modes and effects analysis (SFMEA)"",
    keywords = ""Autonomous underwater vehicles; Decision making; Failure modes; Fuzzy logic; Fuzzy set theory; Fuzzy sets; Rating; Safety factor; Submersibles; Underwater equipment; Water craft; AUV (autonomous underwater vehicle); Grey region relationship; Intelligent planning; Quantitative risk assessment; Single-value; Software failure; Software failure modes and effects analysis (SFMEA); Software systems; Risk assessment"",
    correspondence_address = ""C. Shi; College of Computer Science and Technology, Harbin Engineering University, Harbin 150001, China; email: shichangting@hrbeu.edu.cn"",
    issn = ""10067043"",
    coden = ""HGHPF"",
    language = ""Chinese"",
    abbrev_source_title = ""Harbin Gongcheng Daxue Xuebao"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4""
}
"	Excluded	Excluded	new_screen		Exclusion: full-text is not available/not written in English/not aiming at NN-based CPSs	1	Scopus	2011	Risk assessment of an AUV based on an improved SFMEA method	https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955966021&doi=10.3969%2fj.issn.1006-7043.2011.03.014&partnerID=40&md5=819dbfa9f5cc81fc59b639cf035b2ea6		nan; References; Publisher
66	TestNN	Safety performance monitoring of autonomous marine systems	"<div class=""abstract author-highlights"" id=""ab0015""><h2 class=""section-title u-h4 u-margin-l-top u-margin-xs-bottom"">Highlights</h2><div id=""abs0015""><p id=""sp0080""></p><ul class=""list""><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""p0005"">Process for developing safety indicators for autonomous marine systems.</p></span></li><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""p0010"">Safety indicators based on safety barriers and resilience thinking.</p></span></li><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""p0015"">Location of the development process in the system lifecycle.</p></span></li><li class=""react-xocs-list-item""><span class=""list-label"">•</span><span><p id=""p0020"">Case study on AUV demonstrating applicability of the process.</p></span></li></ul><p></p></div></div>"		Thieme, C. A. and I. B. Utne	Reliability Engineering & System Safety	https://doi.org/10.1016/j.ress.2016.11.024		Volume 159,March 2017, Pages 		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ScienceDirect	2017	Safety performance monitoring of autonomous marine systems		Science Direct	nan; Authors; Keywords; References; Year; Bibtex; Link
67	TestNN	Safety Verification of Deep Neural Networks	Deep neural networks have achieved impressive experimental results in image classification, but can surprisingly be unstable with respect to adversarial perturbations, that is, minimal changes to the input image that cause the network to misclassify it. With potential applications including perception modules and end-to-end controllers for self-driving cars, this raises concerns about their safety. We develop a novel automated verification framework for feed-forward multi-layer neural networks based on Satisfiability Modulo Theory (SMT). We focus on safety of image classification decisions with respect to image manipulations, such as scratches or changes to camera angle or lighting conditions that would result in the same class being assigned by a human, and define safety for an individual decision in terms of invariance of the classification within a small neighbourhood of the original image. We enable exhaustive search of the region by employing discretisation, and propagate the analysis layer by layer. Our method works directly with the network code and, in contrast to existing methods, can guarantee that adversarial examples, if they exist, are found for the given region and family of manipulations. If found, adversarial examples can be shown to human testers and/or used to fine-tune the network. We implement the techniques using Z3 and evaluate them on state-of-the-art networks, including regularised and deep learning networks. We also compare against existing techniques to search for adversarial examples and estimate network robustness.	Deep Neural Networks; Adversarial Examples; Adversarial Perturbations; Fast Gradient Sign Method (FGSM); German Traffic Sign Recognition Benchmark (GTSRB)	Xiaowei Huang15,; Marta Kwiatkowska15,; Sen Wang15&; Min Wu15	International Conference on Computer Aided Verification	https://doi.org/10.1007/978-3-319-63387-9_1		pp 3–29		Included	Included	new_screen			1	SpringerLink	2017	Safety Verification of Deep Neural Networks, Pt I. R. Majumdar and V. Kuncak. 10426: 3-29.		Springer, Cham	nan; References; Year; Bibtex; Link
68	TestNN	Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios	This chapter focuses on procedures and tools used in the testing stages of the intelligent vehicle design process. By testing the developed intelligent vehicle algorithms and architectures in a series of environments, starting from pure simulation and ending with physical, full-scale tests, it is possible to avoid the time, safety, and logistics costs of full-blown outdoor tests for the initial stages of the development process. The described procedure, which uses both simulation environments and small-scale indoor testbeds before the outdoor tests, makes use of different levels of virtualization for sensors, agents, scenarios and environments, and has been successfully demonstrated on multiple autonomous vehicle implementation examples. © 2014 Elsevier Inc. All rights reserved.	Intelligent vehicle highway systems; Safety testing; Testbeds; Development process; Full scale tests; Logistics costs; Multiple autonomous vehicles; Simulation environment; Staged scenarios; Vehicle design; Virtual sensor; Vehicles	Kurt, Arda; Vernier, Michael; Biddlestone, Scott; Redmill, Keith; Özgüner, Ümit	Advances in Intelligent Vehicles	https://doi.org/10.1016/B978-0-12-397199-9.00002-1		45 – 64	"@BOOK{Kurt201345,
    author = ""Kurt, Arda and Vernier, Michael and Biddlestone, Scott and Redmill, Keith and Özgüner, Ümit"",
    title = ""Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios"",
    year = ""2013"",
    journal = ""Advances in Intelligent Vehicles"",
    pages = ""45 – 64"",
    doi = ""10.1016/B978-0-12-397199-9.00002-1"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902064057\&doi=10.1016\%2fB978-0-12-397199-9.00002-1\&partnerID=40\&md5=6f60c873d32f91327754beefe97d1f2a"",
    affiliations = ""The Ohio State University, OH, United States"",
    abstract = ""This chapter focuses on procedures and tools used in the testing stages of the intelligent vehicle design process. By testing the developed intelligent vehicle algorithms and architectures in a series of environments, starting from pure simulation and ending with physical, full-scale tests, it is possible to avoid the time, safety, and logistics costs of full-blown outdoor tests for the initial stages of the development process. The described procedure, which uses both simulation environments and small-scale indoor testbeds before the outdoor tests, makes use of different levels of virtualization for sensors, agents, scenarios and environments, and has been successfully demonstrated on multiple autonomous vehicle implementation examples. © 2014 Elsevier Inc. All rights reserved."",
    author_keywords = ""Indoor testbeds; Intelligent vehicles; Simulation environments; Staged scenarios; Virtual sensors"",
    keywords = ""Intelligent vehicle highway systems; Safety testing; Testbeds; Development process; Full scale tests; Logistics costs; Multiple autonomous vehicles; Simulation environment; Staged scenarios; Vehicle design; Virtual sensor; Vehicles"",
    publisher = ""Elsevier Inc."",
    isbn = ""978-012397199-9"",
    language = ""English"",
    abbrev_source_title = ""Adv. in Intell. Veh."",
    type = ""Book chapter"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2013	Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902064057&doi=10.1016%2fB978-0-12-397199-9.00002-1&partnerID=40&md5=6f60c873d32f91327754beefe97d1f2a	Elsevier Inc.	nan; References
69	TestNN	Toward Scalable Verification for Safety-Critical Deep Networks	Abstract:The increasing use of deep neural networks for safety-critical applications, such as autonomous driving and flight control, raises concerns about their safety and reliability. Formal verification can address these concerns by guaranteeing that a deep learning system operates as intended, but the state of the art is limited to small systems. In this work-in-progress report we give an overview of our work on mitigating this difficulty, by pursuing two complementary directions: devising scalable verification techniques, and identifying design choices that result in deep learning systems that are more amenable to verification.		Lindsey Kuper; Guy Katz; Justin Gottschlich; Kyle Julian; Clark Barrett; Mykel Kochenderfer	arXiv	https://doi.org/10.48550/arXiv.1801.05950				Included	Included	new_screen			1	arXiv	2018	Toward scalable verification for safety-critical deep networks [arXiv]			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
70	TestNN	A Flight Simulator for Unmanned Aerial Vehicle Flights Over Construction Job Sites	In 2015, the construction had the highest rate of fatalities among all industries in the United States. Unsafe operation of construction equipment is one of the main causes of fatal incidents. Operation, management and interactions between construction equipment and construction crews should be thoroughly regulated to minimize the risk of fatal incidents on job sites. While use of most traditional construction equipment is regulated, the construction industry has struggled with regulating new, innovative and smart equipment such as Unmanned Aerial Vehicles (UAVs) that have recently been introduced to construction job sites. In this paper, collision avoidance and spatial safety theories in construction are discussed. The bases of these theories are extended to UAV operation in order to establish the first known theory on safe use and operation of UAVs in construction. Also, basic principles of UAV flights are discussed. By applying the basic principles of UAV flights and construction spatial safety theories, a UAV flight simulator in construction environments has been developed in Unity game engine. The flight simulator is designed for UAV pilots, construction managers and safety managers, and enables users to fly a UAV within a simulated environment extracted from a BIM model. This UAV flight simulator is tested in a case study of a building currently under construction. This simulator can be used to assess UAV pilots’ capabilities, test the risks of UAV flights in any construction environment, and UAV safe flight path planning.	Flight simulator; Unmanned aerial vehicle; UAV; Flight simulation	Hashem Izadi MoudORCID:orcid.org/0000-0002-8800-77543,; Mohamad A. RazkenariORCID:orcid.org/0000-0002-1815-75703,; Ian Flood3&; Charles Kibert3	Advances in Informatics and Computing in Civil and Construction Engineering	https://doi.org/10.1007/978-3-030-00220-6_73		pp 609–616		Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	SpringerLink	2019	A Flight Simulator for Unmanned Aerial Vehicle Flights Over Construction Job Sites		Springer, Cham	nan; References; Year; Bibtex; Link
71	TestNN	A formal approach for identifying assurance deficits in unmanned aerial vehicle software	While formal methods have proved to be unfeasible for large scale systems, argument-based safety cases offer a plausible alternative basis for certification of critical software. Our proposed method for increasing safety combines formal methods with argumentation-based reasoning. In a first step, we provide a formal representation of the the argumentative-based Goal Structuring Notation (GSN) standard used in industry. In a second step, our solution exploits reasoning in description logic to identify assurance deficits in the GSN model. The identified flaws are given to a hybrid logic-based model checker to be validated against a Kripke model. The method is illustrated for an unmanned aerial vehicle software, with reasoning performed in RacerPro engine and the HLMC model checker based on hybrid logic. © Springer International Publishing Switzerland 2015.	Case based reasoning; Data description; Formal languages; Model checking; Systems engineering; Unmanned aerial vehicles (UAV); argumentation; Assurance deficits; Description logic; Formal representations; Goal structuring notation; Hybrid logic; Logic-based modeling; Safety case; Formal methods	Groza, Adrian; Letia, Ioan Alfred; Goron, Anca; Zaporojan, Sergiu	Advances in Intelligent Systems and Computing	https://doi.org/10.1007/978-3-319-08422-0_35		233 – 239	"@ARTICLE{Groza2015233,
    author = ""Groza, Adrian and Letia, Ioan Alfred and Goron, Anca and Zaporojan, Sergiu"",
    title = ""A formal approach for identifying assurance deficits in unmanned aerial vehicle software"",
    year = ""2015"",
    journal = ""Advances in Intelligent Systems and Computing"",
    volume = ""1089"",
    pages = ""233 – 239"",
    doi = ""10.1007/978-3-319-08422-0\_35"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906542893\&doi=10.1007\%2f978-3-319-08422-0\_35\&partnerID=40\&md5=70d4bedad213041dcd56678943d96b2d"",
    affiliations = ""Department of Computer Science, Technical University of ClujNapoca, Cluj-Napoca, Romania; Department of Computer Science, Technical University of Moldova, Chisinau, Moldova"",
    abstract = ""While formal methods have proved to be unfeasible for large scale systems, argument-based safety cases offer a plausible alternative basis for certification of critical software. Our proposed method for increasing safety combines formal methods with argumentation-based reasoning. In a first step, we provide a formal representation of the the argumentative-based Goal Structuring Notation (GSN) standard used in industry. In a second step, our solution exploits reasoning in description logic to identify assurance deficits in the GSN model. The identified flaws are given to a hybrid logic-based model checker to be validated against a Kripke model. The method is illustrated for an unmanned aerial vehicle software, with reasoning performed in RacerPro engine and the HLMC model checker based on hybrid logic. © Springer International Publishing Switzerland 2015."",
    author_keywords = ""argumentation; description logic; hybrid logic; safety cases"",
    keywords = ""Case based reasoning; Data description; Formal languages; Model checking; Systems engineering; Unmanned aerial vehicles (UAV); argumentation; Assurance deficits; Description logic; Formal representations; Goal structuring notation; Hybrid logic; Logic-based modeling; Safety case; Formal methods"",
    correspondence_address = ""A. Groza; Department of Computer Science, Technical University of ClujNapoca, Cluj-Napoca, Romania; email: Adrian.Groza@mail.utm.md"",
    publisher = ""Springer Verlag"",
    issn = ""21945357"",
    isbn = ""978-331908421-3"",
    language = ""English"",
    abbrev_source_title = ""Adv. Intell. Sys. Comput."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 10; Conference name: 23rd International Conference on Systems Engineering, ICSEng 2014; Conference date: 19 August 2014 through 21 August 2014; Conference code: 107141""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2015	A formal approach for identifying assurance deficits in unmanned aerial vehicle software	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906542893&doi=10.1007%2f978-3-319-08422-0_35&partnerID=40&md5=70d4bedad213041dcd56678943d96b2d	Springer Verlag	nan; References
72	TestNN	A Formal Approach to Autonomous Vehicle Coordination	Increasing demands on safety and energy efficiency will require higher levels of automation in transportation systems. This involves dealing with safety-critical distributed coordination. In this paper we demonstrate how a Satisfiability Modulo Theories (SMT) solver can be used to prove correctness of a vehicular coordination problem. We formalise a recent distributed coordination protocol and validate our approach using an intersection collision avoidance (ICA) case study. The system model captures continuous time and space, and an unbounded number of vehicles and messages. The safety of the case study is automatically verified using the Z3 theorem prover.	Collision Avoidance; Formal Approach; Reachable State; Target Speed; Hybrid Automaton	Mikael Asplund18,; Atif Manzoor18,; Mélanie Bouroche18,; Siobhàn Clarke18&; Vinny Cahill18	International Symposium on Formal Methods	https://doi.org/10.1007/978-3-642-32759-9_8		pp 52–67		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2012	A Formal Approach to Autonomous Vehicle Coordination		Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
73	TestNN	A Formally Verified Motion Planner for Autonomous Vehicles	Autonomous vehicles are safety-critical cyber-physical systems. To ensure their correctness, we use a proof assistant to prove safety properties deductively. This paper presents a formally verified motion planner based on manoeuvre automata in Isabelle/HOL. Two general properties which we ensure are numerical soundness (the absence of floating-point errors) and logical correctness (satisfying a plan specified in linear temporal logic). From these two properties, we obtain a motion planner whose correctness only depends on the validity of the models of the ego vehicle and its environment.	Motion primitives; Manoeuvre automata; Motion planning; Theorem proving; Linear temporal logic; Reachability analysis; Autonomous vehicles	Albert Rizaldi15,; Fabian Immler16,; Bastian Schürmann15&; Matthias Althoff15	International Symposium on Automated Technology for Verification and Analysis	https://doi.org/10.1007/978-3-030-01090-4_5		pp 75–90		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2018	A Formally Verified Motion Planner for Autonomous Vehicles		Springer, Cham	nan; References; Year; Bibtex; Link
74	TestNN	Automated Synthesis of Safe Autonomous Vehicle Control Under Perception Uncertainty	Autonomous vehicles have found wide-ranging adoption in aerospace, terrestrial as well as marine use. These systems often operate in uncertain environments and in the presence of noisy sensors, and use machine learning and statistical sensor fusion algorithms to form an internal model of the world that is inherently probabilistic. Autonomous vehicles need to operate using this uncertain world-model, and hence, their correctness cannot be deterministically specified. Even once probabilistic correctness is specified, proving that an autonomous vehicle will operate correctly is a challenging problem. In this paper, we address these challenges by proposing acorrect-by-synthesisapproach to autonomous vehicle control. We propose a probabilistic extension of temporal logic, named Chance Constrained Temporal Logic (C2TL), that can be used to specify correctness requirements in presence of uncertainty. We present a novel automated synthesis technique that compiles C2TL specification into mixed integer constraints, and uses second-order (quadratic) cone programming to synthesize optimal control of autonomous vehicles subject to the C2TL specification. We demonstrate the effectiveness of the proposed approach on a diverse set of illustrative examples.	Temporal Logic; Model Predictive Control; Probabilistic Constraint; Autonomous Vehicle; Lane Change	Susmit Jha15&; Vasumathi Raman15	NASA Formal Methods Symposium	https://doi.org/10.1007/978-3-319-40648-0_10		pp 117–132		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2016	Automated Synthesis of Safe Autonomous Vehicle Control Under Perception Uncertainty		Springer, Cham	nan; References; Year; Bibtex; Link
75	TestNN	Combination of Simulation and Model-Checking for the Analysis of Autonomous Vehicles‚Äô Behaviors: A Case Study			Johan ArcileJ√©r√©my SobierajHanna KlaudelGuillaume Hutzler	Multi-Agent Systems and Agreement Technologies					Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1		2018				
76	TestNN	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. © 2019, Springer Nature B.V.	Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms	Dreossi, Tommaso; Donzé, Alexandre; Seshia, Sanjit A.	Journal of Automated Reasoning	https://doi.org/10.1007/s10817-018-09509-5		1031 – 1053	"@ARTICLE{Dreossi20191031,
    author = ""Dreossi, Tommaso and Donzé, Alexandre and Seshia, Sanjit A."",
    title = ""Compositional Falsification of Cyber-Physical Systems with Machine Learning Components"",
    year = ""2019"",
    journal = ""Journal of Automated Reasoning"",
    volume = ""63"",
    number = ""4"",
    pages = ""1031 – 1053"",
    doi = ""10.1007/s10817-018-09509-5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868\&doi=10.1007\%2fs10817-018-09509-5\&partnerID=40\&md5=f87cb216796cb6bb61e71f71664c8f18"",
    affiliations = ""University of California, Berkeley, Berkeley, United States; Decyphir SAS, Moirans, France"",
    abstract = ""Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. © 2019, Springer Nature B.V."",
    author_keywords = ""Autonomous driving; Cyber-physical systems; Deep learning; Falsification; Machine learning; Neural networks; Temporal logic"",
    keywords = ""Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms"",
    correspondence_address = ""T. Dreossi; University of California, Berkeley, Berkeley, United States; email: dreossi@berkeley.edu"",
    publisher = ""Springer Netherlands"",
    issn = ""01687433"",
    coden = ""JAREE"",
    language = ""English"",
    abbrev_source_title = ""J Autom Reasoning"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 97; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868&doi=10.1007%2fs10817-018-09509-5&partnerID=40&md5=f87cb216796cb6bb61e71f71664c8f18	Springer Netherlands	nan; References
77	TestNN	Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning	"A 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Cyber-Physical System</i>
 (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to minimize the robustness. In this paper, we explore state-of-the-art 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Deep Reinforcement Learning</i>
 (DRL) techniques, i.e., 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Asynchronous Advantage Actor-Critic</i>
 (A3C) and 
<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Double Deep Q Network</i>
 (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample."		Yoriyuki Yamagata; Shuang Liu; Takumi Akazaki; Yihai Duan; Jianye Hao	IEEE Transactions on Software Engineering	https://doi.org/10.1109/TSE.2020.2969178				Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2018	Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
78	TestNN	Learning-Based testing of cyber-physical systems-of-systems: A platooning study	Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons. © Springer International Publishing AG 2017.	Artificial intelligence; Cyber Physical System; Embedded systems; Learning systems; Model checking; Safety engineering; Safety testing; Software testing; System of systems; Systems engineering; Automotive ecus; Cyber physical systems (CPSs); Fully automated; Model based testing; Model-checking techniques; Performance properties; Platooning; Safety critical components; Integration testing	Meinke, Karl	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-319-66583-2_9		135 – 151	"@ARTICLE{Meinke2017135,
    author = ""Meinke, Karl"",
    editor = ""P., Reinecke and A., Di Marco"",
    title = ""Learning-Based testing of cyber-physical systems-of-systems: A platooning study"",
    year = ""2017"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""10497 LNCS"",
    pages = ""135 – 151"",
    doi = ""10.1007/978-3-319-66583-2\_9"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453120\&doi=10.1007\%2f978-3-319-66583-2\_9\&partnerID=40\&md5=39d69257e318318ee286f16ef5af0256"",
    affiliations = ""School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden"",
    abstract = ""Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons. © Springer International Publishing AG 2017."",
    author_keywords = ""Cyber-physical system; Learning-based testing; Machine learning; Model-based testing; Platooning; Requirements testing; System-of-systems"",
    keywords = ""Artificial intelligence; Cyber Physical System; Embedded systems; Learning systems; Model checking; Safety engineering; Safety testing; Software testing; System of systems; Systems engineering; Automotive ecus; Cyber physical systems (CPSs); Fully automated; Model based testing; Model-checking techniques; Performance properties; Platooning; Safety critical components; Integration testing"",
    correspondence_address = ""K. Meinke; School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden; email: karlm@kth.se"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-331966582-5"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 25; Conference name: 14th European Workshop on Computer Performance Engineering, EPEW 2017; Conference date: 7 September 2017 through 8 September 2017; Conference code: 197319; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2017	Learning-Based Testing of Cyber-Physical Systems-of-Systems: A Platooning Study	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453120&doi=10.1007%2f978-3-319-66583-2_9&partnerID=40&md5=39d69257e318318ee286f16ef5af0256	Springer Verlag	nan; References
79	TestNN	Model-Based Testing of Cyber-Physical Systems	"<div class=""abstract author"" id=""ab0010""><h2 class=""section-title u-h4 u-margin-l-top u-margin-xs-bottom"">Abstract</h2><div id=""as0010""><p id=""sp0055""><span>Cyber-physical systems (CPSs) are the result of the integration of connected <a class=""topic-link"" href=""/topics/engineering/computer-system"" title=""Learn more about computer systems from ScienceDirect's AI-generated Topic Pages"">computer systems</a><span> with the physical world. They feature complex interactions that go beyond traditional communication schemes and protocols in <a class=""topic-link"" href=""/topics/computer-science/computer-system"" title=""Learn more about computer systems from ScienceDirect's AI-generated Topic Pages"">computer systems</a>. One distinguished feature of such complex interactions is the tight coupling between discrete and continuous interactions, captured by </span></span><a class=""topic-link"" href=""/topics/computer-science/hybrid-system-model"" title=""Learn more about hybrid system models from ScienceDirect's AI-generated Topic Pages"">hybrid system models</a>.</p><p id=""sp0060"">Due to the complexity of CPSs, providing rigorous and model-based analysis methods and tools for verifying correctness of such systems is of the <a class=""topic-link"" href=""/topics/computer-science/utmost-importance"" title=""Learn more about utmost importance from ScienceDirect's AI-generated Topic Pages"">utmost importance</a>. Model-based testing (MBT) is one such verification technique that can be used for checking the conformance of an implementation of a system to its specification (model).</p><p id=""sp0065"">In this chapter, we first review the main concepts and techniques in MBT. Subsequently, we review the most common modeling formalisms for CPSs, with focus on hybrid system models. Subsequently, we provide a brief overview of conformance relations and conformance testing techniques for CPSs.</p></div></div>"		Teck Ping Khoo	Cyber-Physical Systems	https://doi.org/10.1016/B978-0-12-803801-7.00019-5		Found		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ScienceDirect	2018	Model Based Testing of Cyber-Physical Systems		Science Direct	nan; Authors; Keywords; References; Year; Bibtex; Link
80	TestNN	ModelPlex: verified runtime validation of verified cyber-physical system models	Formal verification and validation play a crucial role in making cyber-physical systems (CPS) safe. Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained, including models of the controller and of the physical dynamics. In CPS, models are essential; but any model we could possibly build necessarily deviates from the real world. If the real system fits to the model, its behavior is guaranteed to satisfy the correctness properties verified with respect to the model. Otherwise, all bets are off. This article introduces ModelPlex, a method ensuring that verification results about models apply to CPS implementations. ModelPlex provides correctness guarantees for CPS executions at runtime: it combines offline verification of CPS models with runtime validation of system executions for compliance with the model. ModelPlex ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model. If, at some point, the observed behavior no longer complies with the model so that offline verification results no longer apply, ModelPlex initiates provably safe fallback actions, assuming the system dynamics deviation is bounded. This article, furthermore, develops a systematic technique to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic by a correct-by-construction approach, leading to verifiably correct runtime model validation. Overall, ModelPlex generates provably correct monitor conditions that, if checked to hold at runtime, are provably guaranteed to imply that the offline safety verification results about the CPS model apply to the present run of the actual CPS implementation. © 2016, The Author(s).	Compliance control; Computer circuits; Dynamics; Embedded systems; Formal methods; Hybrid systems; Reconfigurable hardware; Correct-by-construction; Correctness properties; Cyber physical systems (CPSs); Cyber-physical systems (CPS); Differential dynamic logic; Run-time verification; Static verification; Verification-and-validation; Formal verification	Mitsch, Stefan; Platzer, André	Formal Methods in System Design	https://doi.org/10.1007/s10703-016-0241-z		33 – 74	"@ARTICLE{Mitsch201633,
    author = ""Mitsch, Stefan and Platzer, André"",
    title = ""ModelPlex: verified runtime validation of verified cyber-physical system models"",
    year = ""2016"",
    journal = ""Formal Methods in System Design"",
    volume = ""49"",
    number = ""1-2"",
    pages = ""33 – 74"",
    doi = ""10.1007/s10703-016-0241-z"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994027707\&doi=10.1007\%2fs10703-016-0241-z\&partnerID=40\&md5=09d944ed9de3ca1ac892b04787dcd16a"",
    affiliations = ""Computer Science Department, Carnegie Mellon University, Pittsburgh, United States; Department of Cooperative Information Systems, Johannes Kepler University, Linz, Austria"",
    abstract = ""Formal verification and validation play a crucial role in making cyber-physical systems (CPS) safe. Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained, including models of the controller and of the physical dynamics. In CPS, models are essential; but any model we could possibly build necessarily deviates from the real world. If the real system fits to the model, its behavior is guaranteed to satisfy the correctness properties verified with respect to the model. Otherwise, all bets are off. This article introduces ModelPlex, a method ensuring that verification results about models apply to CPS implementations. ModelPlex provides correctness guarantees for CPS executions at runtime: it combines offline verification of CPS models with runtime validation of system executions for compliance with the model. ModelPlex ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model. If, at some point, the observed behavior no longer complies with the model so that offline verification results no longer apply, ModelPlex initiates provably safe fallback actions, assuming the system dynamics deviation is bounded. This article, furthermore, develops a systematic technique to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic by a correct-by-construction approach, leading to verifiably correct runtime model validation. Overall, ModelPlex generates provably correct monitor conditions that, if checked to hold at runtime, are provably guaranteed to imply that the offline safety verification results about the CPS model apply to the present run of the actual CPS implementation. © 2016, The Author(s)."",
    author_keywords = ""Cyber-physical systems; Differential dynamic logic; Hybrid systems; Runtime verification; Static verification"",
    keywords = ""Compliance control; Computer circuits; Dynamics; Embedded systems; Formal methods; Hybrid systems; Reconfigurable hardware; Correct-by-construction; Correctness properties; Cyber physical systems (CPSs); Cyber-physical systems (CPS); Differential dynamic logic; Run-time verification; Static verification; Verification-and-validation; Formal verification"",
    correspondence_address = ""S. Mitsch; Computer Science Department, Carnegie Mellon University, Pittsburgh, United States; email: smitsch@cs.cmu.edu"",
    publisher = ""Springer New York LLC"",
    issn = ""09259856"",
    coden = ""FMSDE"",
    language = ""English"",
    abbrev_source_title = ""Formal Methods Syst Des"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 80; All Open Access, Hybrid Gold Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2014	ModelPlex: Verified Runtime Validation of Verified Cyber-Physical System Models	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994027707&doi=10.1007%2fs10703-016-0241-z&partnerID=40&md5=09d944ed9de3ca1ac892b04787dcd16a	Springer New York LLC	nan; References
81	TestNN	MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems	We present MoDeS3, a complex research demonstrator illustrating the combined use of model-driven development, formal verification, safety engineering and IoT technologies for smart and safe cyber-physical systems. MoDeS3 represents a smart transportation system-of-systems composed of a model railway and a crane which may automatically load and unload cargo from trains where both subsystems need to fulfill functional and safety requirements. The demonstrator is built by using the model-based software engineering principle, while the system level safety is ensured by the combined use of design-time and runtime verification and validation techniques.	Smart cyber-physical systems; Model-driven engineering; Formal methods; Education; Demonstrator	András Vörös16,17,; Márton Búr16,19,; István Ráth17,18,; Ákos Horváth17,18,; Zoltán Micskei17,; László Balogh17,; Bálint Hegyi17,; Benedek Horváth17,; Zsolt Mázló17,18&; Dániel Varró16,17,19	NASA Formal Methods Symposium	https://doi.org/10.1007/978-3-319-77935-5_31		pp 460–467		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2018	MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems		Springer, Cham	nan; References; Year; Bibtex; Link
82	TestNN	Safety Assurance Strategies for Autonomous Vehicles	Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation.	Risk Level; Hazard Analysis; Situation Awareness; System Safety; Autonomous Vehicle	Andrzej Wardziński3	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-540-87698-4_24		pp 277–290		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2008	Safety Assurance Strategies for Autonomous Vehicles		Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
83	TestNN	Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation	Cyber-physical systems (CPS), which integrate algorithmic control with physical processes, often consist of physically distributed components communicating over a network. A malfunctioning or compromised component in such a CPS can lead to costly consequences, especially in the context of public infrastructure. In this short paper, we argue for the importance of constructing invariants (or models) of the physical behaviour exhibited by CPS, motivated by their applications to the control, monitoring, and attestation of components. To achieve this despite the inherent complexity of CPS, we propose a new technique for learning invariants that combines machine learning with ideas from mutation testing. We present a preliminary study on a water treatment system that suggests the efficacy of this approach, propose strategies for establishing confidence in the correctness of invariants, then summarise some research questions and the steps we are taking to investigate them.	Support Vector Machine; Sensor Data; Water Treatment Plant; Mutation Testing; Programmable Logic Controller	Yuqi Chen17,; Christopher M. Poskitt17&; Jun Sun17	International Symposium on Formal Methods	https://doi.org/10.1007/978-3-319-48989-6_10		pp 155–163		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2016	Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation		Springer, Cham	nan; References; Year; Bibtex; Link
84	TestNN	Virtual Environment for Training Autonomous Vehicles	Driver assistance and semi-autonomous features are regularly added to commercial vehicles with two key stakes: collecting data for training self-driving algorithms, and using these vehicles as testbeds for these algorithms. Due to the nature of algorithms used in autonomous vehicles, their behavior in unknown situation is not fully predictable. This calls for extensive testing. In this paper, we propose to use a virtual environment for both testing algorithms for autonomous vehicles and acquiring simulated data for their training. The benefit of this environment is to able to train algorithms with realistic simulated sensor data before their deployment in real life. To this end, the proposed virtual environment has the capacity to generate similar data than real sensors (e.g. cameras, LiDar, ...). After reviewing state-of-the-art techniques and datasets available for the automotive industry, we identify that dynamic data generated on-demand is needed to improve the current results in training autonomous vehicles. Our proposition describes the benefits a virtual environment brings in improving the development, quality and confidence in the algorithms.	Virtual reality; Simulators; Sensor data synthesis; Game physics engine; Machine vision; Neural networks; Datasets	Jerome Leudet16,17,; Tommi Mikkonen16,; François Christophe16&; Tomi Männistö16	Annual Conference Towards Autonomous Robotic Systems	https://doi.org/10.1007/978-3-319-96728-8_14		pp 159–169		Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	SpringerLink	2018	Virtual Environment for Training Autonomous Vehicles		Springer, Cham	nan; References; Year; Bibtex; Link
85	TestNN	Virtualization: System-Level Fault Simulation of SRAM Errors in Automotive Electronic Control Systems	In the coming age of self-driving cars, system-level testing of electronic control will become much more important to ensure dependable operation of automated functions. Modern VLSI devices are not always totally reliable. They can fail due to aging, electromagnetic excitation and many other reasons as described in the other chapters in this book. Therefore, dependable electronic systems must be tested against possible VLSI device failures. This may not be a common practice for meeting the ISO 26262 functional safety standard today, but deemed necessary for full-fledged self-driving cars in future. In this chapter, we demonstrate system-level simulation of SRAM errors and their impact on the design of electronic control. Automotive engine control is chosen as a test bed for this study. Model-based development techniques for automotive control systems are described first as the background and virtual electronic control units are introduced. A dependable SRAM architecture is proposed, and to test it in a practical use, a multilayer simulation modeling of an electromechanical system, its control software, and the SRAM design built-in microcontroller are discussed. To run a fault injection analysis in the SRAM chip at a large scale, a public cloud computing is used. The virtual computer machines in the cloud computing carry out the virtual engine control system simulation in which an instruction set simulator for the microcontroller executes the control software code step by step. The simulation system traces the outcome of the engine control system behavior upon a fault injection into SRAM to evaluate the dependable SRAM design. The large-scale fault analysis proposed here allows us to evaluate quantitatively the impact of the quality design of components on the entire system failure rate.	Electronic control unit (ECU); Model-based development (MBD); Functional safety; Fault injection; Cloud computing	Shigeru Oho2,; Yasuhiro Ito3,; Yasuo Sugure3,; Yohei Nakata4,; Hiroshi Kawaguchi4&; Masahiko Yoshimoto4	VLSI Design and Test for Systems Dependability	https://doi.org/10.1007/978-4-431-56594-9_15		pp 539–551		Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	SpringerLink	2019	Virtualization: System-Level Fault Simulation of SRAM Errors in Automotive Electronic Control Systems		Springer, Tokyo	nan; References; Year; Bibtex; Link
86	TestNN	Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts	Autonomous vehicle safety has received much attention in recent years. Autonomous vehicles will improve road safety by eliminating human errors. However, not all automotive collisions can be avoided. A strategy needs to be developed in the event when an autonomous vehicle encounters an unavoidable collision. Furthermore, the vehicle will need to take responsibility for the safety of its occupants, as well as any other individuals, who may be affected by the vehicle’s behaviour. This paper proposes a control system to assist an autonomous vehicle to make a decision to reduce the risks to occupants potentially involved in highway motorway collisions. Before any decision can be made, the potential collisions need to be assessed for their effects. A quick and numerical method for evaluation of impact of potential collisions was developed. Assessing the Kinetic Energy of the vehicles before and after collisions is proposed as a method to assess the severity of collisions. A simulation model developed calculates the kinetic energy values and recommends an autonomous vehicle the motorway lane to drive into to cause the least severe collision impact. Different scenarios are defined and used to test the simulation model. The results obtained are promising and in line with the decision made by the subject expert. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved	Intelligent systems; Intelligent vehicle highway systems; Kinetic energy; Kinetics; Man machine systems; Motor transportation; Numerical methods; Traffic control; Human errors; Road safety; Simulation model; Vehicle simulation; Autonomous vehicles	Gilbert, Alex; Petrovic, Dobrila; Warwick, Kevin; Serghi, Vasilis	VEHITS 2018 - Proceedings of the 4th International Conference on Vehicle Technology and Intelligent Transport Systems	https://doi.org/10.5220/0006663102430250		243 – 250	"@CONFERENCE{Gilbert2018243,
    author = ""Gilbert, Alex and Petrovic, Dobrila and Warwick, Kevin and Serghi, Vasilis"",
    editor = ""M., Helfert and O., Gusikhin"",
    title = ""Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts"",
    year = ""2018"",
    journal = ""VEHITS 2018 - Proceedings of the 4th International Conference on Vehicle Technology and Intelligent Transport Systems"",
    volume = ""2018-March"",
    pages = ""243 – 250"",
    doi = ""10.5220/0006663102430250"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051927193\&doi=10.5220\%2f0006663102430250\&partnerID=40\&md5=5e43f0b59e89612ef598398306ee60c1"",
    affiliations = ""Coventry University, Faculty of Engineering, Environment and Computing, United Kingdom; Jaguar Land Rover, Autonomous Vehicle Control, United Kingdom"",
    abstract = ""Autonomous vehicle safety has received much attention in recent years. Autonomous vehicles will improve road safety by eliminating human errors. However, not all automotive collisions can be avoided. A strategy needs to be developed in the event when an autonomous vehicle encounters an unavoidable collision. Furthermore, the vehicle will need to take responsibility for the safety of its occupants, as well as any other individuals, who may be affected by the vehicle’s behaviour. This paper proposes a control system to assist an autonomous vehicle to make a decision to reduce the risks to occupants potentially involved in highway motorway collisions. Before any decision can be made, the potential collisions need to be assessed for their effects. A quick and numerical method for evaluation of impact of potential collisions was developed. Assessing the Kinetic Energy of the vehicles before and after collisions is proposed as a method to assess the severity of collisions. A simulation model developed calculates the kinetic energy values and recommends an autonomous vehicle the motorway lane to drive into to cause the least severe collision impact. Different scenarios are defined and used to test the simulation model. The results obtained are promising and in line with the decision made by the subject expert. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved"",
    author_keywords = ""Autonomous Vehicles; Collision Avoidance/Mitigation; Lane-Change Manoeuvre; Simulation Model"",
    keywords = ""Intelligent systems; Intelligent vehicle highway systems; Kinetic energy; Kinetics; Man machine systems; Motor transportation; Numerical methods; Traffic control; Human errors; Road safety; Simulation model; Vehicle simulation; Autonomous vehicles"",
    publisher = ""SciTePress"",
    isbn = ""978-989758293-6"",
    language = ""English"",
    abbrev_source_title = ""VEHITS - Proc. Int. Conf. Veh. Technol. Intell. Transport Syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 4th International Conference on Vehicle Technology and Intelligent Transport Systems, VEHITS 2018; Conference date: 16 March 2018 through 18 March 2018; Conference code: 135924; All Open Access, Green Open Access, Hybrid Gold Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus	2018	 Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051927193&doi=10.5220%2f0006663102430250&partnerID=40&md5=5e43f0b59e89612ef598398306ee60c1	SciTePress	nan; References
87	TestNN	Considerations of Artificial Intelligence Safety Engineering for Unmanned Aircraft	Unmanned aircraft systems promise to be useful for a multitude of applications such as cargo transport and disaster recovery. The research on increased autonomous decision-making capabilities is therefore rapidly growing and advancing. However, the safe use, certification, and airspace integration for unmanned aircraft in a broad fashion is still unclear. Standards for development and verification of manned aircraft are either only partially applicable or resulting safety and verification efforts are unrealistic in practice due to the higher level of autonomy required by unmanned aircraft. Machine learning techniques are hard to interpret for a human and their outcome is strongly dependent on the training data. This work presents the current certification practices in unmanned aviation in the context of autonomy and artificial intelligence. Specifically, the recently introduced categories of unmanned aircraft systems and the specific operation risk assessment are described, which provide means for flight permission not solely focusing on the aircraft but also incorporating the target operation. Exemplary, we show how the specific operation risk assessment might be used as an enabler for hard-to-certify techniques by taking the operation into account during system design.	Aerospace; Certification; AI-based system; Unmanned aircraft systems; Verification and validation	Sebastian Schirmer17,; Christoph Torens17,; Florian Nikodem17&; Johann Dauer17	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-319-99229-7_40		pp 465–472		Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	SpringerLink	2018	Considerations of artificial intelligence safety engineering for unmanned aircraft.		Springer, Cham	nan; References; Year; Bibtex; Link
88	TestNN	DeepGauge: multi-granularity testing criteria for deep learning systems	Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems.		LeiMa; FelixJuefei-Xu; FuyuanZhang; JiyuanSun; MinhuiXue; BoLi; ChunyangChen; TingSu; LiLi; YangLiu; JianjunZhao; YadongWang	ASE '18: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering	https://doi.org/10.1145/3238147.3238202		20-131		Included	Included	new_screen			1	ACM	2018	 DeepGauge: multi-granularity testing criteria for deep learning systems		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
89	TestNN	Deeproad: GaN-based metamorphic testing and input validation framework for autonomous driving systems	While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well. © 2018 Association for Computing Machinery.	Automatic test pattern generation; Deep neural networks; Gallium nitride; III-V semiconductors; Online systems; Safety testing; Software testing; Adversarial networks; Autonomous driving; Extreme conditions; Image transformations; Improving systems; Input validation; Metamorphic testing; Test generations; Image enhancement	Zhang, Mengshi; Zhang, Yuqun; Zhang, Lingming; Liu, Cong; Khurshid, Sarfraz	ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering	https://doi.org/10.1145/3238147.3238187		132 – 142	"@CONFERENCE{Zhang2018132,
    author = ""Zhang, Mengshi and Zhang, Yuqun and Zhang, Lingming and Liu, Cong and Khurshid, Sarfraz"",
    editor = ""C., Kastner and M., Huchard and G., Fraser"",
    title = ""Deeproad: GaN-based metamorphic testing and input validation framework for autonomous driving systems"",
    year = ""2018"",
    journal = ""ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering"",
    pages = ""132 – 142"",
    doi = ""10.1145/3238147.3238187"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056509092\&doi=10.1145\%2f3238147.3238187\&partnerID=40\&md5=1d01dd8945cf7323da3424fc0a43a6ff"",
    affiliations = ""University of Texas, Austin, United States; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, China; University of Texas, Dallas, United States"",
    abstract = ""While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well. © 2018 Association for Computing Machinery."",
    author_keywords = ""Deep neural networks; Input validation; Software testing; Test generation"",
    keywords = ""Automatic test pattern generation; Deep neural networks; Gallium nitride; III-V semiconductors; Online systems; Safety testing; Software testing; Adversarial networks; Autonomous driving; Extreme conditions; Image transformations; Improving systems; Input validation; Metamorphic testing; Test generations; Image enhancement"",
    correspondence_address = ""Y. Zhang; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, China; email: zhangyq@sustc.edu.cn"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035937-5"",
    language = ""English"",
    abbrev_source_title = ""ASE - Proc. ACM/IEEE Int. Conf. Autom. Soft. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 416; Conference name: 33rd IEEE/ACM International Conference on Automated Software Engineering, ASE 2018; Conference date: 3 September 2018 through 7 September 2018; Conference code: 140337; All Open Access, Bronze Open Access""
}
"	Included	Included	new_screen			1	Scopus	2018	DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems.	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056509092&doi=10.1145%2f3238147.3238187&partnerID=40&md5=1d01dd8945cf7323da3424fc0a43a6ff	Association for Computing Machinery, Inc	nan; References
90	TestNN	DLFuzz: Differential fuzzing testing of deep learning systems	Deep learning (DL) systems are increasingly applied to safetycritical domains such as autonomous driving cars. It is of significant importance to ensure the reliability and robustness of DL systems. Existing testing methodologies always fail to include rare inputs in the testing dataset and exhibit low neuron coverage. In this paper, we propose DLFuzz, the first differential fuzzing testing framework to guide DL systems exposing incorrect behaviors. DLFuzz keeps minutely mutating the input to maximize the neuron coverage and the prediction difference between the original input and the mutated input, without manual labeling effort or cross-referencing oracles from other DL systems with the same functionality.We present empirical evaluations on two well-known datasets to demonstrate its efficiency. Compared with DeepXplore, the state-of-the-art DL whitebox testing framework, DLFuzz does not require extra efforts to find similar functional DL systems for cross-referencing check, but could generate 338.59% more adversarial inputs with 89.82% smaller perturbations, averagely obtain 2.86% higher neuron coverage, and save 20.11% time consumption. © 2018 Association for Computing Machinery.	Neurons; Powertrains; Software engineering; Statistical tests; Autonomous driving; Empirical evaluations; Reliability and robustness; Safety-critical domain; Testing framework; Testing methodology; Time consumption; White-box testing; Deep learning	Guo, Jianmin; Jiang, Yu; Zhao, Yue; Chen, Quan; Sun, Jiaguang	ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering	https://doi.org/10.1145/3236024.3264835		739 – 743	"@CONFERENCE{Guo2018739,
    author = ""Guo, Jianmin and Jiang, Yu and Zhao, Yue and Chen, Quan and Sun, Jiaguang"",
    editor = ""A., Garci and C.S., Pasareanu and G.T., Leavens"",
    title = ""DLFuzz: Differential fuzzing testing of deep learning systems"",
    year = ""2018"",
    journal = ""ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering"",
    pages = ""739 – 743"",
    doi = ""10.1145/3236024.3264835"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058304120\&doi=10.1145\%2f3236024.3264835\&partnerID=40\&md5=ce34bac0d915f65df8a0af97678ad7c6"",
    affiliations = ""School of Software, Tsinghua University, Beijing, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"",
    abstract = ""Deep learning (DL) systems are increasingly applied to safetycritical domains such as autonomous driving cars. It is of significant importance to ensure the reliability and robustness of DL systems. Existing testing methodologies always fail to include rare inputs in the testing dataset and exhibit low neuron coverage. In this paper, we propose DLFuzz, the first differential fuzzing testing framework to guide DL systems exposing incorrect behaviors. DLFuzz keeps minutely mutating the input to maximize the neuron coverage and the prediction difference between the original input and the mutated input, without manual labeling effort or cross-referencing oracles from other DL systems with the same functionality.We present empirical evaluations on two well-known datasets to demonstrate its efficiency. Compared with DeepXplore, the state-of-the-art DL whitebox testing framework, DLFuzz does not require extra efforts to find similar functional DL systems for cross-referencing check, but could generate 338.59\% more adversarial inputs with 89.82\% smaller perturbations, averagely obtain 2.86\% higher neuron coverage, and save 20.11\% time consumption. © 2018 Association for Computing Machinery."",
    author_keywords = ""Deep Learning; Fuzzing Testing; Neuron Coverage"",
    keywords = ""Neurons; Powertrains; Software engineering; Statistical tests; Autonomous driving; Empirical evaluations; Reliability and robustness; Safety-critical domain; Testing framework; Testing methodology; Time consumption; White-box testing; Deep learning"",
    correspondence_address = ""J. Guo; School of Software, Tsinghua University, Beijing, China; email: guojm17@mails.tsinghua.edu.cn"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035573-5"",
    language = ""English"",
    abbrev_source_title = ""ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 190; Conference name: 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018; Conference date: 4 November 2018 through 9 November 2018; Conference code: 142072; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2018	DLFuzz: differential fuzzing testing of deep learning systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058304120&doi=10.1145%2f3236024.3264835&partnerID=40&md5=ce34bac0d915f65df8a0af97678ad7c6	Association for Computing Machinery, Inc	nan; References
91	TestNN	Experimental Resilience Assessment of an Open-Source Driving Agent	Autonomous vehicles (AV) depend on the sensors like RADAR and camera for the perception of the environment, path planning, and control. With the increasing autonomy and interactions with the complex environment, there have been growing concerns regarding the safety and reliability of AVs. This paper presents a Systems-Theoretic Process Analysis (STPA) based fault injection framework to assess the resilience of an open-source driving agent, called openpilot, under different environmental conditions and faults affecting sensor data. To increase the coverage of unsafe scenarios during testing, we use a strategic software fault-injection approach where the triggers for injecting the faults are derived from the unsafe scenarios identified during the high-level hazard analysis of the system. The experimental results show that the proposed strategic fault injection approach increases the hazard coverage compared to random fault injection and, thus, can help with more effective simulation of safety-critical faults and testing of AVs. In addition, the paper provides insights on the performance of openpilot safety mechanisms and its ability in timely detection and recovery from faulty inputs.		Abu Hasnat Mohammad Rubaiyat; Yongming Qin; Homa Alemzadeh	2018 IEEE 23rd Pacific Rim International Symposium on Dependable Computing (PRDC)	https://doi.org/10.1109/PRDC.2018.00016				Included	Included	new_screen			1	IEEE	2018	Experimental Resilience Assessment of An Open-Source Driving Agent 		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
92	TestNN	Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations	Deep Neural Networks are achieving great success in various fields. However, their use remains limited to non critical applications because their behavior is unpredictable and unsafe. In this paper we propose some fault tolerant approaches based on diversifying learning in order to improve DNNs dependability and particularly safety. Our main goal is to increase trust in the outcome of deep learning mechanisms by recognizing the unlearned inputs and preventing misclassification. © 2018	Accident prevention; Artificial intelligence; Autonomous vehicles; Deep learning; Deep neural networks; Fault tolerance; Critical applications; Fault-tolerant; Learning mechanism; Misclassifications; Neural networks	Rhazali, Kaoutar; Lussier, Benjamin; Schön, Walter; Geronimi, Stéphane	 IFAC-PapersOnLine	https://doi.org/10.1016/j.ifacol.2018.09.525		31 – 37	"@CONFERENCE{Rhazali201831,
    author = ""Rhazali, Kaoutar and Lussier, Benjamin and Schön, Walter and Geronimi, Stéphane"",
    title = ""Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations"",
    year = ""2018"",
    volume = ""51"",
    number = ""24"",
    pages = ""31 – 37"",
    doi = ""10.1016/j.ifacol.2018.09.525"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054570837\&doi=10.1016\%2fj.ifacol.2018.09.525\&partnerID=40\&md5=b86125e80c2cb769e4948714e3b3e43a"",
    affiliations = ""Sorbonne Universités, Université de Technologie de Compiègne, CNRS, UMR 7253, Heudiasyc CS 60 319, Compiègne, 60203, France; Groupe PSA, Direction de la recherche et de l'innovation automobile, Route de Gisy, Vélizy Villacoublay, 78943, Cedex, France"",
    abstract = ""Deep Neural Networks are achieving great success in various fields. However, their use remains limited to non critical applications because their behavior is unpredictable and unsafe. In this paper we propose some fault tolerant approaches based on diversifying learning in order to improve DNNs dependability and particularly safety. Our main goal is to increase trust in the outcome of deep learning mechanisms by recognizing the unlearned inputs and preventing misclassification. © 2018"",
    author_keywords = ""Artificial Intelligence; Autonomous Vehicles; Fault Tolerance; Neural Networks; Safety"",
    keywords = ""Accident prevention; Artificial intelligence; Autonomous vehicles; Deep learning; Deep neural networks; Fault tolerance; Critical applications; Fault-tolerant; Learning mechanism; Misclassifications; Neural networks"",
    publisher = ""Elsevier B.V."",
    issn = ""24058963"",
    language = ""English"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 7; All Open Access, Gold Open Access""
}
"	Included	Included	new_screen			1	Scopus	2018	Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054570837&doi=10.1016%2fj.ifacol.2018.09.525&partnerID=40&md5=b86125e80c2cb769e4948714e3b3e43a	Elsevier B.V.	nan; Venue; References
93	TestNN	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. © 1993-2012 IEEE.	Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles	Li, Nan; Oyler, Dave W.; Zhang, Mengxuan; Yildiz, Yildiray; Kolmanovsky, Ilya; Girard, Anouck R.	IEEE Transactions on Control Systems Technology	https://doi.org/10.1109/TCST.2017.2723574		1782 – 1797	"@ARTICLE{Li20181782,
    author = ""Li, Nan and Oyler, Dave W. and Zhang, Mengxuan and Yildiz, Yildiray and Kolmanovsky, Ilya and Girard, Anouck R."",
    title = ""Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems"",
    year = ""2018"",
    journal = ""IEEE Transactions on Control Systems Technology"",
    volume = ""26"",
    number = ""5"",
    pages = ""1782 – 1797"",
    doi = ""10.1109/TCST.2017.2723574"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873\&doi=10.1109\%2fTCST.2017.2723574\&partnerID=40\&md5=886568f3ecc536e5329fc3b743b980a4"",
    affiliations = ""Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, MI, United States; Department of Mechanical Engineering, Bilkent University, Ankara, 06800, Turkey"",
    abstract = ""Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. © 1993-2012 IEEE."",
    author_keywords = ""Autonomous vehicles; game theory; reinforcement learning (RL); traffic modeling; verification and validation (V\&V)"",
    keywords = ""Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles"",
    correspondence_address = ""N. Li; Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, United States; email: nanli@umich.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10636536"",
    coden = ""IETTE"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans Control Syst Technol"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 184; All Open Access, Bronze Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2018	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873&doi=10.1109%2fTCST.2017.2723574&partnerID=40&md5=886568f3ecc536e5329fc3b743b980a4	Institute of Electrical and Electronics Engineers Inc.	nan; References
94	TestNN	Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical & Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system. © 2017 IEEE.	Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment	Khastgir, Siddartha; Sivencrona, Hakan; Dhadyalla, Gunwant; Billing, Peter; Birrell, Stewart; Jennings, Paul	IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC	https://doi.org/10.1109/ITSC.2017.8317868		1 – 6	"@CONFERENCE{Khastgir20171,
    author = ""Khastgir, Siddartha and Sivencrona, Hakan and Dhadyalla, Gunwant and Billing, Peter and Birrell, Stewart and Jennings, Paul"",
    title = ""Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles"",
    year = ""2017"",
    journal = ""IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC"",
    volume = ""2018-March"",
    pages = ""1 – 6"",
    doi = ""10.1109/ITSC.2017.8317868"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261765\&doi=10.1109\%2fITSC.2017.8317868\&partnerID=40\&md5=95943814807438cbe7f8afe9498c3e48"",
    affiliations = ""WMG, University of Warwick Coventry, United Kingdom; Qamcom Research and Technology AB, Göteborg, Sweden"",
    abstract = ""Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical \& Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system. © 2017 IEEE."",
    author_keywords = ""HARA; Hazards; ISO 26262; Tactical decisions"",
    keywords = ""Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment"",
    correspondence_address = ""S. Khastgir; WMG, University of Warwick Coventry, United Kingdom; email: S.Khastgir@warwick.ac.uk"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153861525-6"",
    language = ""English"",
    abbrev_source_title = ""IEEE Conf Intell Transport Syst Proc ITSC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 14; Conference name: 20th IEEE International Conference on Intelligent Transportation Systems, ITSC 2017; Conference date: 16 October 2017 through 19 October 2017; Conference code: 135272; All Open Access, Green Open Access""
}
"	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus	2018	 Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261765&doi=10.1109%2fITSC.2017.8317868&partnerID=40&md5=95943814807438cbe7f8afe9498c3e48	Institute of Electrical and Electronics Engineers Inc.	nan; References
95	TestNN	Keeping intelligence under control	Modern software systems, such as smart systems, are based on a continuous interaction with the dynamic and partially unknown environment in which they are deployed. Classical development techniques, based on a complete description of how the system must behave in different environmental conditions, are no longer effective. On the contrary, modern techniques should be able to produce systems that autonomouslylearnhow to behave in different environmental conditions.		PiergiuseppeMallozzi; PatrizioPelliccione; ClaudioMenghi	SE4COG '18: Proceedings of the 1st International Workshop on Software Engineering for Cognitive Services	https://doi.org/10.1145/3195555.3195558		7-40		Included	Included	new_screen			1	ACM	2018	Keeping intelligence under control. 		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
96	TestNN	LEMNA:Explaining Deep Learning based Security Applications	While deep learning has shown a great potential in various domains, the lack of transparency has limited its application in security or safety-critical areas. Existing research has attempted to develop explanation techniques to provide interpretable explanations for each classification decision. Unfortunately, current methods are optimized for non-security tasks ( e.g., image analysis). Their key assumptions are often violated in security applications, leading to a poor explanation fidelity. In this paper, we propose LEMNA, a high-fidelity explanation method dedicated for security applications. Given an input data sample, LEMNA generates a small set of interpretable features to explain how the input sample is classified. The core idea is to approximate a local area of the complex deep learning decision boundary using a simple interpretable model. The local interpretable model is specially designed to (1) handle feature dependency to better work with security applications ( e.g., binary code analysis); and (2) handle nonlinear local boundaries to boost explanation fidelity. We evaluate our system using two popular deep learning applications in security (a malware classifier, and a function start detector for binary reverse-engineering). Extensive evaluations show that LEMNA's explanation has a much higher fidelity level compared to existing methods. In addition, we demonstrate practical use cases of LEMNA to help machine learning developers to validate model behavior, troubleshoot classification errors, and automatically patch the errors of the target models.		WenboGuo; DongliangMu; JunXu; PuruiSu; GangWang; XinyuXing	CCS '18: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security	https://doi.org/10.1145/3243734.3243792		64-379		Included	Included	new_screen			1	ACM	2018	LEMNA: Explaining Deep Learning based Security Applications		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
97	TestNN	MTL Robustness for Path Planning with A*	Maintaining the safety of an autonomous drone while it executes a mission is a primary concern in presence of fixed and mobile enemies. Path planning using A* fails to deliver a feasible, safe plan when a drone has resource limitations in such environments. Enhancing A* with constraint optimization techniques may improve outcomes, but significantly increases path determination time. We define Robust A* (RA*) that introduces the use of a safety margin to maximize the robustness of the drone to meet mission requirements while managing resource restrictions. We rely on a theory of robustness based on Metric Temporal Logic (MTL) as applied to offline verification and online control of hybrid systems. By satisfying the predefined MTL constraints, RA* dynamically defines a safety margin between the drone and an enemy, while constraining the margin size given the drone's resources. The safety margin creates a robust neighborhood around the dynamically generated path. The robust neighborhood holds all valid trajectories within the current world state. When the world state changes, RA* first examines the robust neighborhood to find a valid trajectory before initiating the path re-planning. We evaluate RA* using the Rassim simulator. The results show that the algorithm generates faster and safer paths than the classical A* in the presence of moving enemies.		SarraAlqahtani; IanRiley; SamuelTaylor; RoseGamble; RogerMailler	AAMAS '18: Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems	https://doi.org/10.5555/3237383.3237425		47-255		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	ACM	2018	MTL Robustness for Path Planning with A* for Autonomous Agents and Multiagent Systems		International Foundation for Autonomous Agents and Multiagent Systems	nan; Keywords; References; Year; Bibtex; Link
98	TestNN	 Safety reinforced driving			Schwalb, E., F. Taslimi and H. Kuecuekyan	AUVSI XPONENTIAL 2018, May 1, 2018 - May 3, 2018 Denver, CO, United states					Excluded	Excluded	new_screen		Exclusion: full-text is not available	1		2018				
99	TestNN	Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems	Autonomous systems governed by a variety of adaptive and nondeterministic algorithms are being planned for inclusion into safety-critical environments, such as unmanned aircraft and space systems in both civilian and military applications. However, until autonomous systems are proven and perceived to be capable and resilient in the face of unanticipated conditions, humans will be reluctant or unable to delegate authority, remaining in control aided by machine-based information and decision support. Proving capability, or trustworthiness, is a necessary component of certification. Perceived capability is a component of trust. Trustworthiness is an attribute of a cyber-physical system that requires context-driven metrics to prove and certify. Trust is an attribute of the agents participating in the system and is gained over time and multiple interactions through trustworthy behavior and transparency. Historically, artificial intelligence and machine learning systems provide answers without explanation – without a rationale or insight into the machine “thinking”. In order to function as trusted teammates, machines must be able to explain their decisions and actions. This transparency is a product of both content and communication. NASA’s Autonomy Teaming & TRAjectories for Complex Trusted Operational Reliability (ATTRACTOR) project seeks to build a basis for certification of autonomous systems via establishing metrics for trustworthiness and trust in multi-agent team interactions, using AI explainability and persistent modeling and simulation, in the context of mission planning and execution, with analyzable trajectories. Inspired by Massively Multiplayer Online Role Playing Games (MMORPG) and Serious Gaming, the proposed ATTRACTOR modeling and simulation environment is similar to online gaming environments in which player (aka agent) participants interact with each other, affect their environment, and expect the simulation to persist and change regardless of any individual agent’s active participation. This persistent simulation environment will accommodate individual agents, groups of self-organizing agents, and large-scale infrastructure behavior. The effects of the emerging adaptation and co-evolution can be observed and measured to building a basis of measurable trustworthiness and trust, toward certification of safety-critical autonomous systems. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.	Decision support systems; Embedded systems; Intelligent agents; Learning systems; Military applications; Multi agent systems; NASA; Safety engineering; Serious games; Social networking (online); Transparency; Large scale infrastructures; Massively multiplayer online role-playing games; Nondeterministic algorithms; Operational reliability; Perceived capabilities; Self organizing agents; Simulation environment; Trust and trustworthiness; Autonomous agents	Allen, Bonnie D.	2018 Aviation Technology, Integration, and Operations Conference	https://doi.org/10.2514/6.2018-3844			"@CONFERENCE{Allen2018,
    author = ""Allen, Bonnie D."",
    title = ""Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems"",
    year = ""2018"",
    journal = ""2018 Aviation Technology, Integration, and Operations Conference"",
    doi = ""10.2514/6.2018-3844"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051647799\&doi=10.2514\%2f6.2018-3844\&partnerID=40\&md5=847a402844d0db04809ec3d1c4a07c28"",
    affiliations = ""NASA Senior Technologist for Intelligent Flight Systems, NASA Langley Research Center, MS 492, Hampton, 23681, VA, United States"",
    abstract = ""Autonomous systems governed by a variety of adaptive and nondeterministic algorithms are being planned for inclusion into safety-critical environments, such as unmanned aircraft and space systems in both civilian and military applications. However, until autonomous systems are proven and perceived to be capable and resilient in the face of unanticipated conditions, humans will be reluctant or unable to delegate authority, remaining in control aided by machine-based information and decision support. Proving capability, or trustworthiness, is a necessary component of certification. Perceived capability is a component of trust. Trustworthiness is an attribute of a cyber-physical system that requires context-driven metrics to prove and certify. Trust is an attribute of the agents participating in the system and is gained over time and multiple interactions through trustworthy behavior and transparency. Historically, artificial intelligence and machine learning systems provide answers without explanation – without a rationale or insight into the machine “thinking”. In order to function as trusted teammates, machines must be able to explain their decisions and actions. This transparency is a product of both content and communication. NASA’s Autonomy Teaming \& TRAjectories for Complex Trusted Operational Reliability (ATTRACTOR) project seeks to build a basis for certification of autonomous systems via establishing metrics for trustworthiness and trust in multi-agent team interactions, using AI explainability and persistent modeling and simulation, in the context of mission planning and execution, with analyzable trajectories. Inspired by Massively Multiplayer Online Role Playing Games (MMORPG) and Serious Gaming, the proposed ATTRACTOR modeling and simulation environment is similar to online gaming environments in which player (aka agent) participants interact with each other, affect their environment, and expect the simulation to persist and change regardless of any individual agent’s active participation. This persistent simulation environment will accommodate individual agents, groups of self-organizing agents, and large-scale infrastructure behavior. The effects of the emerging adaptation and co-evolution can be observed and measured to building a basis of measurable trustworthiness and trust, toward certification of safety-critical autonomous systems. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Decision support systems; Embedded systems; Intelligent agents; Learning systems; Military applications; Multi agent systems; NASA; Safety engineering; Serious games; Social networking (online); Transparency; Large scale infrastructures; Massively multiplayer online role-playing games; Nondeterministic algorithms; Operational reliability; Perceived capabilities; Self organizing agents; Simulation environment; Trust and trustworthiness; Autonomous agents"",
    correspondence_address = ""B.D. Allen; NASA Senior Technologist for Intelligent Flight Systems, NASA Langley Research Center, Hampton, MS 492, 23681, United States; email: danette.allen@nasa.gov"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410556-2"",
    language = ""English"",
    abbrev_source_title = ""Aviat. Technol., Integr., Op. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: 18th AIAA Aviation Technology, Integration, and Operations Conference, 2018; Conference date: 25 June 2018 through 29 June 2018; Conference code: 215129""
}
"	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus	2018	 Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051647799&doi=10.2514%2f6.2018-3844&partnerID=40&md5=847a402844d0db04809ec3d1c4a07c28	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
100	TestNN	Tactical Safety Reasoning - A Case for Autonomous Vehicles	Self driving cars have recently attracted academia and industry interest. As planning algorithms become responsible for critical decisions, many questions concerning traffic safety arise. An increased automation level demands proportional impact on safety requirements, currently governed by the ISO 26262 standard. However, ISO 26262 sees safety as a functional property of a system and fails to cover emergent concerns related to autonomous decisions. In order to fill this gap we propose the field of tactical safety, which extends safety analysis to planning and execution of driving maneuvers, response to traffic events or autonomous system failures. It is meant to complement, not to replace functional safety properties of a system and allows the analysis of autonomous agents from a safe behavior point of view. We draw the requirements for tactical safety from an automotive standard which defines functional elements for advanced driving automation systems.		Alexandru Constantin Serban; Erik Poll; Joost Visser	2018 IEEE 87th Vehicular Technology Conference (VTC Spring)	https://doi.org/10.1109/VTCSpring.2018.8417887				Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	IEEE	2018	 Tactical safety reasoning. A case for autonomous vehicles		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
101	TestNN	Validation and verification flight tests of fixed-wing collaborative UASs with high speeds and high inertias	The research objective for this work is to validate and verify guidance, navigation, and control algorithms that are designed for fixed-wing collaborative unmanned aerial systems (UASs) in unstructured environments. A biologically-inspired swarm control theory provides a framework to distribute sensor payloads between several smaller and less complex agents that have local interactions. Controller design and flight testing of large UASs with high speeds and high inertias holding a formation in a dynamically changing environment and in the presence of external disturbances is complex and requires advanced planning and safety measures. Verification and validation flight tests were conducted using a fixed-wing unmanned aerial system with 4 meter wingspans to investigate the robustness of the guidance, navigation, and control algorithms and also test the embedded morphing potential field collision avoidance logic. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.	Air navigation; Antennas; Controllers; Flight dynamics; Safety testing; Biologically inspired swarm controls; Changing environment; External disturbances; Guidance , navigation , and controls; Unmanned aerial systems; Unstructured environments; Validation and verification; Verification-and-validation; Fixed wings	Blevins, Aaron T.; Kim, A. Ram; Shukla, Daksh; Keshmiri, Shawn S.; Huang, Weizhang	2018 Flight Testing Conference	https://doi.org/10.2514/6.2018-4280			"@CONFERENCE{Blevins2018,
    author = ""Blevins, Aaron T. and Kim, A. Ram and Shukla, Daksh and Keshmiri, Shawn S. and Huang, Weizhang"",
    title = ""Validation and verification flight tests of fixed-wing collaborative UASs with high speeds and high inertias"",
    year = ""2018"",
    journal = ""2018 Flight Testing Conference"",
    doi = ""10.2514/6.2018-4280"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051656104\&doi=10.2514\%2f6.2018-4280\&partnerID=40\&md5=c890a0b3855ba6801664c40bbb93328d"",
    affiliations = ""Department of Aerospace Engineering, University of Kansas, Lawrence, 66045, KS, United States"",
    abstract = ""The research objective for this work is to validate and verify guidance, navigation, and control algorithms that are designed for fixed-wing collaborative unmanned aerial systems (UASs) in unstructured environments. A biologically-inspired swarm control theory provides a framework to distribute sensor payloads between several smaller and less complex agents that have local interactions. Controller design and flight testing of large UASs with high speeds and high inertias holding a formation in a dynamically changing environment and in the presence of external disturbances is complex and requires advanced planning and safety measures. Verification and validation flight tests were conducted using a fixed-wing unmanned aerial system with 4 meter wingspans to investigate the robustness of the guidance, navigation, and control algorithms and also test the embedded morphing potential field collision avoidance logic. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Air navigation; Antennas; Controllers; Flight dynamics; Safety testing; Biologically inspired swarm controls; Changing environment; External disturbances; Guidance , navigation , and controls; Unmanned aerial systems; Unstructured environments; Validation and verification; Verification-and-validation; Fixed wings"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410555-5"",
    language = ""English"",
    abbrev_source_title = ""Flight Test. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4; Conference name: AIAA Flight Testing Conference, 2018; Conference date: 25 June 2018 through 29 June 2018; Conference code: 215029""
}
"	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus	2018	 Validation and Verification Flight Tests of Fixed-Wing Collaborative UASs With High Speeds and High Inertias	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051656104&doi=10.2514%2f6.2018-4280&partnerID=40&md5=c890a0b3855ba6801664c40bbb93328d	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
102	TestNN	Virtual Environment for Training Autonomous Vehicles	Driver assistance and semi-autonomous features are regularly added to commercial vehicles with two key stakes: collecting data for training self-driving algorithms, and using these vehicles as testbeds for these algorithms. Due to the nature of algorithms used in autonomous vehicles, their behavior in unknown situation is not fully predictable. This calls for extensive testing. In this paper, we propose to use a virtual environment for both testing algorithms for autonomous vehicles and acquiring simulated data for their training. The benefit of this environment is to able to train algorithms with realistic simulated sensor data before their deployment in real life. To this end, the proposed virtual environment has the capacity to generate similar data than real sensors (e.g. cameras, LiDar, ...). After reviewing state-of-the-art techniques and datasets available for the automotive industry, we identify that dynamic data generated on-demand is needed to improve the current results in training autonomous vehicles. Our proposition describes the benefits a virtual environment brings in improving the development, quality and confidence in the algorithms.	Virtual reality; Simulators; Sensor data synthesis; Game physics engine; Machine vision; Neural networks; Datasets	Jerome Leudet16,17,; Tommi Mikkonen16,; François Christophe16&; Tomi Männistö16	Annual Conference Towards Autonomous Robotic Systems	https://doi.org/10.1007/978-3-319-96728-8_14		pp 159–169		Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	SpringerLink	2018	Virtual Environment for Training Autonomous Vehicles		Springer, Cham	nan; References; Year; Bibtex; Link
103	TestNN	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. © 2019, Springer Nature B.V.	Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms	Dreossi, Tommaso; Donzé, Alexandre; Seshia, Sanjit A.	Journal of Automated Reasoning	https://doi.org/10.1007/s10817-018-09509-5		1031 – 1053	"@ARTICLE{Dreossi20191031,
    author = ""Dreossi, Tommaso and Donzé, Alexandre and Seshia, Sanjit A."",
    title = ""Compositional Falsification of Cyber-Physical Systems with Machine Learning Components"",
    year = ""2019"",
    journal = ""Journal of Automated Reasoning"",
    volume = ""63"",
    number = ""4"",
    pages = ""1031 – 1053"",
    doi = ""10.1007/s10817-018-09509-5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868\&doi=10.1007\%2fs10817-018-09509-5\&partnerID=40\&md5=f87cb216796cb6bb61e71f71664c8f18"",
    affiliations = ""University of California, Berkeley, Berkeley, United States; Decyphir SAS, Moirans, France"",
    abstract = ""Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. © 2019, Springer Nature B.V."",
    author_keywords = ""Autonomous driving; Cyber-physical systems; Deep learning; Falsification; Machine learning; Neural networks; Temporal logic"",
    keywords = ""Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms"",
    correspondence_address = ""T. Dreossi; University of California, Berkeley, Berkeley, United States; email: dreossi@berkeley.edu"",
    publisher = ""Springer Netherlands"",
    issn = ""01687433"",
    coden = ""JAREE"",
    language = ""English"",
    abbrev_source_title = ""J Autom Reasoning"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 97; All Open Access, Green Open Access""
}
"	Included	Included	new_screen			1	Scopus	2017	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868&doi=10.1007%2fs10817-018-09509-5&partnerID=40&md5=f87cb216796cb6bb61e71f71664c8f18	Springer Netherlands	nan; References
104	TestNN	Safety Assurance Strategies for Autonomous Vehicles	Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation.	Risk Level; Hazard Analysis; Situation Awareness; System Safety; Autonomous Vehicle	Andrzej Wardziński3	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-540-87698-4_24		pp 277–290		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	SpringerLink	2008	Safety Assurance Strategies for Autonomous Vehicles		Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
105	TestNN	Outline safety case for the use of autonomous UAVs in unsegregated airspace	Uninhibited air vehicles (UAVs) are routinely deployed in segregated airspace, however, due to organisational difficulty they are only partially integrated with normal air traffic in exceptional circumstances. This presentation examines the correct operation of UAV's software and the formal analysis of the SOAR agent programming language as contributions to the safe deployment of future military UAVs in unsegregated airspace.		C. Pygott	2005 The IEE Forum on Autonomous Systems (Ref. No. 2005/11271)	https://doi.org/10.1049/ic				Excluded	Excluded	snowballing		Exclusion: full-text is not available, not peer-reviewed, only have slides	1	IEEE	2005	Outline safety case for the use of autonomous UAVs in unsegregated airspace		IET	nan; Keywords; References; Pages; Year; Bibtex; Link
106	TestNN	Adaptive verification for an on-line learning neural-based flight control system	This paper presents a complex adaptive systems approach for the verification of an adaptive, online learning, sigma-pi neural network that is used for the Intelligent Flight Control System (IFCS) that has the potential of commercial aviation application. This paper reports on the partial completion of my doctoral dissertation proposal at Nova Southeastern University, in the Graduate School of Computer and Information Sciences. The most significant shortcoming of the prior and current approaches to verifying adaptive neural networks is the application of linear approaches to a non-linear problem. The project will use a MatLab simulation of the sigma-pi adaptive neural network and an aircraft simulation to fly a series of simulated flight tests. As a result of the flight simulations, a statistical analysis of the neural network weights is performed as input to both a complexity analysis and a neural network rule extraction analysis. Complex adaptive methods are a novel approach to overcome previous linear analysis limitations. Future work will be required to analyze emergent behavior of the neural network weights to show stability and convergence characteristics. Advances in computational power and neural network techniques for estimating aerodynamic stability and control derivatives provide opportunity for real-time adaptive control. New verification techniques are needed that substantially increases trustworthiness in the use of these neural network systems in life critical systems. Verification of neural-based IFCS is currently an urgent and significant research and engineering topic since these systems are being looked upon as a new approach for aircraft survivability, for both commercial and military.	Adaptive systems; Aerodynamics; Air traffic control; Computer simulation; Flight dynamics; Learning systems; Neural networks; Online systems; Statistical methods; Intelligent Flight Control System (IFCS); MatLab simulation; Non-linear problem; Rule extraction analysis; Civil aviation	Broderick, Ronald L.	AIAA/IEEE Digital Avionics Systems Conference - Proceedings	https://doi.org/10.1109/DASC.2005.1563392			"@CONFERENCE{Broderick2005,
    author = ""Broderick, Ronald L."",
    title = ""Adaptive verification for an on-line learning neural-based flight control system"",
    year = ""2005"",
    journal = ""AIAA/IEEE Digital Avionics Systems Conference - Proceedings"",
    volume = ""1"",
    doi = ""10.1109/DASC.2005.1563392"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746281095\&doi=10.1109\%2fDASC.2005.1563392\&partnerID=40\&md5=db62d823d4caaea803d8a361046397c2"",
    affiliations = ""Graduate School of Computer and Information Science, Nova Southeastern University, Ft. Lauderdale, FL, United States"",
    abstract = ""This paper presents a complex adaptive systems approach for the verification of an adaptive, online learning, sigma-pi neural network that is used for the Intelligent Flight Control System (IFCS) that has the potential of commercial aviation application. This paper reports on the partial completion of my doctoral dissertation proposal at Nova Southeastern University, in the Graduate School of Computer and Information Sciences. The most significant shortcoming of the prior and current approaches to verifying adaptive neural networks is the application of linear approaches to a non-linear problem. The project will use a MatLab simulation of the sigma-pi adaptive neural network and an aircraft simulation to fly a series of simulated flight tests. As a result of the flight simulations, a statistical analysis of the neural network weights is performed as input to both a complexity analysis and a neural network rule extraction analysis. Complex adaptive methods are a novel approach to overcome previous linear analysis limitations. Future work will be required to analyze emergent behavior of the neural network weights to show stability and convergence characteristics. Advances in computational power and neural network techniques for estimating aerodynamic stability and control derivatives provide opportunity for real-time adaptive control. New verification techniques are needed that substantially increases trustworthiness in the use of these neural network systems in life critical systems. Verification of neural-based IFCS is currently an urgent and significant research and engineering topic since these systems are being looked upon as a new approach for aircraft survivability, for both commercial and military."",
    keywords = ""Adaptive systems; Aerodynamics; Air traffic control; Computer simulation; Flight dynamics; Learning systems; Neural networks; Online systems; Statistical methods; Intelligent Flight Control System (IFCS); MatLab simulation; Non-linear problem; Rule extraction analysis; Civil aviation"",
    isbn = ""0780393074; 978-078039307-3"",
    coden = ""ADACF"",
    language = ""English"",
    abbrev_source_title = ""AIAA IEEE Dig Avionics Syst Conf Proc"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: 24th DASC: 24th Digital Avionics Systems Conference; Conference date: 30 October 2005 through 3 November 2005; Conference code: 66374""
}
"	Excluded	Excluded	snowballing		Exclusion: not aimed at testing/verification approach	1	Scopus	2005	 Adaptive verification for an on-line learning neural-based flight control system	https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746281095&doi=10.1109%2fDASC.2005.1563392&partnerID=40&md5=db62d823d4caaea803d8a361046397c2		nan; References; Pages; Publisher
107	TestNN	An Abstraction-Refinement Approach to Verification of Artificial Neural Networks	A key problem in the adoption of artificial neural networks in safety-related applications is that misbehaviors can be hardly ruled out with traditional analytical or probabilistic techniques. In this paper we focus on specific networks known as Multi-Layer Perceptrons (MLPs), and we propose a solution to verify their safety using abstractions to Boolean combinations of linear arithmetic constraints. We show that our abstractions are consistent, i.e., whenever the abstract MLP is declared to be safe, the same holds for the concrete one. Spurious counterexamples, on the other hand, trigger refinements and can be leveraged to automate the correction of misbehaviors. We describe an implementation of our approach based on theHySATsolver, detailing the abstraction-refinement process and the automated correction strategy. Finally, we present experimental results confirming the feasibility of our approach on a realistic case study.	Root Mean Square Error; Hide Layer; Input Vector; Generalization Error; Abstract Domain	Luca Pulina19&; Armando Tacchella19	International Conference on Computer Aided Verification	https://doi.org/10.1007/978-3-642-14295-6_24		pp 243–257		Excluded	Excluded	snowballing		Exclusion: previous verison of [91]	1	SpringerLink	2010	 An abstraction-refinement approach to verification of artificial neural networks		Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
108	TestNN	NeVer: a tool for artificial neural networks verification	The adoption of Artificial Neural Networks (ANNs) in safety-related applications is often avoided because it is difficult to rule out possible misbehaviors with traditional analytical or probabilistic techniques. In this paper we present NeVer, our tool for checking safety of ANNs. NeVerencodes the problem of verifying safety of ANNs into the problem of satisfying corresponding Boolean combinations of linear arithmetic constraints. We describe the main verification algorithm and the structure of NeVer. We present also empirical results confirming the effectiveness of NeVeron realistic case studies.	Artificial Intelligence; Formal methods for adaptive systems; Abstraction techniques; Algorithms and tools for verification; 68Q60; 68Q45	Luca Pulina1&; Armando Tacchella1	Annals of Mathematics and Artificial Intelligence	https://doi.org/10.1007/s10472-011-9243-0	"citation_journal_title=IEEE Trans. Syst. Man Cybern., Part C Appl. Rev.; citation_title=Neural networks for classification: a survey; citation_author=GP Zhang; citation_volume=30; citation_issue=4; citation_publication_date=2000; citation_pages=451-462; citation_doi=10.1109/5326.897072; citation_id=CR1; Smith, D.J., Simpson, K.G.L.: Functional Safety – A Straightforward Guide to Applying IEC 61505 and Related Standards (2nd edn.). Elsevier (2004); Schumann, J., Gupta, P., Nelson, S.: On verification & validation of neural network based controllers. In: Proc. of International Conf. on Engineering Applications of Neural Networks (EANN’03) (2003); citation_journal_title=Neural Comput. Appl.; citation_title=Developing artificial neural networks for safety critical systems; citation_author=Z Kurd, T Kelly, J Austin; citation_volume=16; citation_issue=1; citation_publication_date=2007; citation_pages=11-19; citation_id=CR4; citation_journal_title=ACM Trans. Program. Lang. Syst. (TOPLAS); citation_title=Automatic verification of finite-state concurrent systems using temporal logic specifications; citation_author=EM Clarke, EA Emerson, AP Sistla; citation_volume=8; citation_issue=2; citation_publication_date=1986; citation_pages=263; citation_doi=10.1145/5397.5399; citation_id=CR5; Queille, J., Sifakis, J.: Specification and verification of concurrent systems in CESAR. In: International Symposium on Programming, pp. 337–351. Springer (1982); Schubert, T.: High level formal verification of next-generation microprocessors. In: Proceedings of the 40th annual Design Automation Conference. ACM (2003); Ball, T., Cook, B., Levin, V., Rajamani, S.K.: SLAM and static driver verifier: Technology transfer of formal methods inside Microsoft. In: Integrated Formal Methods, pp. 1–20. Springer (2004); Armando, A., Carbone, R., Compagna, L.: LTL model checking for security protocols. In: 20th IEEE Computer Security Foundations Symposium, pp. 385–396 (2007); Alur, R., Henzinger, T.A., Ho, P.: Automatic symbolic verification of embedded systems. In: IEEE Real-Time Systems Symposium, pp. 2–11 (1993); Clarke, E.M., Grumberg, O., Peled, D.A.: Model Checking. Springer (1999); citation_journal_title=Neural Netw; citation_title=Multilayer feedforward networks are universal approximators; citation_author=K Hornik, M Stinchcombe, H White; citation_volume=2; citation_issue=5; citation_publication_date=1989; citation_pages=359-366; citation_doi=10.1016/0893-6080(89)90020-8; citation_id=CR12; Pulina, L., Tacchella, A.: An abstraction-refinement approach to verification of artificial neural networks. In: 22nd International Conference on Computer Aided Verification (CAV 2010). Lecture Notes in Computer Science, vol. 6174, pp. 243–257. Springer (2010); Solar-Lezama, A., Jones, C.G., Bodik, R.: Sketching concurrent data structures. In: 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 136–148. ACM (2008); Vechev, M., Yahav, E., Yorsh, G.G.: Abstraction-guided synthesis of synchronization. In: 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pp. 327–338. ACM (2010); citation_journal_title=J. Mach. Learn. Res.; citation_title=Shark; citation_author=C Igel, T Glasmachers, V Heidrich-Meisner; citation_volume=9; citation_publication_date=2008; citation_pages=993-996; citation_id=CR16; citation_journal_title=JSAT, Boolean Modeling and Computation; citation_title=Efficient solving of large non-linear arithmetic constraint systems with complex boolean structure; citation_author=M Franzle, C Herde, T Teige, S Ratschan, T Schubert; citation_volume=1; citation_publication_date=2007; citation_pages=209-236; citation_id=CR17; citation_journal_title=Cem. Concr. Res.; citation_title=Modeling of strength of high-performance concrete using artificial neural networks; citation_author=IC Yeh; citation_volume=28; citation_issue=12; citation_publication_date=1998; citation_pages=1797-1808; citation_doi=10.1016/S0008-8846(98)00165-3; citation_id=CR18; Haykin, S.: Neural Networks: a Comprehensive Foundation. Prentice Hall (2008); citation_journal_title=Artif. Intell.; citation_title=Consistency in networks of relations; citation_author=AK Mackworth; citation_volume=8; citation_issue=1; citation_publication_date=1977; citation_pages=99-118; citation_doi=10.1016/0004-3702(77)90007-8; citation_id=CR20; Van Hentenryck, P.: Numerica: a modeling language for global optimization. In: Fifteenth International Joint Conference on Artificial Intelligence (IJCAI), pp. 1642–1650 (1997); Rossi, F., Van Beek, P., Walsh, T.: Handbook of Constraint Programming. Elsevier Science Ltd (2006); Barichard, V., Hao, J.K.: A population and interval constraint propagation algorithm. In: Evolutionary Multi-Criterion Optimization, Second International Conference (EMO 2003), pp. 88–101. Springer (2003); citation_title=Conflict-driven Clause Learning SAT Solvers. Handbook of Satisfiability; citation_publication_date=2009; citation_id=CR24; citation_author=J Marques-Silva; citation_author=I Lynce; citation_author=S Malik; citation_publisher=IOS Press; citation_title=Satisfiability Modulo Theories. Handbook of Satisfiability; citation_publication_date=2009; citation_id=CR25; citation_author=C Barrett; citation_author=R Sebastiani; citation_author=SA Seshia; citation_author=C Tinelli; citation_publisher=IOS Press; Jermann, C., Sam-Haroud, D., Trombettoni, G. (eds.): CP Workshop on Interval Analysis, Constraint Propagation, Applications (IntCP 2009) (2009); Cousot, P., Cousot, R.: Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In: 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pp. 238–252 (1977); citation_journal_title=J. ACM (JACM); citation_title=Counterexample-guided abstraction refinement for symbolic model checking; citation_author=E Clarke, O Grumberg, S Jha, Y Lu, H Veith; citation_volume=50; citation_issue=5; citation_publication_date=2003; citation_pages=794; citation_doi=10.1145/876638.876643; citation_id=CR28; citation_title=Yale: rapid prototyping for complex data mining tasks; citation_inbook_title=12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’06); citation_publication_date=2006; citation_pages=935-940; citation_id=CR29; citation_author=I Mierswa; citation_author=M Wurst; citation_author=R Klinkenberg; citation_author=M Scholz; citation_author=T Euler; citation_publisher=ACM; Gordeau, R.: Roboop – a robotics object oriented package in C++. 
                    http://www.cours.polymtl.ca/roboop
                    
                   (2005); Rabunal, J.R., Dorrado, J.: Artificial Neural Networks in Real-life Applications. Idea Group Pub (2006); Witten, I.H., Frank, E.: Data Mining (2nd edn.). Morgan Kaufmann (2005); citation_journal_title=J. Artif. Intell. Res.; citation_title=Asimovian adaptive agents; citation_author=DF Gordon; citation_volume=13; citation_issue=1; citation_publication_date=2000; citation_pages=95-153; citation_id=CR33; Pappas, G., Kress-Gazit, H. (eds.): ICRA Workshop on Formal Methods in Robotics and Automation (2009)"			Included	Included	snowballing			1	SpringerLink	2011	NeVer: a tool for artificial neural networks verification		Springer Link	nan; Pages; Year; Bibtex; Link
109	TestNN	Challenging SMT solvers to verify neural networks	In recent years, Satisfiability Modulo Theory (SMT) solvers are becoming increasingly popular in the Computer Aided Verification and Reasoning community. Used natively or as back-engines, they are accumulating a record of success stories and, as witnessed by the annual SMT competition, their performances and capacity are also increasing steadily. Introduced in previous contributions of ours, a new application domain providing an outstanding challenge for SMT solvers is represented by verification of Multi-Layer Perceptrons (MLPs) a widely-adopted kind of artificial neural network. In this paper we present an extensive evaluation of the current state-of-the-art SMT solvers and assess their potential in the promising domain of MLP verification.		LucaPulina; ArmandoTacchella	AI Communications	https://doi.org/10.5555/2350156.2350160		17-135		Included	Included	snowballing			1	ACM	2012	Challenging SMT solvers to verify neural networks		IOS Press	nan; Keywords; References; Year; Bibtex; Link
110	TestNN	Intriguing properties of neural networks	Abstract:Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.		Christian Szegedy; Wojciech Zaremba; Ilya Sutskever; Joan Bruna; Dumitru Erhan; Ian Goodfellow; Rob Fergus		https://doi.org/10.48550/arXiv.1312.6199				Included	Included	snowballing			1	arXiv	2013	Intriguing properties of neural networks			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
111	TestNN	Toward guaranteed illumination models for non-convex objects	Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambert Ian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build models for the set of images across illumination variation with worst-case performance guarantees, for nonconvex Lambertian objects. Namely, a natural verification test based on the distance to the model guarantees to accept any image which can be sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. These models are generated by sampling illumination directions with sufficient density, which follows from a new perturbation bound for directional illuminated images in the Lambertian model. As the number of such images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original model. © 2013 IEEE.	Face recognition; Dimensionality reduction; Illumination cone; Illumination variation; Lambertian surfaces; Low-rank decomposition; Nonconvex; Object detection and recognition; Worst-case performance; Acceptance tests	Zhang, Yuqian; Mu, Cun; Kuo, Han-Wen; Wright, John	Proceedings of the IEEE International Conference on Computer Vision	https://doi.org/10.1109/ICCV.2013.120		937 – 944	"@CONFERENCE{Zhang2013937,
    author = ""Zhang, Yuqian and Mu, Cun and Kuo, Han-Wen and Wright, John"",
    title = ""Toward guaranteed illumination models for non-convex objects"",
    year = ""2013"",
    journal = ""Proceedings of the IEEE International Conference on Computer Vision"",
    pages = ""937 – 944"",
    doi = ""10.1109/ICCV.2013.120"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898771090\&doi=10.1109\%2fICCV.2013.120\&partnerID=40\&md5=a5c21cb9ee32e20ccc344f0cc326b4f9"",
    affiliations = ""Columbia University, New York City, NY, United States"",
    abstract = ""Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambert Ian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build models for the set of images across illumination variation with worst-case performance guarantees, for nonconvex Lambertian objects. Namely, a natural verification test based on the distance to the model guarantees to accept any image which can be sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. These models are generated by sampling illumination directions with sufficient density, which follows from a new perturbation bound for directional illuminated images in the Lambertian model. As the number of such images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original model. © 2013 IEEE."",
    author_keywords = ""Illumination cone model; Lambertian surface; Nonconvex object; Object instance verification"",
    keywords = ""Face recognition; Dimensionality reduction; Illumination cone; Illumination variation; Lambertian surfaces; Low-rank decomposition; Nonconvex; Object detection and recognition; Worst-case performance; Acceptance tests"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147992839-2"",
    coden = ""PICVE"",
    language = ""English"",
    abbrev_source_title = ""Proc IEEE Int Conf Comput Vision"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 9; Conference name: 2013 14th IEEE International Conference on Computer Vision, ICCV 2013; Conference date: 1 December 2013 through 8 December 2013; Conference code: 104551; All Open Access, Green Open Access""
}
"	Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2013	 Toward guaranteed illumination models for non-convex objects	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898771090&doi=10.1109%2fICCV.2013.120&partnerID=40&md5=a5c21cb9ee32e20ccc344f0cc326b4f9	Institute of Electrical and Electronics Engineers Inc.	nan; References
112	TestNN	Deep inside convolutional networks: Visualising image classification models and saliency maps	This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13]. © 2014 International Conference on Learning Representations, ICLR. All rights reserved.	Convolution; Image segmentation; Visualization; Classification models; Convnet; Convolutional networks; Gradient based; Input image; Object segmentation; Saliency map; Image classification	Simonyan, Karen; Vedaldi, Andrea; Zisserman, Andrew	2nd International Conference on Learning Representations, ICLR 2014 - Workshop Track Proceedings				"@CONFERENCE{Simonyan2014,
    author = ""Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew"",
    title = ""Deep inside convolutional networks: Visualising image classification models and saliency maps"",
    year = ""2014"",
    journal = ""2nd International Conference on Learning Representations, ICLR 2014 - Workshop Track Proceedings"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953896\&partnerID=40\&md5=5897b0590b10086cbf0bd356292a0908"",
    affiliations = ""Visual Geometry Group, University of Oxford, United Kingdom"",
    abstract = ""This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13]. © 2014 International Conference on Learning Representations, ICLR. All rights reserved."",
    keywords = ""Convolution; Image segmentation; Visualization; Classification models; Convnet; Convolutional networks; Gradient based; Input image; Object segmentation; Saliency map; Image classification"",
    publisher = ""International Conference on Learning Representations, ICLR"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Learn. Represent., ICLR - Workshop Track Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1754; Conference name: 2nd International Conference on Learning Representations, ICLR 2014; Conference date: 14 April 2014 through 16 April 2014; Conference code: 149800""
}
"	Included	Included	snowballing			1	Scopus	2013	Deep inside convolutional networks: Visualising image classification models and saliency maps	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953896&partnerID=40&md5=5897b0590b10086cbf0bd356292a0908	International Conference on Learning Representations, ICLR	nan; References; Pages; DOI
113	TestNN	AxNN: Energy-efficient neuromorphic systems using approximate computing	Neuromorphic algorithms, which are comprised of highly complex, large-scale networks of artificial neurons, are increasingly used for a variety of recognition, classification, search and vision tasks. However, their computational and energy requirements can be quite high, and hence their energy-efficient implementation is of great interest. We propose a new approach to design energy-efficient hardware implementations of large-scale neural networks (NNs) using approximate computing. Our work is motivated by the observations that (i) NNs are used in applications where less-than-perfect results are acceptable, and often inevitable, and (ii) they are highly resilient to inexactness in many (but not all) of their constituent computations. We make two key contributions. First, we propose a method to transform any given NN into an Approximate Neural Network (AxNN). This is performed by (i) adapting the backpropagation technique, which is commonly used to train these networks, to quantify the impact of approximating each neuron to the overall network quality (e.g., classification accuracy), and (ii) selectively approximating those neurons that impact network quality the least. Further, we make the key observation that training is a naturally error-healing process that can be used to mitigate the impact of approximations to neurons. Therefore, we incrementally retrain the network with the approximations in-place, reclaiming a significant portion of the quality ceded by approximations. As a second contribution, we propose a programmable and quality-configurable neuromorphic processing engine (qcNPE), which utilizes arrays of specialized processing elements that execute neuron computations with dynamically configurable accuracies and can be used to execute AxNNs from diverse applications. We evaluated the proposed approach by constructing AXNNs for 6 recognition applications (ranging in complexity from 12-47,818 neurons and 160-3,155,968 connections) and executing them on two different platforms-qcNPE implementation containing 272 processing elements in 45nm technology and a commodity Intel Xeon server. Our results demonstrate 1.14X-1.92X energy benefits for virtually no loss (< 0.5%) in output quality, and even higher improvements (upto 2.3X) when some loss (upto 7.5%) in output quality is acceptable. © 2014 ACM.	Algorithms; Complex networks; Hardware; Low power electronics; Neural networks; Neurons; Power electronics; Approximate Computing; Backpropagation techniques; Classification accuracy; Diverse applications; Hardware implementations; Large-scale network; Neural networks (NNS); Neuromorphic systems; Energy efficiency	Venkataramani, Swagath; Ranjan, Ashish; Roy, Kaushik; Raghunathan, Anand	Proceedings of the International Symposium on Low Power Electronics and Design	https://doi.org/10.1145/2627369.2627613		27 – 32	"@CONFERENCE{Venkataramani201527,
    author = ""Venkataramani, Swagath and Ranjan, Ashish and Roy, Kaushik and Raghunathan, Anand"",
    title = ""AxNN: Energy-efficient neuromorphic systems using approximate computing"",
    year = ""2015"",
    journal = ""Proceedings of the International Symposium on Low Power Electronics and Design"",
    volume = ""2015-October"",
    pages = ""27 – 32"",
    doi = ""10.1145/2627369.2627613"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953384046\&doi=10.1145\%2f2627369.2627613\&partnerID=40\&md5=e552bd33a9fe0ddb6cafc554fd61aaf9"",
    affiliations = ""School of Electrical and Computer Engineering, Purdue University, 475 Northwestern Ave, West Lafayette, 47907, IN, United States"",
    abstract = ""Neuromorphic algorithms, which are comprised of highly complex, large-scale networks of artificial neurons, are increasingly used for a variety of recognition, classification, search and vision tasks. However, their computational and energy requirements can be quite high, and hence their energy-efficient implementation is of great interest. We propose a new approach to design energy-efficient hardware implementations of large-scale neural networks (NNs) using approximate computing. Our work is motivated by the observations that (i) NNs are used in applications where less-than-perfect results are acceptable, and often inevitable, and (ii) they are highly resilient to inexactness in many (but not all) of their constituent computations. We make two key contributions. First, we propose a method to transform any given NN into an Approximate Neural Network (AxNN). This is performed by (i) adapting the backpropagation technique, which is commonly used to train these networks, to quantify the impact of approximating each neuron to the overall network quality (e.g., classification accuracy), and (ii) selectively approximating those neurons that impact network quality the least. Further, we make the key observation that training is a naturally error-healing process that can be used to mitigate the impact of approximations to neurons. Therefore, we incrementally retrain the network with the approximations in-place, reclaiming a significant portion of the quality ceded by approximations. As a second contribution, we propose a programmable and quality-configurable neuromorphic processing engine (qcNPE), which utilizes arrays of specialized processing elements that execute neuron computations with dynamically configurable accuracies and can be used to execute AxNNs from diverse applications. We evaluated the proposed approach by constructing AXNNs for 6 recognition applications (ranging in complexity from 12-47,818 neurons and 160-3,155,968 connections) and executing them on two different platforms-qcNPE implementation containing 272 processing elements in 45nm technology and a commodity Intel Xeon server. Our results demonstrate 1.14X-1.92X energy benefits for virtually no loss (< 0.5\%) in output quality, and even higher improvements (upto 2.3X) when some loss (upto 7.5\%) in output quality is acceptable. © 2014 ACM."",
    author_keywords = ""Approximate Computing; Energy Efficiency; Large-scale Neural Networks; Neuromorphic Systems"",
    keywords = ""Algorithms; Complex networks; Hardware; Low power electronics; Neural networks; Neurons; Power electronics; Approximate Computing; Backpropagation techniques; Classification accuracy; Diverse applications; Hardware implementations; Large-scale network; Neural networks (NNS); Neuromorphic systems; Energy efficiency"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""15334678"",
    isbn = ""978-145032975-0"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Symp. Low Power Electron. Des."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 18; Conference name: ACM/IEEE International Symposium on Low Power Electronics and Design, ISLPED 2014; Conference date: 11 August 2014 through 13 August 2014; Conference code: 117254""
}
"	Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus	2014	 AxNN: energy-efficient neuromorphic systems using approximate computing	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953384046&doi=10.1145%2f2627369.2627613&partnerID=40&md5=e552bd33a9fe0ddb6cafc554fd61aaf9	Institute of Electrical and Electronics Engineers Inc.	nan; References
114	TestNN	Explaining and Harnessing Adversarial Examples	Abstract:Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.		Ian J. Goodfellow; Jonathon Shlens; Christian Szegedy		https://doi.org/10.48550/arXiv.1412.6572				Included	Included	snowballing			1	arXiv	2014	Explaining and Harnessing Adversarial Examples			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
115	TestNN	Towards Deep Neural Network Architectures Robust to Adversarial Examples	Abstract:Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. How- ever, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty.		Shixiang Gu; Luca Rigazio		https://doi.org/10.48550/arXiv.1412.5068				Included	Included	snowballing			1	arXiv	2014	Towards deep neural network architectures robust to adversarial examples			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
116	TestNN	Visualizing and Understanding Convolutional Networks	Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevskyet al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevskyet alon the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.	Input Image; Training Image; Convolutional Neural Network; Stochastic Gradient Descent; Pixel Space	Matthew D. Zeiler19&; Rob Fergus19	European Conference on Computer Vision	https://doi.org/10.1007/978-3-319-10590-1_53		pp 818–833		Included	Included	snowballing			1	SpringerLink	2014	 Visualizing and understanding convolutional networks		Springer, Cham	nan; References; Year; Bibtex; Link
117	TestNN	Visualizing and Understanding Convolutional Networks	Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevskyet al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevskyet alon the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.	Input Image; Training Image; Convolutional Neural Network; Stochastic Gradient Descent; Pixel Space	Matthew D. Zeiler19&; Rob Fergus19	European Conference on Computer Vision	https://doi.org/10.1007/978-3-319-10590-1_53		pp 818–833		Included	Included	snowballing			1	SpringerLink	2014	 Visualizing and understanding convolutional networks		Springer, Cham	nan; References; Year; Bibtex; Link
118	TestNN	ApproxANN: An approximate computing framework for artificial neural network	Artificial Neural networks (ANNs) are one of the most well-established machine learning techniques and have a wide range of applications, such as Recognition, Mining and Synthesis (RMS). As many of these applications are inherently error-tolerant, in this work, we propose a novel approximate computing framework for ANN, namely ApproxANN. When compared to existing solutions, ApproxANN considers approximation for both computation and memory accesses, thereby achieving more energy savings. To be specific, ApproxANN characterizes the impact of neurons on the output quality in an effective and efficient manner, and judiciously determine how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint. Experimental results on various ANN applications with different datasets demonstrate the efficacy of the proposed solution. © 2015 EDAA.	Energy efficiency; Learning systems; ANN application; Computing frameworks; Critical neurons; Error tolerant; Machine learning techniques; Memory access; Output quality; Quality constraints; Neural networks	Zhang, Qian; Wang, Ting; Tian, Ye; Yuan, Feng; Xu, Qiang	Proceedings -Design, Automation and Test in Europe, DATE	https://doi.org/10.7873/date.2015.0618		701 – 706	"@CONFERENCE{Zhang2015701,
    author = ""Zhang, Qian and Wang, Ting and Tian, Ye and Yuan, Feng and Xu, Qiang"",
    title = ""ApproxANN: An approximate computing framework for artificial neural network"",
    year = ""2015"",
    journal = ""Proceedings -Design, Automation and Test in Europe, DATE"",
    volume = ""2015-April"",
    pages = ""701 – 706"",
    doi = ""10.7873/date.2015.0618"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945911897\&doi=10.7873\%2fdate.2015.0618\&partnerID=40\&md5=66e4f192e10d57febce67fd81ab26d83"",
    affiliations = ""CUhk REliable Computing Laboratory (CURE), Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, N.T., Hong Kong"",
    abstract = ""Artificial Neural networks (ANNs) are one of the most well-established machine learning techniques and have a wide range of applications, such as Recognition, Mining and Synthesis (RMS). As many of these applications are inherently error-tolerant, in this work, we propose a novel approximate computing framework for ANN, namely ApproxANN. When compared to existing solutions, ApproxANN considers approximation for both computation and memory accesses, thereby achieving more energy savings. To be specific, ApproxANN characterizes the impact of neurons on the output quality in an effective and efficient manner, and judiciously determine how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint. Experimental results on various ANN applications with different datasets demonstrate the efficacy of the proposed solution. © 2015 EDAA."",
    keywords = ""Energy efficiency; Learning systems; ANN application; Computing frameworks; Critical neurons; Error tolerant; Machine learning techniques; Memory access; Output quality; Quality constraints; Neural networks"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""15301591"",
    isbn = ""978-398153704-8"",
    language = ""English"",
    abbrev_source_title = ""Proc. Des. Autom. Test Eur. DATE"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 191; Conference name: 2015 Design, Automation and Test in Europe Conference and Exhibition, DATE 2015; Conference date: 9 March 2015 through 13 March 2015; Conference code: 115713""
}
"	Included	Included	snowballing			1	Scopus	2015	 ApproxANN: an approximate computing framework for artificial neural network	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945911897&doi=10.7873%2fdate.2015.0618&partnerID=40&md5=66e4f192e10d57febce67fd81ab26d83	Institute of Electrical and Electronics Engineers Inc.	nan; References
119	TestNN	Deep neural networks are easily fooled: High confidence predictions for unrecognizable images	Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.		Anh Nguyen; Jason Yosinski; Jeff Clune	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2015.7298640				Included	Included	snowballing			1	IEEE	2015	 Deep neural networks are easily fooled: High confidence predictions for unrecognizable images		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
120	TestNN	 Towards Verification of Artificial Neural Networks			Scheibler, K., L. Winterer, R. Wimmer and B. Becker						Included	Included	snowballing			1		2015				
121	TestNN	Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization	Abstract:We propose a general framework for increasing local stability of Artificial Neural Nets (ANNs) using Robust Optimization (RO). We achieve this through an alternating minimization-maximization procedure, in which the loss of the network is minimized over perturbed examples that are generated at each parameter update. We show that adversarial training of ANNs is in fact robustification of the network optimization, and that our proposed framework generalizes previous approaches for increasing local stability of ANNs. Experimental results reveal that our approach increases the robustness of the network to existing adversarial examples, while making it harder to generate new ones. Furthermore, our algorithm improves the accuracy of the network also on the original test data.		Uri Shaham; Yutaro Yamada; Sahand Negahban		https://doi.org/10.48550/arXiv.1511.05432				Included	Included	snowballing			1	arXiv	2015	Understanding adversarial training: Increasing local stability of neural nets through robust optimization			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
122	TestNN	Understanding deep image representations by inverting them	Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.		Aravindh Mahendran; Andrea Vedaldi	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2015.7299155				Included	Included	snowballing			1	IEEE	2015	 Understanding deep image representations by inverting them		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
123	TestNN	Distilling Knowledge from Deep Networks with Applications to Healthcare Domain	Abstract:Exponential growth in Electronic Healthcare Records (EHR) has resulted in new opportunities and urgent needs for discovery of meaningful data-driven representations and patterns of diseases in Computational Phenotyping research. Deep Learning models have shown superior performance for robust prediction in computational phenotyping tasks, but suffer from the issue of model interpretability which is crucial for clinicians involved in decision-making. In this paper, we introduce a novel knowledge-distillation approach called Interpretable Mimic Learning, to learn interpretable phenotype features for making robust prediction while mimicking the performance of deep learning models. Our framework uses Gradient Boosting Trees to learn interpretable features from deep learning models such as Stacked Denoising Autoencoder and Long Short-Term Memory. Exhaustive experiments on a real-world clinical time-series dataset show that our method obtains similar or better performance than the deep learning models, and it provides interpretable phenotypes for clinical decision making.		Zhengping Che; Sanjay Purushotham; Robinder Khemani; Yan Liu		https://doi.org/10.48550/arXiv.1512.03542				Included	Included	snowballing			1	arXiv	2015	Distilling knowledge from deep networks with applications to healthcare domain			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
124	TestNN	Distilling the Knowledge in a Neural Network	Abstract:A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.		Geoffrey Hinton; Oriol Vinyals; Jeff Dean		https://doi.org/10.48550/arXiv.1503.02531				Included	Included	snowballing			1	arXiv	2015	Distilling the knowledge in a neural network			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
125	TestNN	On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation	Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest.We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package. © 2015 Bach et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.	Algorithms; Artificial Intelligence; Humans; Image Processing, Computer-Assisted; Pattern Recognition, Automated; Article; artificial neural network; Bag of Words model; classification; classifier; controlled study; image analysis; kernel method; layer wise relevance propagation; machine learning; nonlinear system; prediction; algorithm; artificial intelligence; automated pattern recognition; human; image processing; procedures	Bach, Sebastian; Binder, Alexander; Montavon, Grégoire; Klauschen, Frederick; Müller, Klaus-Robert; Samek, Wojciech	PLoS ONE	https://doi.org/10.1371/journal.pone.0130140			"@ARTICLE{Bach2015,
    author = ""Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech"",
    title = ""On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation"",
    year = ""2015"",
    journal = ""PLoS ONE"",
    volume = ""10"",
    number = ""7"",
    doi = ""10.1371/journal.pone.0130140"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940560152\&doi=10.1371\%2fjournal.pone.0130140\&partnerID=40\&md5=7de7149c6d217b8865b973d5df616d90"",
    affiliations = ""Machine Learning Group, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Machine Learning Group, Technische Universität Berlin, Berlin, Germany; Charité University Hospital, Berlin, Germany; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; ISTD Pillar, Singapore University of Technology and Design (SUTD), Singapore, Singapore"",
    abstract = ""Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest.We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package. © 2015 Bach et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."",
    keywords = ""Algorithms; Artificial Intelligence; Humans; Image Processing, Computer-Assisted; Pattern Recognition, Automated; Article; artificial neural network; Bag of Words model; classification; classifier; controlled study; image analysis; kernel method; layer wise relevance propagation; machine learning; nonlinear system; prediction; algorithm; artificial intelligence; automated pattern recognition; human; image processing; procedures"",
    publisher = ""Public Library of Science"",
    issn = ""19326203"",
    coden = ""POLNC"",
    pmid = ""26161953"",
    language = ""English"",
    abbrev_source_title = ""PLoS ONE"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2794; All Open Access, Gold Open Access, Green Open Access""
}
"	Included	Included	snowballing			1	Scopus	2015	On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation	https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940560152&doi=10.1371%2fjournal.pone.0130140&partnerID=40&md5=7de7149c6d217b8865b973d5df616d90	Public Library of Science	nan; References; Pages
126	TestNN	Understanding deep image representations by inverting them	Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.		Aravindh Mahendran; Andrea Vedaldi	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2015.7299155				Included	Included	snowballing			1	IEEE	2015	 Understanding deep image representations by inverting them		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
127	TestNN	Attentive Explanations: Justifying Decisions and Pointing to the Evidence	Abstract:Deep models are the defacto standard in visual decision models due to their impressive performance on a wide array of visual tasks. However, they are frequently seen as opaque and are unable to explain their decisions. In contrast, humans can justify their decisions with natural language and point to the evidence in the visual world which led to their decisions. We postulate that deep models can do this as well and propose our Pointing and Justification (PJ-X) model which can justify its decision with a sentence and point to the evidence by introspecting its decision and explanation process using an attention mechanism. Unfortunately there is no dataset available with reference explanations for visual decision making. We thus collect two datasets in two domains where it is interesting and challenging to explain decisions. First, we extend the visual question answering task to not only provide an answer but also a natural language explanation for the answer. Second, we focus on explaining human activities which is traditionally more challenging than object classification. We extensively evaluate our PJ-X model, both on the justification and pointing tasks, by comparing it to prior models and ablations using both automatic and human evaluations.		Dong Huk Park; Lisa Anne Hendricks; Zeynep Akata; Bernt Schiele; Trevor Darrell; Marcus Rohrbach		https://doi.org/10.48550/arXiv.1612.04757				Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	arXiv	2016	Attentive explanations: Justifying decisions and pointing to the evidence			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
128	TestNN	Concrete Problems in AI Safety	"Abstract:Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (""avoiding side effects"" and ""avoiding reward hacking""), an objective function that is too expensive to evaluate frequently (""scalable supervision""), or undesirable behavior during the learning process (""safe exploration"" and ""distributional shift""). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI."		Dario Amodei; Chris Olah; Jacob Steinhardt; Paul Christiano; John Schulman; Dan Mané		https://doi.org/10.48550/arXiv.1606.06565				Excluded	Excluded	snowballing		Exclusion: review paper	1	arXiv	2016	Concrete problems in AI safety			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
129	TestNN	Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks	Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content filters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 800% on one of the DNNs we tested.		Nicolas Papernot; Patrick McDaniel; Xi Wu; Somesh Jha; Ananthram Swami	2016 IEEE Symposium on Security and Privacy (SP)	https://doi.org/10.1109/SP.2016.41				Included	Included	snowballing			1	IEEE	2016	Distillation as a defense to adversarial perturbations against deep neural networks		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
130	TestNN	Improving the Robustness of Deep Neural Networks via Stability Training	In this paper we address the issue of output instability of deep neural networks: small perturbations in the visual input can significantly distort the feature embeddings and output of a neural network. Such instability affects many deep architectures with state-of-the-art performance on a wide range of computer vision tasks. We present a general stability training method to stabilize deep networks against small input distortions that result from various types of common image processing, such as compression, rescaling, and cropping. We validate our method by stabilizing the state of-the-art Inception architecture [11] against these types of distortions. In addition, we demonstrate that our stabilized model gives robust state-of-the-art performance on largescale near-duplicate detection, similar-image ranking, and classification on noisy datasets.		Stephan Zheng; Yang Song; Thomas Leung; Ian Goodfellow	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2016.485				Included	Included	snowballing			1	IEEE	2016	 Improving the robustness of deep neural networks via stability training		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
131	TestNN	Measuring neural net robustness with constraints	"Despite having high accuracy, neural nets have been shown to be susceptible to adversarial examples, where a small perturbation to an input can cause it to become mislabeled. We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program. We show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the MNIST and CIFAR-10 datasets. Our algorithm generates more informative estimates of robustness metrics compared to estimates based on existing algorithms. Furthermore, we show how existing approaches to improving robustness ""overfit"" to adversarial examples generated using a specific algorithm. Finally, we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose, but also according to previously proposed metrics."		OsbertBastani; YaniIoannou; LeonidasLampropoulos; DimitriosVytiniotis; Aditya V.Nori; AntonioCriminisi	NIPS'16: Proceedings of the 30th International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3157382.3157391		621-2629		Included	Included	snowballing			1	ACM	2016	 Measuring neural net robustness with constraints		Curran Associates Inc.	nan; Keywords; References; Year; Bibtex; Link
132	TestNN	Policy compression for aircraft collision avoidance systems	One approach to designing the decision making logic for an aircraft collision avoidance system is to frame the problem as Markov decision process and optimize the system using dynamic programming. The resulting strategy can be represented as a numeric table. This methodology has been used in the development of the ACAS X family of collision avoidance systems for manned and unmanned aircraft. However, due to the high dimensionality of the state space, discretizing the state variables can lead to very large tables. To improve storage efficiency, we propose two approaches for compressing the lookup table. The first approach exploits redundancy in the table. The table is decomposed into a set of lower-dimensional tables, some of which can be represented by single tables in areas where the lower-dimensional tables are identical or nearly identical with respect to a similarity metric. The second approach uses a deep neural network to learn a complex non-linear function approximation of the table. With the use of an asymmetric loss function and a gradient descent algorithm, the parameters for this network can be trained to provide very accurate estimates of values while preserving the relative preferences of the possible advisories for each state. As a result, the table can be approximately represented by only the parameters of the network, which reduces the required storage space by a factor of 1000. Simulation studies show that system performance is very similar using either compressed table representation in place of the original table. Even though the neural network was trained directly on the original table, the network surpasses the original table on the performance metrics and encounter sets evaluated here.		Kyle D. Julian; Jessica Lopez; Jeffrey S. Brush; Michael P. Owen; Mykel J. Kochenderfer	2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)	https://doi.org/10.1109/DASC.2016.7778091				Included	Included	snowballing			1	IEEE	2016	 Policy compression for aircraft collision avoidance systems		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
133	TestNN	Toward verified artificial intelligence	Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.		Sanjit A.Seshia; DorsaSadigh; S. ShankarSastry	Communications of the ACM	https://doi.org/10.1145/3503914		6-55		Excluded	Excluded	snowballing		Exclusion: review paper	1	ACM	2016	Towards verified artificial intelligence		Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
134	TestNN	Understanding Error Propagation in GPGPU Applications	GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results. © 2016 IEEE.	Program processors; Software testing; CUDA; Error propagation; Error resilience; Fault injection; GPGPU; Errors	Li, Guanpeng; Pattabiraman, Karthik; Cher, Chen-Yang; Bose, Pradip	International Conference for High Performance Computing, Networking, Storage and Analysis, SC	https://doi.org/10.1109/SC.2016.20		240 – 251	"@CONFERENCE{Li2016240,
    author = ""Li, Guanpeng and Pattabiraman, Karthik and Cher, Chen-Yang and Bose, Pradip"",
    title = ""Understanding Error Propagation in GPGPU Applications"",
    year = ""2016"",
    journal = ""International Conference for High Performance Computing, Networking, Storage and Analysis, SC"",
    volume = ""0"",
    pages = ""240 – 251"",
    doi = ""10.1109/SC.2016.20"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017275616\&doi=10.1109\%2fSC.2016.20\&partnerID=40\&md5=6d5c28cfc6276448a447f6d585e58890"",
    affiliations = ""University of British Columbia, Vancouver, BC, Canada; IBM T.J. Watson Research Center, New York, United States"",
    abstract = ""GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results. © 2016 IEEE."",
    author_keywords = ""CUDA; Error Propagation; Error Resilience; Fault Injection; GPGPU"",
    keywords = ""Program processors; Software testing; CUDA; Error propagation; Error resilience; Fault injection; GPGPU; Errors"",
    publisher = ""IEEE Computer Society"",
    issn = ""21674329"",
    isbn = ""978-146738815-3"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. High Perfor. Comput., Networking, Storage Analysis, SC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 84; Conference name: 2016 International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2016; Conference date: 13 November 2016 through 18 November 2016; Conference code: 126860""
}
"	Included	Included	snowballing			1	Scopus	2016	 Understanding error propagation in GPGPU applications	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017275616&doi=10.1109%2fSC.2016.20&partnerID=40&md5=6d5c28cfc6276448a447f6d585e58890	IEEE Computer Society	nan; References
135	TestNN	"Documenting Evidence of a Reuse of '""Why Should i Trust You?"": Explaining the Predictions of Any Classifier'"	"We report here the following example of reuse. LIME is a local instance-based explanation generation framework that was originally proposed by Ribeiro et al. in their paper ""'Why Should I Trust You?': Explaining the Predictions of Any Classifier"". The framework was reused by Peng et al. in their paper ""Defect Reduction Planning (using TimeLIME)"". The paper used the original implementation of LIME as one of the core components in the proposed framework. © 2021 ACM."	Computer software reusability; Actionable analyse; Core components; Defect reduction; Reuse; Software analytic; Lime	Peng, Kewen; Menzies, Tim	ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering	https://doi.org/10.1145/3468264.3477217		1600	"@CONFERENCE{Peng20211600,
    author = ""Peng, Kewen and Menzies, Tim"",
    editor = ""D., Spinellis"",
    title = {Documenting Evidence of a Reuse of '""Why Should i Trust You?"": Explaining the Predictions of Any Classifier'},
    year = ""2021"",
    journal = ""ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering"",
    pages = ""1600"",
    doi = ""10.1145/3468264.3477217"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116297955\&doi=10.1145\%2f3468264.3477217\&partnerID=40\&md5=aaecd31b049fb6a13ac14670b15f5a0f"",
    affiliations = ""North Carolina State University, United States"",
    abstract = {We report here the following example of reuse. LIME is a local instance-based explanation generation framework that was originally proposed by Ribeiro et al. in their paper ""'Why Should I Trust You?': Explaining the Predictions of Any Classifier"". The framework was reused by Peng et al. in their paper ""Defect Reduction Planning (using TimeLIME)"". The paper used the original implementation of LIME as one of the core components in the proposed framework. © 2021 ACM.},
    author_keywords = ""Actionable analysis; Software analytics"",
    keywords = ""Computer software reusability; Actionable analyse; Core components; Defect reduction; Reuse; Software analytic; Lime"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145038562-6"",
    language = ""English"",
    abbrev_source_title = ""ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4; Conference name: 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2021; Conference date: 23 August 2021 through 28 August 2021; Conference code: 171831""
}
"	Included	Included	snowballing			1	Scopus	2016	 Why should i trust you?: Explaining the predictions of any classifier	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116297955&doi=10.1145%2f3468264.3477217&partnerID=40&md5=aaecd31b049fb6a13ac14670b15f5a0f	Association for Computing Machinery, Inc	nan; References
136	TestNN	Controlling explanatory heatmap resolution and semantics via decomposition depth	We present an application of the Layer-wise Relevance Propagation (LRP) algorithm to state of the art deep convolutional neural networks and Fisher Vector classifiers to compare the image perception and prediction strategies of both classifiers with the use of visualized heatmaps. Layer-wise Relevance Propagation (LRP) is a method to compute scores for individual components of an input image, denoting their contribution to the prediction of the classifier for one particular test point. We demonstrate the impact of different choices of decomposition cut-off points during the LRP-process, controlling the resolution and semantics of the heatmap on test images from the PASCAL VOC 2007 test data set. © 2016 IEEE.	Neural networks; Semantics; Statistical tests; Convolutional neural network; Decomposition depths; Fisher vectors; Heatmapping; Image perception; Individual components; Input image; State of the art; Image processing	Bach, Sebastian; Binder, Alexander; Muller, Klaus-Robert; Samek, Wojciech	Proceedings - International Conference on Image Processing, ICIP	https://doi.org/10.1109/ICIP.2016.7532763		2271 – 2275	"@CONFERENCE{Bach20162271,
    author = ""Bach, Sebastian and Binder, Alexander and Muller, Klaus-Robert and Samek, Wojciech"",
    title = ""Controlling explanatory heatmap resolution and semantics via decomposition depth"",
    year = ""2016"",
    journal = ""Proceedings - International Conference on Image Processing, ICIP"",
    volume = ""2016-August"",
    pages = ""2271 – 2275"",
    doi = ""10.1109/ICIP.2016.7532763"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006759512\&doi=10.1109\%2fICIP.2016.7532763\&partnerID=40\&md5=bfff85e7003cbef621dd49dd11c8e4e7"",
    affiliations = ""Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Singapore University of Technology (SUTD), 8 Soapah Road, Singapore, 487372, Singapore; Berlin Institute of Technology (TU Berlin), Straße des 17. Juni 135, Berlin, 10623, Germany; Korea University, 145 Anam-ro, Seongbuk-gu, Seoul, 02841, South Korea"",
    abstract = ""We present an application of the Layer-wise Relevance Propagation (LRP) algorithm to state of the art deep convolutional neural networks and Fisher Vector classifiers to compare the image perception and prediction strategies of both classifiers with the use of visualized heatmaps. Layer-wise Relevance Propagation (LRP) is a method to compute scores for individual components of an input image, denoting their contribution to the prediction of the classifier for one particular test point. We demonstrate the impact of different choices of decomposition cut-off points during the LRP-process, controlling the resolution and semantics of the heatmap on test images from the PASCAL VOC 2007 test data set. © 2016 IEEE."",
    author_keywords = ""Explaining Classifiers; Heatmapping"",
    keywords = ""Neural networks; Semantics; Statistical tests; Convolutional neural network; Decomposition depths; Fisher vectors; Heatmapping; Image perception; Individual components; Input image; State of the art; Image processing"",
    publisher = ""IEEE Computer Society"",
    issn = ""15224880"",
    isbn = ""978-146739961-6"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Conf. Image Process. ICIP"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 17; Conference name: 23rd IEEE International Conference on Image Processing, ICIP 2016; Conference date: 25 September 2016 through 28 September 2016; Conference code: 125190; All Open Access, Green Open Access""
}
"	Excluded	Excluded	snowballing		Inclusion: 	1	Scopus	2016	Controlling explanatory heatmap resolution and semantics via decomposition depth	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006759512&doi=10.1109%2fICIP.2016.7532763&partnerID=40&md5=bfff85e7003cbef621dd49dd11c8e4e7	IEEE Computer Society	nan; References
137	TestNN	Learning Deep Features for Discriminative Localization	In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.		Bolei Zhou; Aditya Khosla; Agata Lapedriza; Aude Oliva; Antonio Torralba	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2016.319				Included	Included	snowballing			1	IEEE	2016	 Learning deep features for discriminative localization		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
138	TestNN	Not Just a Black Box: Learning Important Features Through Propagating Activation Differences	"Abstract:Note: This paper describes an older version of DeepLIFT. Seehttps://arxiv.org/abs/1704.02685for the newer version. Original abstract follows: The purported ""black box"" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods."		Avanti Shrikumar; Peyton Greenside; Anna Shcherbina; Anshul Kundaje		https://doi.org/10.48550/arXiv.1605.01713				Included	Included	snowballing			1	arXiv	2016	 Not just a black box: Interpretable deep learning by propagating activation differences			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
139	TestNN	Synthesizing the preferred inputs for neurons in neural networks via deep generator networks	Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images). © 2016 NIPS Foundation - All Rights Reserved.	Chemical activation; Network architecture; Neural networks; Neurons; Pattern recognition; Basic science; Generative methods; High quality; Human brain; Network functions; Qualitative state; State of the art; Synthetic images; Deep neural networks	Nguyen, Anh; Dosovitskiy, Alexey; Yosinski, Jason; Brox, Thomas; Clune, Jeff	Advances in Neural Information Processing Systems			3395 – 3403	"@CONFERENCE{Nguyen20163395,
    author = ""Nguyen, Anh and Dosovitskiy, Alexey and Yosinski, Jason and Brox, Thomas and Clune, Jeff"",
    editor = ""R., Garnett and D.D., Lee and von Luxburg U. and I., Guyon and M., Sugiyama"",
    title = ""Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"",
    year = ""2016"",
    journal = ""Advances in Neural Information Processing Systems"",
    pages = ""3395 – 3403"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019234593\&partnerID=40\&md5=9e504aace5eb4b61086588bf42290a9c"",
    abstract = ""Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images). © 2016 NIPS Foundation - All Rights Reserved."",
    keywords = ""Chemical activation; Network architecture; Neural networks; Neurons; Pattern recognition; Basic science; Generative methods; High quality; Human brain; Network functions; Qualitative state; State of the art; Synthetic images; Deep neural networks"",
    publisher = ""Neural information processing systems foundation"",
    issn = ""10495258"",
    language = ""English"",
    abbrev_source_title = ""Adv. neural inf. proces. syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 445; Conference name: 30th Annual Conference on Neural Information Processing Systems, NIPS 2016; Conference date: 5 December 2016 through 10 December 2016; Conference code: 127462""
}
"	Included	Included	snowballing			1	Scopus	2016	 Synthesizing the preferred inputs for neurons in neural networks via deep generator networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019234593&partnerID=40&md5=9e504aace5eb4b61086588bf42290a9c	Neural information processing systems foundation	nan; References; DOI
140	TestNN	TreeView: Peeking into Deep Neural Networks Via Feature-Space Partitioning	Abstract:With the advent of highly predictive but opaque deep learning models, it has become more important than ever to understand and explain the predictions of such models. Existing approaches define interpretability as the inverse of complexity and achieve interpretability at the cost of accuracy. This introduces a risk of producing interpretable but misleading explanations. As humans, we are prone to engage in this kind of behavior \cite{mythos}. In this paper, we take a step in the direction of tackling the problem of interpretability without compromising the model accuracy. We propose to build a Treeview representation of the complex model via hierarchical partitioning of the feature space, which reveals the iterative rejection of unlikely class labels until the correct association is predicted.		Jayaraman J. Thiagarajan; Bhavya Kailkhura; Prasanna Sattigeri; Karthikeyan Natesan Ramamurthy		https://doi.org/10.48550/arXiv.1611.07429				Included	Included	snowballing			1	arXiv	2016	TreeView: Peeking into deep neural networks via feature-space partitioning			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
141	TestNN	Verifying properties of binarized deep neural networks	Understanding properties of deep neural networks is an important challenge in deep learning. In this paper, we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks, Binarized Neural Networks, using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the firstexactBoolean representation of a deep neural network. Using this encoding, we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property, our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge, this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network.		NinaNarodytska; ShivaKasiviswanathan; LeonidRyzhyk; MoolySagiv; TobyWalsh	AAAI'18/IAAI'18/EAAI'18: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence	https://doi.org/10.5555/3504035.3504845		615-6624		Included	Included	snowballing			1	ACM	2017	Verifying properties of binarized deep neural networks		AAAI Press	nan; Keywords; References; Year; Bibtex; Link
142	TestNN	Towards proving the adversarial robustness of deep neural networks	Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed.	Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.3		19 – 26	"@CONFERENCE{Katz201719,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""Towards proving the adversarial robustness of deep neural networks"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""19 – 26"",
    doi = ""10.4204/EPTCS.257.3"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870\&doi=10.4204\%2fEPTCS.257.3\&partnerID=40\&md5=7c1218ee68d68aa322e5e3ba887dba5e"",
    affiliations = ""Stanford University, United States"",
    abstract = ""Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed."",
    keywords = ""Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, United States; email: guyk@stanford.edu"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 47; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"	Included	Included	snowballing			1	Scopus	2017	Towards proving the adversarial robustness of deep neural networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870&doi=10.4204%2fEPTCS.257.3&partnerID=40&md5=7c1218ee68d68aa322e5e3ba887dba5e	Open Publishing Association	nan; References
143	TestNN	Output Reachable Set Estimation and Verification for Multilayer Neural Networks	In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches.		Weiming Xiang; Hoang-Dung Tran; Taylor T. Johnson	IEEE Transactions on Neural Networks and Learning Systems	https://doi.org/10.1109/TNNLS.2018.2808470				Excluded	Excluded	snowballing		Exclusion: duplicated with selected paper [95]	1	IEEE	2017	Output reachable set estimation and verification for multi-layer neural networks		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
144	TestNN	Output Range Analysis for Deep Neural Networks	"Abstract:Deep neural networks (NN) are extensively used for machine learning tasks such as image classification, perception and control of autonomous systems. Increasingly, these deep NNs are also been deployed in high-assurance applications. Thus, there is a pressing need for developing techniques to verify neural networks to check whether certain user-expected properties are satisfied. In this paper, we study a specific verification problem of computing a guaranteed range for the output of a deep neural network given a set of inputs represented as a convex polyhedron. Range estimation is a key primitive for verifying deep NNs. We present an efficient range estimation algorithm that uses a combination of local search and linear programming problems to efficiently find the maximum and minimum values taken by the outputs of the NN over the given input set. In contrast to recently proposed ""monolithic"" optimization approaches, we use local gradient descent to repeatedly find and eliminate local minima of the function. The final global optimum is certified using a mixed integer programming instance. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks. We demonstrate the effectiveness of the proposed approach for verification of NNs used in automated control as well as those used in classification."		Souradeep Dutta; Susmit Jha; Sriram Sanakaranarayanan; Ashish Tiwari		https://doi.org/10.48550/arXiv.1709.09130				Included	Included	snowballing			1	arXiv	2017	Output range analysis for deep neural networks			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
145	TestNN	Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks	We present an approach for the verification of feed-forward neural networks in which all nodes have a piece-wise linear activation function. Such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory (SMT) and integer linear programming (ILP) solvers.The starting point of our approach is the addition of a global linear approximation of the overall network behavior to the verification problem that helps with SMT-like reasoning over the network behavior. We present a specialized verification algorithm that employs this approximation in a search process in which it infers additional node phases for the non-linear nodes in the network from partial node phase assignments, similar to unit propagation in classical SAT solving. We also show how to infer additional conflict clauses and safe node fixtures from the results of the analysis steps performed during the search. The resulting approach is evaluated on collision avoidance and handwritten digit recognition case studies.		Rüdiger Ehlers15	International Symposium on Automated Technology for Verification and Analysis	https://doi.org/10.1007/978-3-319-68167-2_19		pp 269–286		Included	Included	snowballing			1	SpringerLink	2017	 Formal verification of piece-wise linear feed-forward neural networks		Springer, Cham	nan; Keywords; References; Year; Bibtex; Link
146	TestNN	DeepSafe: A Data-Driven Approach for Assessing Robustness of Neural Networks	Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust, i.e. all the inputs in the region are guaranteed to be classified correctly. We also introduce the concept of targeted robustness, which ensures that the neural network is guaranteed not to misclassify inputs within a region to a specific target (adversarial) label. We evaluate DeepSafe on a neural network implementation of a controller for the next-generation Airborne Collision Avoidance System for unmanned aircraft (ACAS Xu) and for the well known MNIST network. For these networks, DeepSafe identified many regions which were safe, and also found adversarial perturbations of interest. © 2018, Springer Nature Switzerland AG.	Aircraft accidents; Speech recognition; Airborne collision avoidance systems; Classification tasks; Complex applications; Constraint solvers; Data-driven approach; Pattern analysis; Self-driving vehicles; Unmanned aircrafts; Deep neural networks	Gopinath, Divya; Katz, Guy; Păsăreanu, Corina S.; Barrett, Clark	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-030-01090-4_1		3 – 19	"@ARTICLE{Gopinath20183,
    author = ""Gopinath, Divya and Katz, Guy and Păsăreanu, Corina S. and Barrett, Clark"",
    editor = ""C., Wang and S.K., Lahiri"",
    title = ""DeepSafe: A Data-Driven Approach for Assessing Robustness of Neural Networks"",
    year = ""2018"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""11138 LNCS"",
    pages = ""3 – 19"",
    doi = ""10.1007/978-3-030-01090-4\_1"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054789898\&doi=10.1007\%2f978-3-030-01090-4\_1\&partnerID=40\&md5=e6c855de182e4b98a8f43a7ab79c17f4"",
    affiliations = ""Carnegie Mellon University, Silicon Valley, Mountain View, United States; NASA Ames Research Center, Mountain View, United States; Stanford University, Stanford, United States"",
    abstract = ""Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust, i.e. all the inputs in the region are guaranteed to be classified correctly. We also introduce the concept of targeted robustness, which ensures that the neural network is guaranteed not to misclassify inputs within a region to a specific target (adversarial) label. We evaluate DeepSafe on a neural network implementation of a controller for the next-generation Airborne Collision Avoidance System for unmanned aircraft (ACAS Xu) and for the well known MNIST network. For these networks, DeepSafe identified many regions which were safe, and also found adversarial perturbations of interest. © 2018, Springer Nature Switzerland AG."",
    keywords = ""Aircraft accidents; Speech recognition; Airborne collision avoidance systems; Classification tasks; Complex applications; Constraint solvers; Data-driven approach; Pattern analysis; Self-driving vehicles; Unmanned aircrafts; Deep neural networks"",
    correspondence_address = ""C.S. Păsăreanu; NASA Ames Research Center, Mountain View, United States; email: corina.s.pasareanu@nasa.gov"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-303001089-8"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 61; Conference name: 16th International Symposium on Automated Technology for Verification and Analysis, ATVA 2018; Conference date: 7 October 2018 through 10 October 2018; Conference code: 218949""
}
"	Included	Included	snowballing			1	Scopus	2017	Deepsafe: A data-driven approach for checking adversarial robustness in neural networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054789898&doi=10.1007%2f978-3-030-01090-4_1&partnerID=40&md5=e6c855de182e4b98a8f43a7ab79c17f4	Springer Verlag	nan; References
147	TestNN	The challenge of verification and testing of machine learning			Goodfellow, I. and N. Papernot 						Excluded	Excluded	snowballing		Exclusion: review paper	1		2017				
148	TestNN	Detecting Adversarial Samples from Artifacts	Abstract:Deep neural networks (DNNs) are powerful nonlinear architectures that are known to be robust to random perturbations of the input. However, these models are vulnerable to adversarial perturbations--small input changes crafted explicitly to fool the model. In this paper, we ask whether a DNN can distinguish adversarial samples from their normal and noisy counterparts. We investigate model confidence on adversarial samples by looking at Bayesian uncertainty estimates, available in dropout neural networks, and by performing density estimation in the subspace of deep features learned by the model. The result is a method for implicit adversarial detection that is oblivious to the attack algorithm. We evaluate this method on a variety of standard datasets including MNIST and CIFAR-10 and show that it generalizes well across different architectures and attacks. Our findings report that 85-93% ROC-AUC can be achieved on a number of standard classification tasks with a negative class that consists of both normal and noisy samples.		Reuben Feinman; Ryan R. Curtin; Saurabh Shintre; Andrew B. Gardner		https://doi.org/10.48550/arXiv.1703.00410				Included	Included	snowballing			1	arXiv	2017	Detecting Adversarial Samples from Artifacts			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
149	TestNN	Extending Defensive Distillation	Abstract:Machine learning is vulnerable to adversarial examples: inputs carefully modified to force misclassification. Designing defenses against such inputs remains largely an open problem. In this work, we revisit defensive distillation---which is one of the mechanisms proposed to mitigate adversarial examples---to address its limitations. We view our results not only as an effective way of addressing some of the recently discovered attacks but also as reinforcing the importance of improved training techniques.		Nicolas Papernot; Patrick McDaniel		https://doi.org/10.48550/arXiv.1705.05264				Included	Included	snowballing			1	arXiv	2017	Extending defensive distillation			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
150	TestNN	Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks	Abstract:Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by \emph{adversarial examples} that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, \emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.		Weilin Xu; David Evans; Yanjun Qi		https://doi.org/10.48550/arXiv.1704.01155				Included	Included	snowballing			1	arXiv	2017	Feature squeezing: Detecting adversarial examples in deep neural networks			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
151	TestNN	On Detecting Adversarial Perturbations	"Abstract:Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small ""detector"" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack."		Jan Hendrik Metzen; Tim Genewein; Volker Fischer; Bastian Bischoff		https://doi.org/10.48550/arXiv.1702.04267				Included	Included	snowballing			1	arXiv	2017	On detecting adversarial perturbations			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
152	TestNN	Parseval networks: Improving robustness to adversarial examples	We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks. © 2017 by the author (s).	Artificial intelligence; Convolution; Deep neural networks; Important features; Lipschitz constant; Orthogonal matrix; Square matrices; State of the art; Tight frame; Weight matrices; Matrix algebra	Cisse, Moustapha; Bojanowski, Piotr; Grave, Edouard; Dauphin, Yann; Usunier, Nicolas	34th International Conference on Machine Learning, ICML 2017			1423 – 1432	"@CONFERENCE{Cisse20171423,
    author = ""Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas"",
    title = ""Parseval networks: Improving robustness to adversarial examples"",
    year = ""2017"",
    journal = ""34th International Conference on Machine Learning, ICML 2017"",
    volume = ""2"",
    pages = ""1423 – 1432"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046998902\&partnerID=40\&md5=e83a5aae0741ba575818c2526f5f294b"",
    affiliations = ""Facebook AI Research, France"",
    abstract = ""We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks. © 2017 by the author (s)."",
    keywords = ""Artificial intelligence; Convolution; Deep neural networks; Important features; Lipschitz constant; Orthogonal matrix; Square matrices; State of the art; Tight frame; Weight matrices; Matrix algebra"",
    correspondence_address = ""M. Cisse; Facebook AI Research, France; email: moustaphacisse@fb.com"",
    publisher = ""International Machine Learning Society (IMLS)"",
    isbn = ""978-151085514-4"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Mach. Learn., ICML"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 281; Conference name: 34th International Conference on Machine Learning, ICML 2017; Conference date: 6 August 2017 through 11 August 2017; Conference code: 136027""
}
"	Included	Included	snowballing			1	Scopus	2017	Parseval networks: Improving robustness to adversarial examples	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046998902&partnerID=40&md5=e83a5aae0741ba575818c2526f5f294b	International Machine Learning Society (IMLS)	nan; References; DOI
153	TestNN	Reachable Set Estimation and Safety Verification for Piecewise Linear Systems with Neural Network Controllers	In this work, the reachable set estimation and safety verification problems for a class of piecewise linear systems equipped with neural network controllers are addressed. The neural network is considered to consist of Rectified Linear Unit (ReLU) activation functions. A layer-by-layer approach is developed for the output reachable set computation of ReLU neural networks. The computation is formulated in the form of a set of manipulations for a union of polytopes. Based on the output reachable set for neural network controllers, the output reachable set for a piecewise linear feedback control system can be estimated iteratively for a given finite-time interval. With the estimated output reachable set, the safety verification for piecewise linear systems with neural network controllers can be performed by checking the existence of intersections of unsafe regions and output reach set. A numerical example is presented to illustrate the effectiveness of our approach.		Weiming Xiang; Hoang-Dung Tran; Joel A. Rosenfeld; Taylor T. Johnson	2018 Annual American Control Conference (ACC)	https://doi.org/10.23919/ACC.2018.8431048				Included	Included	snowballing			1	IEEE	2017	Reachable set computation and safety verification for neural networks with ReLU activations		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
154	TestNN	A Study of Deep Learning Robustness Against Computation Failures	Abstract:For many types of integrated circuits, accepting larger failure rates in computations can be used to improve energy efficiency. We study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults. After identifying the impact of hyperparameters such as the number of layers on robustness, we study the ability of the network to compensate for computational failures through an increase of the network size. We show that some networks can achieve equivalent performance under faulty implementations, and quantify the required increase in computational complexity.		Jean-Charles Vialatte; François Leduc-Primeau		https://doi.org/10.48550/arXiv.1704.05396				Included	Included	snowballing			1	arXiv	2017	A Study of Deep Learning Robustness Against Computation Failures			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
155	TestNN	Towards proving the adversarial robustness of deep neural networks	Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed.	Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.3		19 – 26	"@CONFERENCE{Katz201719,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""Towards proving the adversarial robustness of deep neural networks"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""19 – 26"",
    doi = ""10.4204/EPTCS.257.3"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870\&doi=10.4204\%2fEPTCS.257.3\&partnerID=40\&md5=7c1218ee68d68aa322e5e3ba887dba5e"",
    affiliations = ""Stanford University, United States"",
    abstract = ""Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed."",
    keywords = ""Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, United States; email: guyk@stanford.edu"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 47; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"	Included	Included	snowballing			1	Scopus	2017	Towards proving the adversarial robustness of deep neural networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870&doi=10.4204%2fEPTCS.257.3&partnerID=40&md5=7c1218ee68d68aa322e5e3ba887dba5e	Open Publishing Association	nan; References
156	TestNN	Axiomatic attribution for deep networks	We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—SensitivityandImplementation Invariancethat attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method calledIntegrated Gradients.Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.		MukundSundararajan; AnkurTaly; QiqiYan	ICML'17: Proceedings of the 34th International Conference on Machine Learning - Volume 70	https://doi.org/10.5555/3305890.3306024		319-3328		Included	Included	snowballing			1	ACM	2017	 Axiomatic attribution for deep networks		JMLR.org	nan; Keywords; References; Year; Bibtex; Link
157	TestNN	Explaining nonlinear classification decisions with deep Taylor decomposition	Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets. © 2016 The Author(s)	Image recognition; Learning systems; Multilayers; Network architecture; Deep neural networks; Heatmapping; Machine learning problem; Network classification; Non-linear methods; Nonlinear classification; Nonlinear structure; Scope of application; Multilayer neural networks	Montavon, Grégoire; Lapuschkin, Sebastian; Binder, Alexander; Samek, Wojciech; Müller, Klaus-Robert	Pattern Recognition	https://doi.org/10.1016/j.patcog.2016.11.008		211 – 222	"@ARTICLE{Montavon2017211,
    author = ""Montavon, Grégoire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and Müller, Klaus-Robert"",
    title = ""Explaining nonlinear classification decisions with deep Taylor decomposition"",
    year = ""2017"",
    journal = ""Pattern Recognition"",
    volume = ""65"",
    pages = ""211 – 222"",
    doi = ""10.1016/j.patcog.2016.11.008"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010676902\&doi=10.1016\%2fj.patcog.2016.11.008\&partnerID=40\&md5=fe281e0adbac8b5f621dc36cba4b43f2"",
    affiliations = ""Department of Electrical Engineering \& Computer Science, Technische Universität Berlin, Marchstr. 23, Berlin, 10587, Germany; Department of Video Coding \& Analytics, Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Information Systems Technology \& Design, Singapore University of Technology and Design, 8 Somapah Road, Building 1, Level 5, 487372, Singapore; Department of Brain \& Cognitive Engineering, Korea University, Anam-dong 5ga, Seongbuk-g, Seoul, 136-713, South Korea"",
    abstract = ""Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets. © 2016 The Author(s)"",
    author_keywords = ""Deep neural networks; Heatmapping; Image recognition; Relevance propagation; Taylor decomposition"",
    keywords = ""Image recognition; Learning systems; Multilayers; Network architecture; Deep neural networks; Heatmapping; Machine learning problem; Network classification; Non-linear methods; Nonlinear classification; Nonlinear structure; Scope of application; Multilayer neural networks"",
    correspondence_address = ""G. Montavon; Department of Electrical Engineering \& Computer Science, Technische Universität Berlin, Berlin, Marchstr. 23, 10587, Germany; email: gregoire.montavon@tu-berlin.de"",
    publisher = ""Elsevier Ltd"",
    issn = ""00313203"",
    coden = ""PTNRA"",
    language = ""English"",
    abbrev_source_title = ""Pattern Recogn."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 903; All Open Access, Green Open Access, Hybrid Gold Open Access""
}
"	Included	Included	snowballing			1	Scopus	2017	Explaining nonlinear classification decisions with deep Taylor decomposition	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010676902&doi=10.1016%2fj.patcog.2016.11.008&partnerID=40&md5=fe281e0adbac8b5f621dc36cba4b43f2	Elsevier Ltd	nan; References
158	TestNN	Improving Interpretability of Deep Neural Networks with Semantic Information	Interpretability of deep neural networks (DNNs) is essential since it enables users to understand the overall strengths and weaknesses of the models, conveys an understanding of how the models will behave in the future, and how to diagnose and correct potential problems. However, it is challenging to reason about what a DNN actually does due to its opaque or black-box nature. To address this issue, we propose a novel technique to improve the interpretability of DNNs by leveraging the rich semantic information embedded in human descriptions. By concentrating on the video captioning task, we first extract a set of semantically meaningful topics from the human descriptions that cover a wide range of visual concepts, and integrate them into the model with an interpretive loss. We then propose a prediction difference maximization algorithm to interpret the learned features of each neuron. Experimental results demonstrate its effectiveness in video captioning using the interpretable features, which can also be transferred to video action recognition. By clearly understanding the learned features, users can easily revise false predictions via a human-in-the-loop procedure.		Yinpeng Dong; Hang Su; Jun Zhu; Bo Zhang	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2017.110	"1.S.D. Ali, ""The impact of deep learning on investments: Exploring the implications one at a time"", Predictive Analytics and Futurism, vol. 13, pp. 49-50, 2016. Google Scholar; 2.N. Ballas, L. Yao, C. Pal and A. Courville, ""Delving deeper into convolutional networks for learning video representations"", ICLR, 2016. Google Scholar; 3.Y. Bengio, A. Courville and P. Vincent, ""Representation learning: A review and new perspectives"", IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 8, pp. 1798-1828, 2013. View Article  Google Scholar; 4.D.M. Blei, A.Y. Ng and M.I. Jordan, ""Latent dirichlet allocation"", Journal of machine Learning research, vol. 3, pp. 993-1022, Jan 2003. Google Scholar; 5.M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L.D. Jackel, M. Monfort, U. Muller, J. Zhang et al., End to end learning for self-driving cars, 2016. Google Scholar; 6.J.L. Boyd-Graber, D.M. Blei and X. Zhu, ""A topic model for word sense disambiguation"", EMNLP-CoNLL, 2007. Google Scholar; 7.L. Cao and L. Fei-Fei, ""Spatially coherent latent topic model for concurrent segmentation and classification of objects and scenes"", ICCV, 2007. View Article  Google Scholar; 8.D.L. Chen and W.B. Dolan, ""Collecting highly parallel data for paraphrase evaluation"", ACL, 2011. Google Scholar; 9.J. Chen, K. Li, J. Zhu and W. Chen, ""Warplda: a simple and efficient o (1) algorithm for latent dirichlet allocation"", VLDB, 2016. CrossRef  Google Scholar; 10.J. Chung, C. Gulcehre, K. Cho and Y. Bengio, ""Empirical evaluation of gated recurrent neural networks on sequence modeling"", NIPS Workshop on Deep Learning, 2014. Google Scholar; 11.M. Denkowski and A. Lavie, ""Meteor universal: Language specific translation evaluation for any target language"", ACL Workshop on Statistical Machine Translation, 2014. CrossRef  Google Scholar; 12.D. Erhan, Y. Bengio, A. Courville and P. Vincent, Visualizing higher-layer features of a deep network, University of Montreal, pp. 1341, 2009. Google Scholar; 13.L. Fei-Fei and P. Perona, ""A bayesian hierarchical model for learning natural scene categories"", CVPR, 2005. View Article  Google Scholar; 14.R. Girshick, J. Donahue, T. Darrell and J. Malik, ""Rich feature hierarchies for accurate object detection and semantic segmentation"", CVPR, 2014. View Article  Google Scholar; 15.""Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique"", IEEE Transactions on Medical Imaging, vol. 35, no. 5, pp. 1153-1159, 2016. View Article  Google Scholar; 16.B. Huval, T. Wang, S. Tandon, J. Kiske, W. Song, J. Pazhayampallil, M. Andriluka, P. Rajpurkar, T. Migimatsu, R. Cheng-Yue et al., An empirical evaluation of deep learning on highway driving, 2015. Google Scholar; 17.A. Karpathy, J. Johnson and L. Fei-Fei, ""Visualizing and understanding recurrent networks"", ICLR Workshop, 2016. Google Scholar; 18.A. Krizhevsky, I. Sutskever and G.E. Hinton, ""Imagenet classification with deep convolutional neural networks"", NIPS, 2012. Google Scholar; 19.Y. LeCun, Y. Bengio and G. Hinton, ""Deep learning"", Nature, vol. 521, no. 7553, pp. 436-444, 2015. CrossRef  Google Scholar; 20.A.-A. Liu, Y.-T. Su, W.-Z. Nie and M. Kankanhalli, ""Hierarchical clustering multi-task learning for joint human action grouping and recognition"", IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 1, pp. 102-114, 2017. View Article  Google Scholar; 21.A.-A. Liu, N. Xu, W.-Z. Nie, Y.-T. Su, Y. Wong and M. Kankanhalli, ""Benchmarking a multimodal and multiview and interactive dataset for human action recognition"", IEEE Transactions on Cybernetics, 2016. Google Scholar; 22.J. Liu, J. Luo and M. Shah, ""Recognizing realistic actions from videos in the wild"", CVPR, 2009. View Article  Google Scholar; 23.M. Liu, J. Shi, Z. Li, C. Li, J. Zhu and S. Liu, ""Towards better analysis of deep convolutional neural networks"", VAST, 2016. Google Scholar; 24.A. Nguyen, J. Yosinski and J. Clune, ""Deep neural networks are easily fooled: High confidence predictions for unrecognizable images"", CVPR, 2015. View Article  Google Scholar; 25.A. Nguyen, J. Yosinski and J. Clune, ""Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks"", ICML Visualization Workshop, 2016. Google Scholar; 26.Y. Pan, T. Mei, T. Yao, H. Li and Y. Rui, ""Jointly modeling embedding and translation to bridge video and language"", CVPR, 2016. View Article  Google Scholar; 27.K. Papineni, S. Roukos, T. Ward and W.-J. Zhu, ""Bleu: a method for automatic evaluation of machine translation"", ACL, 2002. CrossRef  Google Scholar; 28.S. Ren, K. He, R. Girshick and J. Sun, ""Faster r-cnn: Towards real-time object detection with region proposal networks"", NIPS, 2015. Google Scholar; 29.M. Schuster and K.K. Paliwal, ""Bidirectional recurrent neural networks"", IEEE Transactions on Signal Processing, vol. 45, no. 11, pp. 2673-2681, 1997. View Article  Google Scholar; 30.C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, et al., ""Going deeper with convolutions"", CVPR, 2015. View Article  Google Scholar"			Included	Included	snowballing			1	IEEE	2017	 Improving interpretability of deep neural networks with semantic information		IEEE	nan; Keywords; Pages; Year; Bibtex; Link
159	TestNN	Interpretability via Model Extraction	Abstract:The ability to interpret machine learning models has become increasingly important now that machine learning is used to inform consequential decisions. We propose an approach called model extraction for interpreting complex, blackbox models. Our approach approximates the complex model using a much more interpretable model; as long as the approximation quality is good, then statistical properties of the complex model are reflected in the interpretable model. We show how model extraction can be used to understand and debug random forests and neural nets trained on several datasets from the UCI Machine Learning Repository, as well as control policies learned for several classical reinforcement learning problems.		Osbert Bastani; Carolyn Kim; Hamsa Bastani		https://doi.org/10.48550/arXiv.1706.09773				Included	Included	snowballing			1	arXiv	2017	Interpretability via model extraction			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
160	TestNN	Interpretable Explanations of Black Boxes by Meaningful Perturbation	As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks “look” in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we specialise the framework to find the part of an image most responsible for a classifier decision. Unlike previous works, our method is model-agnostic and testable because it is grounded in explicit and interpretable image perturbations.		Ruth C. Fong; Andrea Vedaldi	2017 IEEE International Conference on Computer Vision (ICCV)	https://doi.org/10.1109/ICCV.2017.371				Included	Included	snowballing			1	IEEE	2017	 Interpretable explanations of black boxes by meaningful perturbation		IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
161	TestNN	Real time image saliency for black box classifiers	In this work we develop a fast saliency detection method that can be applied to any differentiable image classifier. We train a masking model to manipulate the scores of the classifier by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods. © 2017 Neural information processing systems foundation. All rights reserved.	Image classification; Image segmentation; Interactive computer systems; Black boxes; Image Classifiers; Localisation; Masking models; Real time images; Saliency detection; Saliency map; Supervised methods; Real time systems	Dabkowski, Piotr; Gal, Yarin	Advances in Neural Information Processing Systems			6968 – 6977	"@CONFERENCE{Dabkowski20176968,
    author = ""Dabkowski, Piotr and Gal, Yarin"",
    editor = ""I., Guyon and R., Fergus and H., Wallach and H., Wallach and I., Guyon and S.V.N., Vishwanathan and von Luxburg U. and R., Garnett and S.V.N., Vishwanathan and S., Bengio and R., Fergus"",
    title = ""Real time image saliency for black box classifiers"",
    year = ""2017"",
    journal = ""Advances in Neural Information Processing Systems"",
    volume = ""2017-December"",
    pages = ""6968 – 6977"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047021939\&partnerID=40\&md5=d7fc61dc7820b5003e899a747ead5ffa"",
    affiliations = ""University of Cambridge, United Kingdom; Alan Turing Institute, London, United Kingdom"",
    abstract = ""In this work we develop a fast saliency detection method that can be applied to any differentiable image classifier. We train a masking model to manipulate the scores of the classifier by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods. © 2017 Neural information processing systems foundation. All rights reserved."",
    keywords = ""Image classification; Image segmentation; Interactive computer systems; Black boxes; Image Classifiers; Localisation; Masking models; Real time images; Saliency detection; Saliency map; Supervised methods; Real time systems"",
    publisher = ""Neural information processing systems foundation"",
    issn = ""10495258"",
    language = ""English"",
    abbrev_source_title = ""Adv. neural inf. proces. syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 336; Conference name: 31st Annual Conference on Neural Information Processing Systems, NIPS 2017; Conference date: 4 December 2017 through 9 December 2017; Conference code: 136033""
}
"	Included	Included	snowballing			1	Scopus	2017	 Real time image saliency for black box classifiers	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047021939&partnerID=40&md5=d7fc61dc7820b5003e899a747ead5ffa	Neural information processing systems foundation	nan; References; DOI
162	TestNN	Right for the right reasons:training differentiable models by constraining their explanations	Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially if conditions in training may differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients. We apply these penalties both based on expert annotation and in an unsupervised fashion that produces multiple classifiers with qualitatively different decision boundaries. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.		Andrew SlavinRoss; Michael C.Hughes; FinaleDoshi-Velez	IJCAI'17: Proceedings of the 26th International Joint Conference on Artificial Intelligence	https://doi.org/10.5555/3172077.3172259		662-2670		Included	Included	snowballing			1	ACM	2017	Right for the right reasons: Training differentiable models by constraining their explanations		AAAI Press	nan; Keywords; References; Year; Bibtex; Link
163	TestNN	A simple neural network module for relational reasoning	Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Thus, by simply augmenting convolutions, LSTMs, and MLPs with RNs, we can remove computational burden from network components that are not well-suited to handle relational reasoning, reduce overall network complexity, and gain a general ability to reason about the relations between entities and their properties.		AdamSantoro; DavidRaposo; David G.T.Barrett; MateuszMalinowski; RazvanPascanu; PeterBattaglia; TimothyLillicrap	NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3295222.3295250		974-4983		Included	Included	snowballing			1	ACM	2017	 A simple neural network module for relational reasoning		Curran Associates Inc.	nan; Keywords; References; Year; Bibtex; Link
164	TestNN	A unified approach to interpreting model predictions	Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension betweenaccuracyandinterpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.		Scott M.Lundberg; Su-InLee	NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3295222.3295230		768-4777		Included	Included	snowballing			1	ACM	2017	 A unified approach to interpreting model predictions		Curran Associates Inc.	nan; Keywords; References; Year; Bibtex; Link
165	TestNN	Verification of Binarized Neural Networks via Inter-neuron Factoring	Binarized Neural Networks (BNN) have recently been proposed as an energy-efficient alternative to more traditional learning networks. Here we study the problem of formally verifying BNNs by reducing it to a corresponding hardware verification problem. The main step in this reduction is based on factoring computations among neurons within a hidden layer of the BNN in order to make the BNN verification problem more scalable in practice. The main contributions of this paper include results on the NP-hardness and hardness of PTAS approximability of this essential optimization and factoring step, and we design polynomial-time search heuristics for generating approximate factoring solutions. With these techniques we are able to scale the verification problem to moderately-sized BNNs for embedded devices with thousands of neurons and inputs.		Chih-Hong Cheng17,; Georg Nührenberg17,; Chung-Hao Huang17&; Harald Ruess17	Working Conference on Verified Software: Theories, Tools, and Experiments	https://doi.org/10.1007/978-3-030-03592-1_16		pp 279–290		Included	Included	snowballing			1	SpringerLink	2018	Verification of binarized neural networks		Springer, Cham	nan; Keywords; References; Year; Bibtex; Link
166	TestNN	Poster abstract: Safety analysis for UAV networks	The recent trend of collaborative operations of a network of Unmanned Aerial Vehicles (UAVs) to achieve a common objective has attracted the researchers, as well as commercial vendors. It has revolutionized the means of data collection to maximize mission performances. However, the collaborative UAVs need to be safe from cyberattacks to prevent catastrophe. They need to be able to collaborate with each other to avoid potential failure of a mission. As these smart devices are always targets of adversaries, they need to maintain safe communication with each other while avoiding fuel outage and mid-air collisions, as well as reducing the possibilities of being hacked. In this work, we present the idea of a formal verification tool that takes different UAV parameters, safety requirements, and resource constraints as input and verifies the network's safety. © 2018 IEEE.	Aircraft accidents; Antennas; Commercial vehicle operations; Commercial vehicles; Deep learning; Disaster prevention; Image processing; Internet of things; Collaborative operations; Formal verification tools; Mid-air collisions; Mission performance; Potential failures; Resource Constraint; Safe communications; Safety requirements; Unmanned aerial vehicles (UAV)	Jakaria, A.H.M.; Rahman, Mohammad Ashiqur	Proceedings - ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018	https://doi.org/10.1109/IoTDI.2018.00046		294 – 295	"@CONFERENCE{Jakaria2018294,
    author = ""Jakaria, A.H.M. and Rahman, Mohammad Ashiqur"",
    title = ""Poster abstract: Safety analysis for UAV networks"",
    year = ""2018"",
    journal = ""Proceedings - ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018"",
    pages = ""294 – 295"",
    doi = ""10.1109/IoTDI.2018.00046"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048478177\&doi=10.1109\%2fIoTDI.2018.00046\&partnerID=40\&md5=68ef198599708e97c267fb7ec1c1f831"",
    affiliations = ""Department of Computer Science, Tennessee Tech University, Cookeville, TN, United States"",
    abstract = ""The recent trend of collaborative operations of a network of Unmanned Aerial Vehicles (UAVs) to achieve a common objective has attracted the researchers, as well as commercial vendors. It has revolutionized the means of data collection to maximize mission performances. However, the collaborative UAVs need to be safe from cyberattacks to prevent catastrophe. They need to be able to collaborate with each other to avoid potential failure of a mission. As these smart devices are always targets of adversaries, they need to maintain safe communication with each other while avoiding fuel outage and mid-air collisions, as well as reducing the possibilities of being hacked. In this work, we present the idea of a formal verification tool that takes different UAV parameters, safety requirements, and resource constraints as input and verifies the network's safety. © 2018 IEEE."",
    author_keywords = ""BLE; Deep learning; Image processing"",
    keywords = ""Aircraft accidents; Antennas; Commercial vehicle operations; Commercial vehicles; Deep learning; Disaster prevention; Image processing; Internet of things; Collaborative operations; Formal verification tools; Mid-air collisions; Mission performance; Potential failures; Resource Constraint; Safe communications; Safety requirements; Unmanned aerial vehicles (UAV)"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153866312-7"",
    language = ""English"",
    abbrev_source_title = ""Proc. - ACM/IEEE Int. Conf. Internet Things Des. Implement., IoTDI"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 3rd ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018; Conference date: 17 April 2018 through 20 April 2018; Conference code: 136740""
}
"	Excluded	Excluded	snowballing		Exclusion: full-text is not available	1	Scopus	2018	 Poster abstract: Safety analysis for UAV networks	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048478177&doi=10.1109%2fIoTDI.2018.00046&partnerID=40&md5=68ef198599708e97c267fb7ec1c1f831	Institute of Electrical and Electronics Engineers Inc.	nan; References
167	TestNN	A game-based approximate verification of deep neural networks with provable guarantees	"<div class=""abstract author"" id=""ab0010""><h2 class=""section-title u-h4 u-margin-l-top u-margin-xs-bottom"">Abstract</h2><div id=""as0010""><p id=""sp0240"">Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. In this paper, we study two variants of pointwise robustness, the <em>maximum safe radius</em> problem, which for a given input sample computes the minimum distance to an adversarial example, and the <em>feature robustness</em> problem, which aims to quantify the robustness of individual features to adversarial perturbations. We demonstrate that, under the assumption of Lipschitz continuity, both problems can be approximated using finite optimisation by discretising the input space, and the approximation has provable guarantees, i.e., the error is bounded. We then show that the resulting optimisation problems can be reduced to the solution of two-player turn-based games, where the first player selects features and the second perturbs the image within the feature. While the second player aims to minimise the distance to an adversarial example, depending on the optimisation objective the first player can be cooperative or competitive. We employ an anytime approach to solve the games, in the sense of approximating the value of a game by monotonically improving its upper and lower bounds. The Monte Carlo tree search algorithm is applied to compute upper bounds for both games, and the Admissible A<sup>⁎</sup> and the Alpha-Beta Pruning algorithms are, respectively, used to compute lower bounds for the maximum safety radius and feature robustness games. When working on the upper bound of the maximum safe radius problem, our tool demonstrates competitive performance against existing adversarial example crafting algorithms. Furthermore, we show how our framework can be deployed to evaluate pointwise robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.</p></div></div>"	Automated verification; Deep neural networks; Adversarial examples; Two-player game	Wu, M., M. Wicker, W. Ruan, X. Huang and M. Kwiatkowska	Theoretical Computer Science	https://doi.org/10.1016/j.tcs.2019.05.046		Volume 807,6 February 2020, Pages 		Included	Included	snowballing			1	ScienceDirect	2018	A Game-Based Approximate Verification of Deep Neural Networks with Provable Guarantees		Science Direct	nan; Authors; References; Year; Bibtex; Link
168	TestNN	Anchors:high-precision model-agnostic explanations	"We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules calledanchors, representing local, ""sufficient"" conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations."		Marco TulioRibeiro; SameerSingh; CarlosGuestrin	AAAI'18/IAAI'18/EAAI'18: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence	https://doi.org/10.5555/3504035.3504222		527-1535		Included	Included	snowballing			1	ACM	2018	 Anchors: High-precision model-agnostic explanations		AAAI Press	nan; Keywords; References; Year; Bibtex; Link
169	TestNN	Global-and-local attention networks for visual recognition			Linsley, D., D. Scheibler, S. Eberhardt and T. Serre						Included	Included	snowballing			1		2018				
170	TestNN	Interpreting Deep Classifier by Visual Distillation of Dark Knowledge	"Abstract:Interpreting black box classifiers, such as deep networks, allows an analyst to validate a classifier before it is deployed in a high-stakes setting. A natural idea is to visualize the deep network's representations, so as to ""see what the network sees"". In this paper, we demonstrate that standard dimension reduction methods in this setting can yield uninformative or even misleading visualizations. Instead, we present DarkSight, which visually summarizes the predictions of a classifier in a way inspired by notion of dark knowledge. DarkSight embeds the data points into a low-dimensional space such that it is easy to compress the deep classifier into a simpler one, essentially combining model compression and dimension reduction. We compare DarkSight against t-SNE both qualitatively and quantitatively, demonstrating that DarkSight visualizations are more informative. Our method additionally yields a new confidence measure based on dark knowledge by quantifying how unusual a given vector of predictions is."		Kai Xu; Dae Hoon Park; Chang Yi; Charles Sutton		https://doi.org/10.48550/arXiv.1803.04042				Included	Included	snowballing			1	arXiv	2018	Interpreting Deep Classifier by Visual Distillation of Dark Knowledge			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
171	TestNN	Learning Functional Causal Models with Generative Neural Networks	We introduce a new approach to functional causal modeling from observational data, calledCausal Generative Neural Networks(CGNN). CGNN leverages the power of neural networks to learn a generative model of the joint distribution of the observed variables, by minimizing the Maximum Mean Discrepancy between generated and observed data. An approximate learning criterion is proposed to scale the computational cost of the approach to linear complexity in the number of observations. The performance of CGNN is studied throughout three experiments. Firstly, CGNN is applied to cause-effect inference, where the task is to identify the best causal hypothesis out of “X→Y” and “Y→X”. Secondly, CGNN is applied to the problem of identifying v-structures and conditional independences. Thirdly, CGNN is applied to multivariate functional causal modeling: given a skeleton describing the direct dependences in a set of random variablesX= [X1, …,Xd], CGNN orients the edges in the skeleton to uncover the directed acyclic causal graph describing the causal structure of the random variables. On all three tasks, CGNN is extensively assessed on both artificial and real-world data, comparing favorably to the state-of-the-art. Finally, CGNN is extended to handle the case of confounders, where latent variables are involved in the overall causal model.	Generative neural networks; Causal structure discovery; Cause-effect pair problem; Functional causal models; Structural equation models	Olivier Goudet11,; Diviyan Kalainathan11,; Philippe Caillou11,; Isabelle Guyon12,13,; David Lopez-Paz14&; Michèle Sebag11	Explainable and Interpretable Models in Computer Vision and Machine Learning	https://doi.org/10.1007/978-3-319-98131-4_3		pp 39–80		Excluded	Excluded	snowballing		Exclusion: not aiming at testing/verification approach	1	SpringerLink	2018	Learning functional causal models with generative neural networks		Springer, Cham	nan; References; Year; Bibtex; Link
172	TestNN	Learning Global Additive Explanations for Neural Nets Using Model Distillation			Tan, S., R. Caruana, G. Hooker, P. Koch and A. Gordo						Included	Included	snowballing			1		2018				
173	TestNN	Learning how to explain neural networks: Patternnet and Patternattribution	DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.	Network layers; Linear modeling; Multi-layer network; Deep neural networks	Kindermans, Pieter-Jan; Schütt, Kristof T.; Alber, Maximilian; Müller, Klaus-Robert; Erhan, Dumitru; Kim, Been; Dähne, Sven	6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings				"@CONFERENCE{Kindermans2018,
    author = ""Kindermans, Pieter-Jan and Schütt, Kristof T. and Alber, Maximilian and Müller, Klaus-Robert and Erhan, Dumitru and Kim, Been and Dähne, Sven"",
    title = ""Learning how to explain neural networks: Patternnet and Patternattribution"",
    year = ""2018"",
    journal = ""6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950751\&partnerID=40\&md5=957a69e05c08058cde74be6a4437d430"",
    affiliations = ""Google Brain, United States; TU Berlin, Germany"",
    abstract = ""DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved."",
    keywords = ""Network layers; Linear modeling; Multi-layer network; Deep neural networks"",
    publisher = ""International Conference on Learning Representations, ICLR"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Learn. Represent., ICLR - Conf. Track Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 92; Conference name: 6th International Conference on Learning Representations, ICLR 2018; Conference date: 30 April 2018 through 3 May 2018; Conference code: 149806""
}
"	Included	Included	snowballing			1	Scopus	2018	 Learning how to explain neural networks: Patternnet and patternattribution	https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950751&partnerID=40&md5=957a69e05c08058cde74be6a4437d430	International Conference on Learning Representations, ICLR	nan; References; Pages; DOI
174	TestNN	Local Rule-Based Explanations of Black Box Decision Systems	Abstract:The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.		Riccardo Guidotti; Anna Monreale; Salvatore Ruggieri; Dino Pedreschi; Franco Turini; Fosca Giannotti		https://doi.org/10.48550/arXiv.1805.10820				Included	Included	snowballing			1	arXiv	2018	Local rule-based explanations of black box decision systems			nan; Venue; Keywords; References; Pages; Year; Bibtex; Link; Publisher
